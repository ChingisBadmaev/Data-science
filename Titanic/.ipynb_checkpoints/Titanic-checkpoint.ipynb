{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic\n",
    "In this task it is proposed to solve the problem of predicting the surviving passengers of the Titanic.\n",
    "Information about the dataset is available at the <a href=https://www.kaggle.com/c/titanic> link </a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy import stats\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first file contains information about passengers, the second contains information about whether the passenger survived or not.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 891 passengers in the sample\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pclass                                               Name  \\\n",
       "PassengerId                                                              \n",
       "1                 3                            Braund, Mr. Owen Harris   \n",
       "2                 1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "3                 3                             Heikkinen, Miss. Laina   \n",
       "4                 1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "5                 3                           Allen, Mr. William Henry   \n",
       "...             ...                                                ...   \n",
       "887               2                              Montvila, Rev. Juozas   \n",
       "888               1                       Graham, Miss. Margaret Edith   \n",
       "889               3           Johnston, Miss. Catherine Helen \"Carrie\"   \n",
       "890               1                              Behr, Mr. Karl Howell   \n",
       "891               3                                Dooley, Mr. Patrick   \n",
       "\n",
       "                Sex   Age  SibSp  Parch            Ticket     Fare Cabin  \\\n",
       "PassengerId                                                                \n",
       "1              male  22.0      1      0         A/5 21171   7.2500   NaN   \n",
       "2            female  38.0      1      0          PC 17599  71.2833   C85   \n",
       "3            female  26.0      0      0  STON/O2. 3101282   7.9250   NaN   \n",
       "4            female  35.0      1      0            113803  53.1000  C123   \n",
       "5              male  35.0      0      0            373450   8.0500   NaN   \n",
       "...             ...   ...    ...    ...               ...      ...   ...   \n",
       "887            male  27.0      0      0            211536  13.0000   NaN   \n",
       "888          female  19.0      0      0            112053  30.0000   B42   \n",
       "889          female   NaN      1      2        W./C. 6607  23.4500   NaN   \n",
       "890            male  26.0      0      0            111369  30.0000  C148   \n",
       "891            male  32.0      0      0            370376   7.7500   NaN   \n",
       "\n",
       "            Embarked  \n",
       "PassengerId           \n",
       "1                  S  \n",
       "2                  C  \n",
       "3                  S  \n",
       "4                  S  \n",
       "5                  S  \n",
       "...              ...  \n",
       "887                S  \n",
       "888                S  \n",
       "889                S  \n",
       "890                C  \n",
       "891                Q  \n",
       "\n",
       "[891 rows x 10 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('titanic_data.csv', index_col='PassengerId')\n",
    "print(f'Total {len(data)} passengers in the sample')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived\n",
       "PassengerId          \n",
       "1                   0\n",
       "2                   1\n",
       "3                   1\n",
       "4                   1\n",
       "5                   0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.read_csv('titanic_surv.csv')\n",
    "y.index = data.index\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pclass                                               Name  \\\n",
       "PassengerId                                                              \n",
       "1                 3                            Braund, Mr. Owen Harris   \n",
       "2                 1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "3                 3                             Heikkinen, Miss. Laina   \n",
       "4                 1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "5                 3                           Allen, Mr. William Henry   \n",
       "\n",
       "                Sex   Age  SibSp  Parch            Ticket     Fare Cabin  \\\n",
       "PassengerId                                                                \n",
       "1              male  22.0      1      0         A/5 21171   7.2500   NaN   \n",
       "2            female  38.0      1      0          PC 17599  71.2833   C85   \n",
       "3            female  26.0      0      0  STON/O2. 3101282   7.9250   NaN   \n",
       "4            female  35.0      1      0            113803  53.1000  C123   \n",
       "5              male  35.0      0      0            373450   8.0500   NaN   \n",
       "\n",
       "            Embarked  Survived  \n",
       "PassengerId                     \n",
       "1                  S         0  \n",
       "2                  C         1  \n",
       "3                  S         1  \n",
       "4                  S         1  \n",
       "5                  S         0  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.join(y)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Survivor analytics by gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Surviving men 109 out of 577    proportion: 0.18890814558058924\n",
      "Surviving women 233 out of 314    proportion: 0.7420382165605095\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "count_male = data['Sex'].value_counts()['male']\n",
    "count_female = data['Sex'].value_counts()['female']\n",
    "\n",
    "count_male_surv = data[data['Survived'] == 1]['Sex'].value_counts()['male']\n",
    "count_female_surv = data[data['Survived'] == 1]['Sex'].value_counts()['female']\n",
    "print('Surviving men', count_male_surv, 'out of', count_male, '  ', 'proportion:', count_male_surv / count_male)\n",
    "print('Surviving women', count_female_surv, 'out of', count_female, '  ', 'proportion:', count_female_surv / count_female)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.bar('Women', [count_male_surv,count_male], alpha=0.5, width = 0.5)\n",
    "ax.bar('Men', [count_female, count_female_surv], alpha=0.5, width = 0.5)\n",
    "\n",
    "fig.set_figwidth(8)    #  width Figure\n",
    "fig.set_figheight(5.5)    #  height Figure\n",
    "fig.set(facecolor='floralwhite')\n",
    "ax.set(facecolor='floralwhite')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Survivors analytics by class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First class survivors 136 out of 216    proportion 0.6296296296296297\n",
      "Second class survivors 87 out of 184    proportion 0.47282608695652173\n",
      "Third class survivors 119 out of 491    proportion 0.24236252545824846\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "count_class_one = data['Pclass'].value_counts()[1]\n",
    "count_class_two = data['Pclass'].value_counts()[2]\n",
    "count_class_three = data['Pclass'].value_counts()[3]\n",
    "\n",
    "count_class_one_surv = data[data['Survived'] == 1]['Pclass'].value_counts()[1]\n",
    "count_class_two_surv = data[data['Survived'] == 1]['Pclass'].value_counts()[2]\n",
    "count_class_three_surv = data[data['Survived'] == 1]['Pclass'].value_counts()[3]\n",
    "\n",
    "print('First class survivors', count_class_one_surv, 'out of', count_class_one, '  ', 'proportion', count_class_one_surv / count_class_one)\n",
    "print('Second class survivors', count_class_two_surv, 'out of', count_class_two,  '  ', 'proportion', count_class_two_surv / count_class_two)\n",
    "print('Third class survivors', count_class_three_surv, 'out of', count_class_three,  '  ', 'proportion', count_class_three_surv / count_class_three)\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.bar('First class', [count_class_one_surv, count_class_one], alpha=0.5, width = 0.5)\n",
    "ax.bar('Second класс', [count_class_two_surv, count_class_two], alpha=0.5, width = 0.5)\n",
    "ax.bar('Third класс', [count_class_three_surv, count_class_three], alpha=0.5, width = 0.5)\n",
    "\n",
    "fig.set_figwidth(8)   \n",
    "fig.set_figheight(5.5)\n",
    "fig.set(facecolor='floralwhite')\n",
    "ax.set(facecolor='floralwhite')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Survivors analytics by age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize = (7, 5))\n",
    "\n",
    "data['Age'].hist(label='total number of people')\n",
    "data[data['Survived'] == 1]['Age'].hist(label='number of survivors by age')\n",
    "\n",
    "fig.set_figwidth(9)    \n",
    "fig.set_figheight(6)    \n",
    "fig.set(facecolor='floralwhite')\n",
    "ax.set(facecolor='floralwhite')\n",
    "\n",
    "plt.xlabel('age', fontsize=13)\n",
    "plt.ylabel('number of survivors', fontsize=13)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Survivors analytics by the number of people in the family on the ship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['Family'] = data['SibSp'] + data['Parch']\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "x = {i: data[data['Family'] == i]['Survived'].count() for i in range(data['Family'].max() + 1)}\n",
    "\n",
    "data['Family'].hist(label='total number of people')\n",
    "data[data['Survived'] == 1]['Family'].hist(label='total number of people')\n",
    "\n",
    "fig.set_figwidth(9)\n",
    "fig.set_figheight(6)\n",
    "fig.set(facecolor='floralwhite')\n",
    "ax.set(facecolor='floralwhite')\n",
    "\n",
    "plt.xlabel('number of people in the family', fontsize=13)\n",
    "plt.ylabel('number of people', fontsize=13)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Survivors analytics by \"Embarked\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Embarked'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[:, ['Embarked']] = data.loc[:, ['Embarked']].fillna('0')\n",
    "data['Embarked'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of survivors, embarked S 217 out of 644    proportion: 0.33695652173913043\n",
      "number of survivors, embarked C 93 out of 168    proportion: 0.5535714285714286\n",
      "number of survivors, embarked Q 30 out of 77    proportion: 0.38961038961038963\n"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "data['Embarked'].hist()\n",
    "data[data['Survived'] == 1]['Embarked'].hist()\n",
    "\n",
    "fig.set_figwidth(9)\n",
    "fig.set_figheight(6)\n",
    "fig.set(facecolor='floralwhite')\n",
    "ax.set(facecolor='floralwhite')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "count_surv_embarked = data.drop(data[data.Survived == 0].index).groupby(['Embarked']).size()\n",
    "count_embarked = data.groupby(['Embarked']).size()\n",
    "\n",
    "print('number of survivors, embarked S', count_surv_embarked[3], 'out of', count_embarked[3], '  ', 'proportion:', count_surv_embarked[3] / count_embarked[3])\n",
    "print('number of survivors, embarked C', count_surv_embarked[1], 'out of', count_embarked[1], '  ', 'proportion:', count_surv_embarked[1] / count_embarked[1])\n",
    "print('number of survivors, embarked Q', count_surv_embarked[2], 'out of', count_embarked[2], '  ', 'proportion:', count_surv_embarked[2] / count_embarked[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking for NaN in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Age', 'Cabin']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns[data.isna().any()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nan in the в Age: 0\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Cabin'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2645\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2646\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Cabin'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-239-cd5a0fcef88f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Nan in the в Age:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Age'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Nan in the в Cabin:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Cabin'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2798\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2799\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2800\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2801\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2646\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2648\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2650\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Cabin'"
     ]
    }
   ],
   "source": [
    "print('Nan in the в Age:', data['Age'].isna().sum())\n",
    "print('Nan in the в Cabin:', data['Cabin'].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fill in the NaN in the \"age\" column. Solve the regression problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[:, ['Cabin']] = data.loc[:, ['Cabin']].fillna('0')\n",
    "data['Cabin'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId\n",
       "1         0\n",
       "2       C85\n",
       "3         0\n",
       "4      C123\n",
       "5         0\n",
       "       ... \n",
       "887       0\n",
       "888     B42\n",
       "889       0\n",
       "890    C148\n",
       "891       0\n",
       "Name: Cabin, Length: 891, dtype: object"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Cabin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Family</th>\n",
       "      <th>Cabin_type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cabin_type_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cabin_type_C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Cabin_type_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cabin_type_C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Cabin_type_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Cabin_type_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Cabin_type_B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Cabin_type_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Cabin_type_C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>0</td>\n",
       "      <td>Q</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Cabin_type_0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pclass                                               Name  \\\n",
       "PassengerId                                                              \n",
       "1                 3                            Braund, Mr. Owen Harris   \n",
       "2                 1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "3                 3                             Heikkinen, Miss. Laina   \n",
       "4                 1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "5                 3                           Allen, Mr. William Henry   \n",
       "...             ...                                                ...   \n",
       "887               2                              Montvila, Rev. Juozas   \n",
       "888               1                       Graham, Miss. Margaret Edith   \n",
       "889               3           Johnston, Miss. Catherine Helen \"Carrie\"   \n",
       "890               1                              Behr, Mr. Karl Howell   \n",
       "891               3                                Dooley, Mr. Patrick   \n",
       "\n",
       "                Sex   Age  SibSp  Parch            Ticket     Fare Cabin  \\\n",
       "PassengerId                                                                \n",
       "1              male  22.0      1      0         A/5 21171   7.2500     0   \n",
       "2            female  38.0      1      0          PC 17599  71.2833   C85   \n",
       "3            female  26.0      0      0  STON/O2. 3101282   7.9250     0   \n",
       "4            female  35.0      1      0            113803  53.1000  C123   \n",
       "5              male  35.0      0      0            373450   8.0500     0   \n",
       "...             ...   ...    ...    ...               ...      ...   ...   \n",
       "887            male  27.0      0      0            211536  13.0000     0   \n",
       "888          female  19.0      0      0            112053  30.0000   B42   \n",
       "889          female   NaN      1      2        W./C. 6607  23.4500     0   \n",
       "890            male  26.0      0      0            111369  30.0000  C148   \n",
       "891            male  32.0      0      0            370376   7.7500     0   \n",
       "\n",
       "            Embarked  Survived  Family    Cabin_type  \n",
       "PassengerId                                           \n",
       "1                  S         0       1  Cabin_type_0  \n",
       "2                  C         1       1  Cabin_type_C  \n",
       "3                  S         1       0  Cabin_type_0  \n",
       "4                  S         1       1  Cabin_type_C  \n",
       "5                  S         0       0  Cabin_type_0  \n",
       "...              ...       ...     ...           ...  \n",
       "887                S         0       0  Cabin_type_0  \n",
       "888                S         1       0  Cabin_type_B  \n",
       "889                S         0       3  Cabin_type_0  \n",
       "890                C         1       0  Cabin_type_C  \n",
       "891                Q         0       0  Cabin_type_0  \n",
       "\n",
       "[891 rows x 13 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_cabin_letter(row):\n",
    "    return 'Cabin_type_' + row['Cabin'][0]\n",
    "\n",
    "data['Cabin_type'] = data.apply(get_cabin_letter, axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>...</th>\n",
       "      <th>S</th>\n",
       "      <th>Cabin_type_0</th>\n",
       "      <th>Cabin_type_A</th>\n",
       "      <th>Cabin_type_B</th>\n",
       "      <th>Cabin_type_C</th>\n",
       "      <th>Cabin_type_D</th>\n",
       "      <th>Cabin_type_E</th>\n",
       "      <th>Cabin_type_F</th>\n",
       "      <th>Cabin_type_G</th>\n",
       "      <th>Cabin_type_T</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pclass                                               Name  \\\n",
       "PassengerId                                                              \n",
       "1                 3                            Braund, Mr. Owen Harris   \n",
       "2                 1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "3                 3                             Heikkinen, Miss. Laina   \n",
       "4                 1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "5                 3                           Allen, Mr. William Henry   \n",
       "\n",
       "                Sex   Age  SibSp  Parch            Ticket     Fare Cabin  \\\n",
       "PassengerId                                                                \n",
       "1              male  22.0      1      0         A/5 21171   7.2500     0   \n",
       "2            female  38.0      1      0          PC 17599  71.2833   C85   \n",
       "3            female  26.0      0      0  STON/O2. 3101282   7.9250     0   \n",
       "4            female  35.0      1      0            113803  53.1000  C123   \n",
       "5              male  35.0      0      0            373450   8.0500     0   \n",
       "\n",
       "            Embarked  ...  S  Cabin_type_0 Cabin_type_A  Cabin_type_B  \\\n",
       "PassengerId           ...                                               \n",
       "1                  S  ...  1             1            0             0   \n",
       "2                  C  ...  0             0            0             0   \n",
       "3                  S  ...  1             1            0             0   \n",
       "4                  S  ...  1             0            0             0   \n",
       "5                  S  ...  1             1            0             0   \n",
       "\n",
       "             Cabin_type_C  Cabin_type_D  Cabin_type_E  Cabin_type_F  \\\n",
       "PassengerId                                                           \n",
       "1                       0             0             0             0   \n",
       "2                       1             0             0             0   \n",
       "3                       0             0             0             0   \n",
       "4                       1             0             0             0   \n",
       "5                       0             0             0             0   \n",
       "\n",
       "             Cabin_type_G  Cabin_type_T  \n",
       "PassengerId                              \n",
       "1                       0             0  \n",
       "2                       0             0  \n",
       "3                       0             0  \n",
       "4                       0             0  \n",
       "5                       0             0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([data, pd.get_dummies(data['Sex'])], axis=1)\n",
    "data = pd.concat([data, pd.get_dummies(data['Embarked'])], axis=1)\n",
    "data = pd.concat([data, pd.get_dummies(data['Cabin_type'])], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Name' 'Sex' 'Ticket' 'Cabin' 'Embarked' 'Cabin_type' '0'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-240-da1f185db03b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# deleting categorical data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Sex'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Ticket'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Cabin'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Embarked'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Cabin_type'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'0'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3988\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[1;36m1.0\u001b[0m     \u001b[1;36m0.8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3989\u001b[0m         \"\"\"\n\u001b[1;32m-> 3990\u001b[1;33m         return super().drop(\n\u001b[0m\u001b[0;32m   3991\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3992\u001b[0m             \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3934\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3935\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3936\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3937\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3938\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3968\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3969\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3970\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3971\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3972\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   5016\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5017\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5018\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5019\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5020\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Name' 'Sex' 'Ticket' 'Cabin' 'Embarked' 'Cabin_type' '0'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# deleting categorical data\n",
    "data.drop(['Name', 'Sex','Ticket', 'Cabin', 'Embarked', 'Cabin_type', '0'], axis=1, inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['PassengerId'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-241-bb2ab8438806>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# delete lines, where age is NaN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata_age\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'any'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Age'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'PassengerId'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdata_age\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3988\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[1;36m1.0\u001b[0m     \u001b[1;36m0.8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3989\u001b[0m         \"\"\"\n\u001b[1;32m-> 3990\u001b[1;33m         return super().drop(\n\u001b[0m\u001b[0;32m   3991\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3992\u001b[0m             \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3934\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3935\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3936\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3937\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3938\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3968\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3969\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3970\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3971\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3972\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   5016\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5017\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5018\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5019\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5020\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['PassengerId'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# delete lines, where age is NaN\n",
    "data_age = data.dropna(axis=0, how='any', subset=['Age']).reset_index().drop('PassengerId', axis=1)\n",
    "data_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['PassengerId'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-242-a271d6fda032>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# delete lines, where age is int/float\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata_age\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'any'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Age'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'PassengerId'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdata_age\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdata_nan_age\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAge\u001b[0m \u001b[1;33m>\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'PassengerId'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdata_nan_age\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3988\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[1;36m1.0\u001b[0m     \u001b[1;36m0.8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3989\u001b[0m         \"\"\"\n\u001b[1;32m-> 3990\u001b[1;33m         return super().drop(\n\u001b[0m\u001b[0;32m   3991\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3992\u001b[0m             \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3934\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3935\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3936\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3937\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3938\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3968\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3969\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3970\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3971\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3972\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   5016\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5017\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5018\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5019\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5020\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['PassengerId'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# delete lines, where age is int/float\n",
    "data_age = data.dropna(axis=0, how='any', subset=['Age']).reset_index().drop('PassengerId', axis=1)\n",
    "data_age\n",
    "data_nan_age = data.drop(data[data.Age >0].index).reset_index().drop('PassengerId', axis=1)\n",
    "data_nan_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_age_train, data_age_test = train_test_split(data_age, random_state=42, test_size=0.2)\n",
    "\n",
    "X_data_age_train = data_age_train.drop('Age', axis=1)\n",
    "y_data_age_train = data_age_train['Age']\n",
    "X_data_age_test = data_age_test.drop('Age', axis=1)\n",
    "y_data_age_test = data_age_test['Age']\n",
    "\n",
    "X_data_nan_age = data_nan_age.drop('Age', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest alghorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.4103006993007"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_RF_age = RandomForestRegressor(random_state=42,\n",
    "                               # число деревьев в лесу\n",
    "                               n_estimators=200,\n",
    "                               criterion='mae',\n",
    "                               max_depth=10,\n",
    "                               # Вычислять out-of-bag ошибку\n",
    "                               oob_score=True,\n",
    "                               warm_start=False\n",
    "                              )\n",
    "\n",
    "# обучаем модель на тренировочных данных\n",
    "model_RF_age.fit(X_data_age_train, y_data_age_train)\n",
    "\n",
    "y_age_pred = model_RF_age.predict(X_data_age_test)\n",
    "mean_absolute_error(y_age_pred, y_data_age_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoostingRegressor alghorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.227447325455945"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_GB_age = GradientBoostingRegressor(random_state=42,\n",
    "                                  learning_rate=0.1,\n",
    "                                  n_estimators=500,\n",
    "                                  criterion='mae',\n",
    "                                  max_depth=1,\n",
    "                                  max_features='auto'\n",
    ")\n",
    "\n",
    "# обучаем модель на тренировочных данных\n",
    "model_GB_age.fit(X_data_age_train, y_data_age_train)\n",
    "\n",
    "y_age_pred = model_GB_age.predict(X_data_age_test)\n",
    "mean_absolute_error(y_age_pred, y_data_age_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import from keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Converting pandas dataframe to numpy array\n",
    "X_data_age_train = X_data_age_train.values\n",
    "y_data_age_train = y_data_age_train.values\n",
    "X_data_age_test = X_data_age_test.values\n",
    "y_data_age_test = y_data_age_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "29/29 [==============================] - 1s 892us/step - loss: 905.0193 - mean_absolute_error: 26.3911\n",
      "Epoch 2/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 796.1862 - mean_absolute_error: 24.8768\n",
      "Epoch 3/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 744.1499 - mean_absolute_error: 23.4518\n",
      "Epoch 4/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 689.0756 - mean_absolute_error: 22.5861\n",
      "Epoch 5/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 691.7787 - mean_absolute_error: 22.0131\n",
      "Epoch 6/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 551.4582 - mean_absolute_error: 19.6158\n",
      "Epoch 7/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 540.9591 - mean_absolute_error: 18.9598\n",
      "Epoch 8/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 505.1930 - mean_absolute_error: 18.0003\n",
      "Epoch 9/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 456.1140 - mean_absolute_error: 17.3092\n",
      "Epoch 10/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 412.0867 - mean_absolute_error: 16.1150\n",
      "Epoch 11/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 448.5757 - mean_absolute_error: 16.6767\n",
      "Epoch 12/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 345.1683 - mean_absolute_error: 14.2160\n",
      "Epoch 13/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 319.5279 - mean_absolute_error: 13.5230\n",
      "Epoch 14/500\n",
      "29/29 [==============================] - 0s 855us/step - loss: 301.8305 - mean_absolute_error: 13.0584\n",
      "Epoch 15/500\n",
      "29/29 [==============================] - 0s 784us/step - loss: 377.8785 - mean_absolute_error: 14.2526\n",
      "Epoch 16/500\n",
      "29/29 [==============================] - 0s 998us/step - loss: 285.2507 - mean_absolute_error: 12.5228\n",
      "Epoch 17/500\n",
      "29/29 [==============================] - 0s 998us/step - loss: 266.7282 - mean_absolute_error: 12.2961\n",
      "Epoch 18/500\n",
      "29/29 [==============================] - 0s 961us/step - loss: 271.9147 - mean_absolute_error: 12.3670\n",
      "Epoch 19/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 269.8713 - mean_absolute_error: 12.5783\n",
      "Epoch 20/500\n",
      "29/29 [==============================] - 0s 927us/step - loss: 262.8576 - mean_absolute_error: 12.4088\n",
      "Epoch 21/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 218.3932 - mean_absolute_error: 11.4028\n",
      "Epoch 22/500\n",
      "29/29 [==============================] - 0s 996us/step - loss: 242.1779 - mean_absolute_error: 12.1098\n",
      "Epoch 23/500\n",
      "29/29 [==============================] - 0s 891us/step - loss: 237.0695 - mean_absolute_error: 12.0504\n",
      "Epoch 24/500\n",
      "29/29 [==============================] - 0s 963us/step - loss: 235.3310 - mean_absolute_error: 11.8581\n",
      "Epoch 25/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 258.6124 - mean_absolute_error: 12.5019\n",
      "Epoch 26/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 236.2696 - mean_absolute_error: 11.9338\n",
      "Epoch 27/500\n",
      "29/29 [==============================] - 0s 892us/step - loss: 215.0138 - mean_absolute_error: 11.5549\n",
      "Epoch 28/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 222.2738 - mean_absolute_error: 11.7030\n",
      "Epoch 29/500\n",
      "29/29 [==============================] - 0s 855us/step - loss: 259.7610 - mean_absolute_error: 12.6099\n",
      "Epoch 30/500\n",
      "29/29 [==============================] - 0s 998us/step - loss: 223.5091 - mean_absolute_error: 11.8291\n",
      "Epoch 31/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 223.0612 - mean_absolute_error: 11.9154\n",
      "Epoch 32/500\n",
      "29/29 [==============================] - 0s 890us/step - loss: 212.6099 - mean_absolute_error: 11.4899\n",
      "Epoch 33/500\n",
      "29/29 [==============================] - 0s 855us/step - loss: 223.2401 - mean_absolute_error: 11.5826\n",
      "Epoch 34/500\n",
      "29/29 [==============================] - 0s 784us/step - loss: 232.9812 - mean_absolute_error: 11.8395\n",
      "Epoch 35/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 217.8170 - mean_absolute_error: 11.6970\n",
      "Epoch 36/500\n",
      "29/29 [==============================] - 0s 784us/step - loss: 224.3821 - mean_absolute_error: 11.8161\n",
      "Epoch 37/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 249.9228 - mean_absolute_error: 12.2968\n",
      "Epoch 38/500\n",
      "29/29 [==============================] - 0s 884us/step - loss: 229.9927 - mean_absolute_error: 11.9322\n",
      "Epoch 39/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 228.3700 - mean_absolute_error: 11.8475\n",
      "Epoch 40/500\n",
      "29/29 [==============================] - 0s 819us/step - loss: 248.9871 - mean_absolute_error: 12.6665\n",
      "Epoch 41/500\n",
      "29/29 [==============================] - 0s 963us/step - loss: 217.7353 - mean_absolute_error: 11.5039\n",
      "Epoch 42/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 208.3242 - mean_absolute_error: 11.5815\n",
      "Epoch 43/500\n",
      "29/29 [==============================] - 0s 926us/step - loss: 222.5312 - mean_absolute_error: 11.7737\n",
      "Epoch 44/500\n",
      "29/29 [==============================] - 0s 855us/step - loss: 239.3482 - mean_absolute_error: 12.1409\n",
      "Epoch 45/500\n",
      "29/29 [==============================] - 0s 798us/step - loss: 223.1792 - mean_absolute_error: 11.9024\n",
      "Epoch 46/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 188.9312 - mean_absolute_error: 11.2175\n",
      "Epoch 47/500\n",
      "29/29 [==============================] - 0s 960us/step - loss: 213.6175 - mean_absolute_error: 11.5802\n",
      "Epoch 48/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 220.0492 - mean_absolute_error: 11.6248\n",
      "Epoch 49/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 197.4397 - mean_absolute_error: 11.4721\n",
      "Epoch 50/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 211.7906 - mean_absolute_error: 11.5790\n",
      "Epoch 51/500\n",
      "29/29 [==============================] - 0s 749us/step - loss: 216.9166 - mean_absolute_error: 11.5191\n",
      "Epoch 52/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 196.1502 - mean_absolute_error: 11.3550\n",
      "Epoch 53/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 195.9043 - mean_absolute_error: 11.1313\n",
      "Epoch 54/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 234.5741 - mean_absolute_error: 12.0838\n",
      "Epoch 55/500\n",
      "29/29 [==============================] - 0s 996us/step - loss: 191.4037 - mean_absolute_error: 11.0306\n",
      "Epoch 56/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 192.9714 - mean_absolute_error: 11.2737\n",
      "Epoch 57/500\n",
      "29/29 [==============================] - 0s 983us/step - loss: 197.0597 - mean_absolute_error: 11.1939\n",
      "Epoch 58/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 199.8190 - mean_absolute_error: 11.4719\n",
      "Epoch 59/500\n",
      "29/29 [==============================] - 0s 996us/step - loss: 198.5926 - mean_absolute_error: 11.1770\n",
      "Epoch 60/500\n",
      "29/29 [==============================] - 0s 891us/step - loss: 197.7282 - mean_absolute_error: 11.1082\n",
      "Epoch 61/500\n",
      "29/29 [==============================] - 0s 891us/step - loss: 197.7638 - mean_absolute_error: 11.3142\n",
      "Epoch 62/500\n",
      "29/29 [==============================] - 0s 891us/step - loss: 176.3234 - mean_absolute_error: 10.6862\n",
      "Epoch 63/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 206.0944 - mean_absolute_error: 11.3335\n",
      "Epoch 64/500\n",
      "29/29 [==============================] - 0s 968us/step - loss: 184.3728 - mean_absolute_error: 10.9565\n",
      "Epoch 65/500\n",
      "29/29 [==============================] - 0s 855us/step - loss: 196.0754 - mean_absolute_error: 11.1306\n",
      "Epoch 66/500\n",
      "29/29 [==============================] - 0s 831us/step - loss: 195.3680 - mean_absolute_error: 10.9403\n",
      "Epoch 67/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 193.3153 - mean_absolute_error: 11.3294\n",
      "Epoch 68/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 190.5519 - mean_absolute_error: 11.1253\n",
      "Epoch 69/500\n",
      "29/29 [==============================] - 0s 855us/step - loss: 190.7751 - mean_absolute_error: 11.2247\n",
      "Epoch 70/500\n",
      "29/29 [==============================] - 0s 855us/step - loss: 185.6281 - mean_absolute_error: 10.8713\n",
      "Epoch 71/500\n",
      "29/29 [==============================] - 0s 998us/step - loss: 215.8623 - mean_absolute_error: 11.7348\n",
      "Epoch 72/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 1ms/step - loss: 188.7681 - mean_absolute_error: 11.1219\n",
      "Epoch 73/500\n",
      "29/29 [==============================] - 0s 855us/step - loss: 179.1601 - mean_absolute_error: 10.6480\n",
      "Epoch 74/500\n",
      "29/29 [==============================] - 0s 893us/step - loss: 185.8561 - mean_absolute_error: 10.8975\n",
      "Epoch 75/500\n",
      "29/29 [==============================] - 0s 902us/step - loss: 182.5266 - mean_absolute_error: 10.8138\n",
      "Epoch 76/500\n",
      "29/29 [==============================] - 0s 840us/step - loss: 173.8403 - mean_absolute_error: 10.3218\n",
      "Epoch 77/500\n",
      "29/29 [==============================] - 0s 744us/step - loss: 196.9976 - mean_absolute_error: 11.0716\n",
      "Epoch 78/500\n",
      "29/29 [==============================] - 0s 784us/step - loss: 186.7831 - mean_absolute_error: 10.9425\n",
      "Epoch 79/500\n",
      "29/29 [==============================] - 0s 748us/step - loss: 178.2567 - mean_absolute_error: 10.6784\n",
      "Epoch 80/500\n",
      "29/29 [==============================] - 0s 841us/step - loss: 187.2894 - mean_absolute_error: 10.9677\n",
      "Epoch 81/500\n",
      "29/29 [==============================] - 0s 784us/step - loss: 184.3907 - mean_absolute_error: 10.8588\n",
      "Epoch 82/500\n",
      "29/29 [==============================] - 0s 927us/step - loss: 189.9775 - mean_absolute_error: 11.1450\n",
      "Epoch 83/500\n",
      "29/29 [==============================] - 0s 890us/step - loss: 183.4318 - mean_absolute_error: 10.7769\n",
      "Epoch 84/500\n",
      "29/29 [==============================] - 0s 820us/step - loss: 180.5199 - mean_absolute_error: 10.6222\n",
      "Epoch 85/500\n",
      "29/29 [==============================] - 0s 855us/step - loss: 186.6082 - mean_absolute_error: 11.0632\n",
      "Epoch 86/500\n",
      "29/29 [==============================] - 0s 927us/step - loss: 174.7995 - mean_absolute_error: 10.5392\n",
      "Epoch 87/500\n",
      "29/29 [==============================] - 0s 798us/step - loss: 159.4283 - mean_absolute_error: 10.2245\n",
      "Epoch 88/500\n",
      "29/29 [==============================] - 0s 842us/step - loss: 167.9652 - mean_absolute_error: 10.4483\n",
      "Epoch 89/500\n",
      "29/29 [==============================] - 0s 819us/step - loss: 164.2128 - mean_absolute_error: 10.3182\n",
      "Epoch 90/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 172.6834 - mean_absolute_error: 10.5790\n",
      "Epoch 91/500\n",
      "29/29 [==============================] - 0s 855us/step - loss: 190.5403 - mean_absolute_error: 11.1483\n",
      "Epoch 92/500\n",
      "29/29 [==============================] - 0s 819us/step - loss: 174.2667 - mean_absolute_error: 10.4633\n",
      "Epoch 93/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 178.1157 - mean_absolute_error: 10.8694\n",
      "Epoch 94/500\n",
      "29/29 [==============================] - 0s 855us/step - loss: 195.2070 - mean_absolute_error: 11.0997\n",
      "Epoch 95/500\n",
      "29/29 [==============================] - 0s 808us/step - loss: 171.0275 - mean_absolute_error: 10.5133\n",
      "Epoch 96/500\n",
      "29/29 [==============================] - 0s 770us/step - loss: 169.0374 - mean_absolute_error: 10.4083\n",
      "Epoch 97/500\n",
      "29/29 [==============================] - 0s 817us/step - loss: 168.1258 - mean_absolute_error: 10.5073\n",
      "Epoch 98/500\n",
      "29/29 [==============================] - 0s 784us/step - loss: 175.0676 - mean_absolute_error: 10.5934\n",
      "Epoch 99/500\n",
      "29/29 [==============================] - 0s 854us/step - loss: 186.3169 - mean_absolute_error: 10.8822\n",
      "Epoch 100/500\n",
      "29/29 [==============================] - 0s 891us/step - loss: 173.5925 - mean_absolute_error: 10.6106\n",
      "Epoch 101/500\n",
      "29/29 [==============================] - 0s 924us/step - loss: 160.6056 - mean_absolute_error: 10.0845\n",
      "Epoch 102/500\n",
      "29/29 [==============================] - 0s 873us/step - loss: 158.1203 - mean_absolute_error: 9.9698\n",
      "Epoch 103/500\n",
      "29/29 [==============================] - 0s 794us/step - loss: 167.2890 - mean_absolute_error: 10.3256\n",
      "Epoch 104/500\n",
      "29/29 [==============================] - 0s 855us/step - loss: 169.2185 - mean_absolute_error: 10.4745\n",
      "Epoch 105/500\n",
      "29/29 [==============================] - 0s 856us/step - loss: 180.2297 - mean_absolute_error: 10.7312\n",
      "Epoch 106/500\n",
      "29/29 [==============================] - 0s 855us/step - loss: 168.8132 - mean_absolute_error: 10.3724\n",
      "Epoch 107/500\n",
      "29/29 [==============================] - 0s 777us/step - loss: 168.7237 - mean_absolute_error: 10.3693\n",
      "Epoch 108/500\n",
      "29/29 [==============================] - 0s 834us/step - loss: 159.2968 - mean_absolute_error: 10.0209\n",
      "Epoch 109/500\n",
      "29/29 [==============================] - 0s 892us/step - loss: 168.2276 - mean_absolute_error: 10.2868\n",
      "Epoch 110/500\n",
      "29/29 [==============================] - 0s 784us/step - loss: 178.4301 - mean_absolute_error: 10.6518\n",
      "Epoch 111/500\n",
      "29/29 [==============================] - 0s 856us/step - loss: 163.2710 - mean_absolute_error: 10.2286\n",
      "Epoch 112/500\n",
      "29/29 [==============================] - 0s 890us/step - loss: 173.1154 - mean_absolute_error: 10.3278\n",
      "Epoch 113/500\n",
      "29/29 [==============================] - 0s 888us/step - loss: 152.8123 - mean_absolute_error: 9.8746\n",
      "Epoch 114/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 168.5214 - mean_absolute_error: 10.2589\n",
      "Epoch 115/500\n",
      "29/29 [==============================] - 0s 891us/step - loss: 165.4147 - mean_absolute_error: 10.2515\n",
      "Epoch 116/500\n",
      "29/29 [==============================] - 0s 925us/step - loss: 175.0502 - mean_absolute_error: 10.5270\n",
      "Epoch 117/500\n",
      "29/29 [==============================] - 0s 890us/step - loss: 173.3044 - mean_absolute_error: 10.5332\n",
      "Epoch 118/500\n",
      "29/29 [==============================] - 0s 926us/step - loss: 165.7566 - mean_absolute_error: 10.1882\n",
      "Epoch 119/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 148.5239 - mean_absolute_error: 9.7743\n",
      "Epoch 120/500\n",
      "29/29 [==============================] - 0s 973us/step - loss: 156.4039 - mean_absolute_error: 9.6556\n",
      "Epoch 121/500\n",
      "29/29 [==============================] - 0s 819us/step - loss: 164.4989 - mean_absolute_error: 10.0435\n",
      "Epoch 122/500\n",
      "29/29 [==============================] - 0s 713us/step - loss: 145.1958 - mean_absolute_error: 9.5038\n",
      "Epoch 123/500\n",
      "29/29 [==============================] - 0s 842us/step - loss: 144.4888 - mean_absolute_error: 9.4847\n",
      "Epoch 124/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 158.8393 - mean_absolute_error: 9.9723\n",
      "Epoch 125/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 158.6291 - mean_absolute_error: 10.0304\n",
      "Epoch 126/500\n",
      "29/29 [==============================] - 0s 890us/step - loss: 151.5646 - mean_absolute_error: 9.8068\n",
      "Epoch 127/500\n",
      "29/29 [==============================] - 0s 855us/step - loss: 168.7336 - mean_absolute_error: 10.2658\n",
      "Epoch 128/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 163.7894 - mean_absolute_error: 10.1994\n",
      "Epoch 129/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 147.8792 - mean_absolute_error: 9.6778\n",
      "Epoch 130/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 157.4934 - mean_absolute_error: 10.1053\n",
      "Epoch 131/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 143.9889 - mean_absolute_error: 9.4334\n",
      "Epoch 132/500\n",
      "29/29 [==============================] - 0s 963us/step - loss: 165.1928 - mean_absolute_error: 10.2612\n",
      "Epoch 133/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 159.6828 - mean_absolute_error: 9.9342\n",
      "Epoch 134/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 166.0548 - mean_absolute_error: 9.8971\n",
      "Epoch 135/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 155.4784 - mean_absolute_error: 9.6300\n",
      "Epoch 136/500\n",
      "29/29 [==============================] - 0s 926us/step - loss: 163.3692 - mean_absolute_error: 10.2711\n",
      "Epoch 137/500\n",
      "29/29 [==============================] - 0s 855us/step - loss: 148.0443 - mean_absolute_error: 9.5417\n",
      "Epoch 138/500\n",
      "29/29 [==============================] - 0s 749us/step - loss: 169.9962 - mean_absolute_error: 10.5578\n",
      "Epoch 139/500\n",
      "29/29 [==============================] - 0s 854us/step - loss: 157.9098 - mean_absolute_error: 9.8637\n",
      "Epoch 140/500\n",
      "29/29 [==============================] - 0s 855us/step - loss: 163.2960 - mean_absolute_error: 10.1685\n",
      "Epoch 141/500\n",
      "29/29 [==============================] - 0s 784us/step - loss: 129.2855 - mean_absolute_error: 9.1255\n",
      "Epoch 142/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 961us/step - loss: 155.7332 - mean_absolute_error: 9.8064\n",
      "Epoch 143/500\n",
      "29/29 [==============================] - 0s 855us/step - loss: 143.9612 - mean_absolute_error: 9.5718\n",
      "Epoch 144/500\n",
      "29/29 [==============================] - 0s 890us/step - loss: 151.6995 - mean_absolute_error: 9.6989\n",
      "Epoch 145/500\n",
      "29/29 [==============================] - 0s 890us/step - loss: 155.6057 - mean_absolute_error: 9.8136\n",
      "Epoch 146/500\n",
      "29/29 [==============================] - 0s 927us/step - loss: 145.5128 - mean_absolute_error: 9.3956\n",
      "Epoch 147/500\n",
      "29/29 [==============================] - 0s 856us/step - loss: 156.6664 - mean_absolute_error: 9.6566\n",
      "Epoch 148/500\n",
      "29/29 [==============================] - 0s 855us/step - loss: 156.0291 - mean_absolute_error: 9.8278\n",
      "Epoch 149/500\n",
      "29/29 [==============================] - 0s 819us/step - loss: 149.3398 - mean_absolute_error: 9.7590\n",
      "Epoch 150/500\n",
      "29/29 [==============================] - 0s 855us/step - loss: 163.5034 - mean_absolute_error: 10.2000\n",
      "Epoch 151/500\n",
      "29/29 [==============================] - 0s 819us/step - loss: 153.2547 - mean_absolute_error: 9.5787\n",
      "Epoch 152/500\n",
      "29/29 [==============================] - 0s 819us/step - loss: 152.8160 - mean_absolute_error: 9.7234\n",
      "Epoch 153/500\n",
      "29/29 [==============================] - 0s 855us/step - loss: 143.1481 - mean_absolute_error: 9.2700\n",
      "Epoch 154/500\n",
      "29/29 [==============================] - 0s 820us/step - loss: 151.4656 - mean_absolute_error: 9.7295\n",
      "Epoch 155/500\n",
      "29/29 [==============================] - 0s 927us/step - loss: 144.7106 - mean_absolute_error: 9.3741\n",
      "Epoch 156/500\n",
      "29/29 [==============================] - 0s 892us/step - loss: 156.6815 - mean_absolute_error: 9.7239\n",
      "Epoch 157/500\n",
      "29/29 [==============================] - 0s 855us/step - loss: 151.5637 - mean_absolute_error: 9.7104\n",
      "Epoch 158/500\n",
      "29/29 [==============================] - 0s 890us/step - loss: 142.0464 - mean_absolute_error: 9.3184\n",
      "Epoch 159/500\n",
      "29/29 [==============================] - 0s 855us/step - loss: 155.4266 - mean_absolute_error: 9.8975\n",
      "Epoch 160/500\n",
      "29/29 [==============================] - 0s 820us/step - loss: 146.5396 - mean_absolute_error: 9.5933\n",
      "Epoch 161/500\n",
      "29/29 [==============================] - 0s 890us/step - loss: 155.9838 - mean_absolute_error: 9.8092\n",
      "Epoch 162/500\n",
      "29/29 [==============================] - 0s 890us/step - loss: 142.3335 - mean_absolute_error: 9.2311\n",
      "Epoch 163/500\n",
      "29/29 [==============================] - 0s 891us/step - loss: 154.7373 - mean_absolute_error: 9.7297\n",
      "Epoch 164/500\n",
      "29/29 [==============================] - 0s 819us/step - loss: 144.7367 - mean_absolute_error: 9.2874\n",
      "Epoch 165/500\n",
      "29/29 [==============================] - 0s 890us/step - loss: 146.2575 - mean_absolute_error: 9.5977\n",
      "Epoch 166/500\n",
      "29/29 [==============================] - 0s 819us/step - loss: 160.4770 - mean_absolute_error: 9.7734\n",
      "Epoch 167/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 146.5207 - mean_absolute_error: 9.4185\n",
      "Epoch 168/500\n",
      "29/29 [==============================] - 0s 890us/step - loss: 161.6269 - mean_absolute_error: 9.8797\n",
      "Epoch 169/500\n",
      "29/29 [==============================] - 0s 819us/step - loss: 149.4545 - mean_absolute_error: 9.7127\n",
      "Epoch 170/500\n",
      "29/29 [==============================] - 0s 819us/step - loss: 135.0436 - mean_absolute_error: 9.0136\n",
      "Epoch 171/500\n",
      "29/29 [==============================] - 0s 890us/step - loss: 147.6004 - mean_absolute_error: 9.4395\n",
      "Epoch 172/500\n",
      "29/29 [==============================] - 0s 855us/step - loss: 159.0889 - mean_absolute_error: 9.8312\n",
      "Epoch 173/500\n",
      "29/29 [==============================] - 0s 819us/step - loss: 141.5345 - mean_absolute_error: 9.2225\n",
      "Epoch 174/500\n",
      "29/29 [==============================] - 0s 855us/step - loss: 149.0984 - mean_absolute_error: 9.4887\n",
      "Epoch 175/500\n",
      "29/29 [==============================] - 0s 856us/step - loss: 167.1439 - mean_absolute_error: 10.0717\n",
      "Epoch 176/500\n",
      "29/29 [==============================] - 0s 819us/step - loss: 160.6650 - mean_absolute_error: 9.9903\n",
      "Epoch 177/500\n",
      "29/29 [==============================] - 0s 891us/step - loss: 149.0731 - mean_absolute_error: 9.4196\n",
      "Epoch 178/500\n",
      "29/29 [==============================] - 0s 890us/step - loss: 138.8323 - mean_absolute_error: 9.1235\n",
      "Epoch 179/500\n",
      "29/29 [==============================] - 0s 855us/step - loss: 144.3496 - mean_absolute_error: 9.4160\n",
      "Epoch 180/500\n",
      "29/29 [==============================] - 0s 890us/step - loss: 150.5692 - mean_absolute_error: 9.5907\n",
      "Epoch 181/500\n",
      "29/29 [==============================] - 0s 885us/step - loss: 153.0475 - mean_absolute_error: 9.6622\n",
      "Epoch 182/500\n",
      "29/29 [==============================] - 0s 891us/step - loss: 152.0596 - mean_absolute_error: 9.6284\n",
      "Epoch 183/500\n",
      "29/29 [==============================] - 0s 890us/step - loss: 154.3734 - mean_absolute_error: 9.7969\n",
      "Epoch 184/500\n",
      "29/29 [==============================] - 0s 890us/step - loss: 135.3707 - mean_absolute_error: 9.0144\n",
      "Epoch 185/500\n",
      "29/29 [==============================] - 0s 890us/step - loss: 146.1097 - mean_absolute_error: 9.4304\n",
      "Epoch 186/500\n",
      "29/29 [==============================] - 0s 818us/step - loss: 137.4209 - mean_absolute_error: 9.0448\n",
      "Epoch 187/500\n",
      "29/29 [==============================] - 0s 855us/step - loss: 156.5131 - mean_absolute_error: 9.7965\n",
      "Epoch 188/500\n",
      "29/29 [==============================] - 0s 891us/step - loss: 149.9506 - mean_absolute_error: 9.5660\n",
      "Epoch 189/500\n",
      "29/29 [==============================] - 0s 884us/step - loss: 179.2880 - mean_absolute_error: 10.6394\n",
      "Epoch 190/500\n",
      "29/29 [==============================] - 0s 925us/step - loss: 149.4440 - mean_absolute_error: 9.5441\n",
      "Epoch 191/500\n",
      "29/29 [==============================] - 0s 891us/step - loss: 137.5117 - mean_absolute_error: 9.2251\n",
      "Epoch 192/500\n",
      "29/29 [==============================] - 0s 819us/step - loss: 155.5730 - mean_absolute_error: 9.6892\n",
      "Epoch 193/500\n",
      "29/29 [==============================] - 0s 890us/step - loss: 157.2895 - mean_absolute_error: 9.8027\n",
      "Epoch 194/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 153.9454 - mean_absolute_error: 9.9335\n",
      "Epoch 195/500\n",
      "29/29 [==============================] - 0s 927us/step - loss: 146.7181 - mean_absolute_error: 9.7121\n",
      "Epoch 196/500\n",
      "29/29 [==============================] - 0s 856us/step - loss: 155.6539 - mean_absolute_error: 9.7935\n",
      "Epoch 197/500\n",
      "29/29 [==============================] - 0s 855us/step - loss: 148.8061 - mean_absolute_error: 9.4876\n",
      "Epoch 198/500\n",
      "29/29 [==============================] - 0s 926us/step - loss: 150.3679 - mean_absolute_error: 9.5505\n",
      "Epoch 199/500\n",
      "29/29 [==============================] - 0s 856us/step - loss: 153.8424 - mean_absolute_error: 9.6340\n",
      "Epoch 200/500\n",
      "29/29 [==============================] - 0s 821us/step - loss: 152.9406 - mean_absolute_error: 9.6554\n",
      "Epoch 201/500\n",
      "29/29 [==============================] - 0s 891us/step - loss: 139.1387 - mean_absolute_error: 9.2265\n",
      "Epoch 202/500\n",
      "29/29 [==============================] - 0s 890us/step - loss: 151.4457 - mean_absolute_error: 9.6834\n",
      "Epoch 203/500\n",
      "29/29 [==============================] - 0s 860us/step - loss: 154.7330 - mean_absolute_error: 9.4892\n",
      "Epoch 204/500\n",
      "29/29 [==============================] - 0s 855us/step - loss: 148.8547 - mean_absolute_error: 9.6512\n",
      "Epoch 205/500\n",
      "29/29 [==============================] - 0s 855us/step - loss: 130.3850 - mean_absolute_error: 8.8721\n",
      "Epoch 206/500\n",
      "29/29 [==============================] - 0s 890us/step - loss: 142.1358 - mean_absolute_error: 9.2412\n",
      "Epoch 207/500\n",
      "29/29 [==============================] - 0s 890us/step - loss: 149.9173 - mean_absolute_error: 9.7584\n",
      "Epoch 208/500\n",
      "29/29 [==============================] - 0s 927us/step - loss: 141.2144 - mean_absolute_error: 9.4101\n",
      "Epoch 209/500\n",
      "29/29 [==============================] - 0s 963us/step - loss: 163.4986 - mean_absolute_error: 9.8302\n",
      "Epoch 210/500\n",
      "29/29 [==============================] - 0s 926us/step - loss: 150.5397 - mean_absolute_error: 9.3951\n",
      "Epoch 211/500\n",
      "29/29 [==============================] - 0s 819us/step - loss: 145.6151 - mean_absolute_error: 9.3998\n",
      "Epoch 212/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 819us/step - loss: 148.7654 - mean_absolute_error: 9.4661\n",
      "Epoch 213/500\n",
      "29/29 [==============================] - 0s 926us/step - loss: 161.9516 - mean_absolute_error: 10.0758\n",
      "Epoch 214/500\n",
      "29/29 [==============================] - 0s 890us/step - loss: 142.4305 - mean_absolute_error: 9.3991\n",
      "Epoch 215/500\n",
      "29/29 [==============================] - 0s 855us/step - loss: 156.3183 - mean_absolute_error: 9.8573\n",
      "Epoch 216/500\n",
      "29/29 [==============================] - 0s 819us/step - loss: 142.3759 - mean_absolute_error: 9.2629\n",
      "Epoch 217/500\n",
      "29/29 [==============================] - 0s 906us/step - loss: 149.1577 - mean_absolute_error: 9.2571\n",
      "Epoch 218/500\n",
      "29/29 [==============================] - 0s 896us/step - loss: 148.1407 - mean_absolute_error: 9.3082\n",
      "Epoch 219/500\n",
      "29/29 [==============================] - 0s 819us/step - loss: 160.0575 - mean_absolute_error: 9.9384\n",
      "Epoch 220/500\n",
      "29/29 [==============================] - 0s 890us/step - loss: 146.3275 - mean_absolute_error: 9.3887\n",
      "Epoch 221/500\n",
      "29/29 [==============================] - 0s 855us/step - loss: 151.9322 - mean_absolute_error: 9.7755\n",
      "Epoch 222/500\n",
      "29/29 [==============================] - 0s 749us/step - loss: 152.5624 - mean_absolute_error: 9.5781\n",
      "Epoch 223/500\n",
      "29/29 [==============================] - 0s 855us/step - loss: 143.6367 - mean_absolute_error: 9.3951\n",
      "Epoch 224/500\n",
      "29/29 [==============================] - 0s 819us/step - loss: 142.5582 - mean_absolute_error: 9.3690\n",
      "Epoch 225/500\n",
      "29/29 [==============================] - 0s 890us/step - loss: 137.4862 - mean_absolute_error: 9.2247\n",
      "Epoch 226/500\n",
      "29/29 [==============================] - 0s 926us/step - loss: 155.7038 - mean_absolute_error: 9.8652\n",
      "Epoch 227/500\n",
      "29/29 [==============================] - 0s 855us/step - loss: 137.0266 - mean_absolute_error: 9.1155\n",
      "Epoch 228/500\n",
      "29/29 [==============================] - 0s 819us/step - loss: 158.3066 - mean_absolute_error: 9.8626\n",
      "Epoch 229/500\n",
      "29/29 [==============================] - 0s 885us/step - loss: 153.7287 - mean_absolute_error: 9.5925\n",
      "Epoch 230/500\n",
      "29/29 [==============================] - 0s 927us/step - loss: 144.4365 - mean_absolute_error: 9.5891\n",
      "Epoch 231/500\n",
      "29/29 [==============================] - 0s 854us/step - loss: 151.0757 - mean_absolute_error: 9.6601\n",
      "Epoch 232/500\n",
      "29/29 [==============================] - 0s 855us/step - loss: 150.9962 - mean_absolute_error: 9.3761\n",
      "Epoch 233/500\n",
      "29/29 [==============================] - 0s 783us/step - loss: 127.6245 - mean_absolute_error: 8.7224\n",
      "Epoch 234/500\n",
      "29/29 [==============================] - 0s 855us/step - loss: 145.4597 - mean_absolute_error: 9.7009\n",
      "Epoch 235/500\n",
      "29/29 [==============================] - 0s 890us/step - loss: 147.7210 - mean_absolute_error: 9.7613\n",
      "Epoch 236/500\n",
      "29/29 [==============================] - 0s 889us/step - loss: 150.6569 - mean_absolute_error: 9.6724\n",
      "Epoch 237/500\n",
      "29/29 [==============================] - 0s 867us/step - loss: 141.3666 - mean_absolute_error: 9.4556\n",
      "Epoch 238/500\n",
      "29/29 [==============================] - 0s 877us/step - loss: 171.3052 - mean_absolute_error: 10.1477\n",
      "Epoch 239/500\n",
      "29/29 [==============================] - 0s 891us/step - loss: 145.6969 - mean_absolute_error: 9.5709\n",
      "Epoch 240/500\n",
      "29/29 [==============================] - 0s 891us/step - loss: 149.2376 - mean_absolute_error: 9.6390\n",
      "Epoch 241/500\n",
      "29/29 [==============================] - 0s 926us/step - loss: 142.1202 - mean_absolute_error: 9.2914\n",
      "Epoch 242/500\n",
      "29/29 [==============================] - 0s 856us/step - loss: 149.4751 - mean_absolute_error: 9.7790\n",
      "Epoch 243/500\n",
      "29/29 [==============================] - 0s 854us/step - loss: 129.9362 - mean_absolute_error: 8.7799\n",
      "Epoch 244/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 146.6506 - mean_absolute_error: 9.3425\n",
      "Epoch 245/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 138.2997 - mean_absolute_error: 9.1257\n",
      "Epoch 246/500\n",
      "29/29 [==============================] - 0s 887us/step - loss: 155.0269 - mean_absolute_error: 9.7648\n",
      "Epoch 247/500\n",
      "29/29 [==============================] - 0s 890us/step - loss: 152.1427 - mean_absolute_error: 9.7974\n",
      "Epoch 248/500\n",
      "29/29 [==============================] - 0s 855us/step - loss: 144.5029 - mean_absolute_error: 9.3758\n",
      "Epoch 249/500\n",
      "29/29 [==============================] - 0s 961us/step - loss: 139.7187 - mean_absolute_error: 9.4192\n",
      "Epoch 250/500\n",
      "29/29 [==============================] - 0s 855us/step - loss: 152.1073 - mean_absolute_error: 9.5366\n",
      "Epoch 251/500\n",
      "29/29 [==============================] - 0s 998us/step - loss: 149.2552 - mean_absolute_error: 9.5130\n",
      "Epoch 252/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 142.7812 - mean_absolute_error: 9.3221\n",
      "Epoch 253/500\n",
      "29/29 [==============================] - 0s 863us/step - loss: 139.3167 - mean_absolute_error: 9.2180\n",
      "Epoch 254/500\n",
      "29/29 [==============================] - 0s 890us/step - loss: 154.5368 - mean_absolute_error: 9.8093\n",
      "Epoch 255/500\n",
      "29/29 [==============================] - 0s 855us/step - loss: 150.8423 - mean_absolute_error: 9.3124\n",
      "Epoch 256/500\n",
      "29/29 [==============================] - 0s 865us/step - loss: 162.8583 - mean_absolute_error: 9.9709\n",
      "Epoch 257/500\n",
      "29/29 [==============================] - 0s 890us/step - loss: 156.1436 - mean_absolute_error: 9.7885\n",
      "Epoch 258/500\n",
      "29/29 [==============================] - 0s 834us/step - loss: 121.4258 - mean_absolute_error: 8.6570\n",
      "Epoch 259/500\n",
      "29/29 [==============================] - 0s 819us/step - loss: 119.2535 - mean_absolute_error: 8.6481\n",
      "Epoch 260/500\n",
      "29/29 [==============================] - 0s 926us/step - loss: 140.8948 - mean_absolute_error: 9.3989\n",
      "Epoch 261/500\n",
      "29/29 [==============================] - 0s 819us/step - loss: 147.0826 - mean_absolute_error: 9.2381\n",
      "Epoch 262/500\n",
      "29/29 [==============================] - 0s 855us/step - loss: 151.3040 - mean_absolute_error: 9.5513\n",
      "Epoch 263/500\n",
      "29/29 [==============================] - 0s 985us/step - loss: 137.3186 - mean_absolute_error: 9.2885\n",
      "Epoch 264/500\n",
      "29/29 [==============================] - 0s 926us/step - loss: 140.6805 - mean_absolute_error: 9.2020\n",
      "Epoch 265/500\n",
      "29/29 [==============================] - 0s 855us/step - loss: 151.7779 - mean_absolute_error: 9.7620\n",
      "Epoch 266/500\n",
      "29/29 [==============================] - 0s 861us/step - loss: 143.4843 - mean_absolute_error: 9.4309\n",
      "Epoch 267/500\n",
      "29/29 [==============================] - 0s 890us/step - loss: 146.2409 - mean_absolute_error: 9.4655\n",
      "Epoch 268/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 147.2720 - mean_absolute_error: 9.4600\n",
      "Epoch 269/500\n",
      "29/29 [==============================] - 0s 855us/step - loss: 155.6444 - mean_absolute_error: 9.7149\n",
      "Epoch 270/500\n",
      "29/29 [==============================] - 0s 892us/step - loss: 136.6553 - mean_absolute_error: 9.1056\n",
      "Epoch 271/500\n",
      "29/29 [==============================] - 0s 870us/step - loss: 139.0250 - mean_absolute_error: 9.1671\n",
      "Epoch 272/500\n",
      "29/29 [==============================] - 0s 891us/step - loss: 140.5395 - mean_absolute_error: 9.2639\n",
      "Epoch 273/500\n",
      "29/29 [==============================] - 0s 915us/step - loss: 147.9627 - mean_absolute_error: 9.5336\n",
      "Epoch 274/500\n",
      "29/29 [==============================] - 0s 890us/step - loss: 145.2781 - mean_absolute_error: 9.4253\n",
      "Epoch 275/500\n",
      "29/29 [==============================] - 0s 926us/step - loss: 127.6741 - mean_absolute_error: 8.7721\n",
      "Epoch 276/500\n",
      "29/29 [==============================] - 0s 998us/step - loss: 132.8104 - mean_absolute_error: 9.0999\n",
      "Epoch 277/500\n",
      "29/29 [==============================] - 0s 890us/step - loss: 147.1255 - mean_absolute_error: 9.6804\n",
      "Epoch 278/500\n",
      "29/29 [==============================] - 0s 926us/step - loss: 144.8716 - mean_absolute_error: 9.4084\n",
      "Epoch 279/500\n",
      "29/29 [==============================] - 0s 890us/step - loss: 133.8680 - mean_absolute_error: 8.9942\n",
      "Epoch 280/500\n",
      "29/29 [==============================] - 0s 855us/step - loss: 138.3204 - mean_absolute_error: 8.9931\n",
      "Epoch 281/500\n",
      "29/29 [==============================] - 0s 853us/step - loss: 137.7467 - mean_absolute_error: 9.2593\n",
      "Epoch 282/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 891us/step - loss: 160.8094 - mean_absolute_error: 10.0019\n",
      "Epoch 283/500\n",
      "29/29 [==============================] - 0s 890us/step - loss: 127.7323 - mean_absolute_error: 8.8337\n",
      "Epoch 284/500\n",
      "29/29 [==============================] - 0s 948us/step - loss: 149.5750 - mean_absolute_error: 9.7272\n",
      "Epoch 285/500\n",
      "29/29 [==============================] - 0s 855us/step - loss: 146.9843 - mean_absolute_error: 9.5304\n",
      "Epoch 286/500\n",
      "29/29 [==============================] - 0s 926us/step - loss: 135.4056 - mean_absolute_error: 9.1246\n",
      "Epoch 287/500\n",
      "29/29 [==============================] - 0s 890us/step - loss: 142.9948 - mean_absolute_error: 9.2323\n",
      "Epoch 288/500\n",
      "29/29 [==============================] - 0s 856us/step - loss: 158.7943 - mean_absolute_error: 9.8624\n",
      "Epoch 289/500\n",
      "29/29 [==============================] - 0s 819us/step - loss: 149.4359 - mean_absolute_error: 9.5923\n",
      "Epoch 290/500\n",
      "29/29 [==============================] - 0s 855us/step - loss: 149.9439 - mean_absolute_error: 9.4506\n",
      "Epoch 291/500\n",
      "29/29 [==============================] - 0s 855us/step - loss: 157.2851 - mean_absolute_error: 9.8861\n",
      "Epoch 292/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 141.4214 - mean_absolute_error: 9.3378\n",
      "Epoch 293/500\n",
      "29/29 [==============================] - 0s 926us/step - loss: 141.1562 - mean_absolute_error: 9.4938\n",
      "Epoch 294/500\n",
      "29/29 [==============================] - 0s 819us/step - loss: 136.3868 - mean_absolute_error: 9.1350\n",
      "Epoch 295/500\n",
      "29/29 [==============================] - 0s 855us/step - loss: 144.3160 - mean_absolute_error: 9.3225\n",
      "Epoch 296/500\n",
      "29/29 [==============================] - 0s 890us/step - loss: 129.8404 - mean_absolute_error: 8.8662\n",
      "Epoch 297/500\n",
      "29/29 [==============================] - 0s 927us/step - loss: 154.4275 - mean_absolute_error: 9.8138\n",
      "Epoch 298/500\n",
      "29/29 [==============================] - 0s 890us/step - loss: 145.5735 - mean_absolute_error: 9.4716\n",
      "Epoch 299/500\n",
      "29/29 [==============================] - 0s 820us/step - loss: 147.7662 - mean_absolute_error: 9.4599\n",
      "Epoch 300/500\n",
      "29/29 [==============================] - 0s 819us/step - loss: 137.1064 - mean_absolute_error: 9.0026\n",
      "Epoch 301/500\n",
      "29/29 [==============================] - 0s 892us/step - loss: 137.3060 - mean_absolute_error: 9.3973\n",
      "Epoch 302/500\n",
      "29/29 [==============================] - 0s 854us/step - loss: 145.1976 - mean_absolute_error: 9.3485\n",
      "Epoch 303/500\n",
      "29/29 [==============================] - 0s 855us/step - loss: 142.4271 - mean_absolute_error: 9.3052\n",
      "Epoch 304/500\n",
      "29/29 [==============================] - 0s 961us/step - loss: 151.3240 - mean_absolute_error: 9.8200\n",
      "Epoch 305/500\n",
      "29/29 [==============================] - 0s 817us/step - loss: 132.4750 - mean_absolute_error: 9.1158\n",
      "Epoch 306/500\n",
      "29/29 [==============================] - 0s 889us/step - loss: 137.6503 - mean_absolute_error: 9.1135\n",
      "Epoch 307/500\n",
      "29/29 [==============================] - 0s 855us/step - loss: 126.9131 - mean_absolute_error: 8.6950\n",
      "Epoch 308/500\n",
      "29/29 [==============================] - 0s 926us/step - loss: 148.3550 - mean_absolute_error: 9.4238\n",
      "Epoch 309/500\n",
      "29/29 [==============================] - 0s 855us/step - loss: 146.6825 - mean_absolute_error: 9.5076\n",
      "Epoch 310/500\n",
      "29/29 [==============================] - 0s 927us/step - loss: 147.4979 - mean_absolute_error: 9.4958\n",
      "Epoch 311/500\n",
      "29/29 [==============================] - 0s 819us/step - loss: 141.3393 - mean_absolute_error: 9.3256\n",
      "Epoch 312/500\n",
      "29/29 [==============================] - 0s 925us/step - loss: 152.1849 - mean_absolute_error: 9.5396\n",
      "Epoch 313/500\n",
      "29/29 [==============================] - 0s 996us/step - loss: 152.2282 - mean_absolute_error: 9.7225\n",
      "Epoch 314/500\n",
      "29/29 [==============================] - 0s 891us/step - loss: 138.7135 - mean_absolute_error: 9.2634\n",
      "Epoch 315/500\n",
      "29/29 [==============================] - 0s 856us/step - loss: 132.0356 - mean_absolute_error: 8.9103\n",
      "Epoch 316/500\n",
      "29/29 [==============================] - 0s 891us/step - loss: 163.0625 - mean_absolute_error: 9.8251\n",
      "Epoch 317/500\n",
      "29/29 [==============================] - 0s 884us/step - loss: 146.6363 - mean_absolute_error: 9.4325\n",
      "Epoch 318/500\n",
      "29/29 [==============================] - 0s 881us/step - loss: 154.7421 - mean_absolute_error: 9.6336\n",
      "Epoch 319/500\n",
      "29/29 [==============================] - 0s 856us/step - loss: 133.0549 - mean_absolute_error: 8.8183\n",
      "Epoch 320/500\n",
      "29/29 [==============================] - 0s 890us/step - loss: 150.9042 - mean_absolute_error: 9.5223\n",
      "Epoch 321/500\n",
      "29/29 [==============================] - 0s 876us/step - loss: 147.9826 - mean_absolute_error: 9.4519\n",
      "Epoch 322/500\n",
      "29/29 [==============================] - 0s 907us/step - loss: 148.0672 - mean_absolute_error: 9.3465\n",
      "Epoch 323/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 145.2244 - mean_absolute_error: 9.4373\n",
      "Epoch 324/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 151.8476 - mean_absolute_error: 9.4956\n",
      "Epoch 325/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 134.2278 - mean_absolute_error: 9.0173\n",
      "Epoch 326/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 136.2899 - mean_absolute_error: 9.0205\n",
      "Epoch 327/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 145.2261 - mean_absolute_error: 9.4505\n",
      "Epoch 328/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 139.6845 - mean_absolute_error: 9.2853\n",
      "Epoch 329/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 157.1768 - mean_absolute_error: 9.7288\n",
      "Epoch 330/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 148.0597 - mean_absolute_error: 9.5830\n",
      "Epoch 331/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 141.6397 - mean_absolute_error: 9.4000\n",
      "Epoch 332/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 147.9113 - mean_absolute_error: 9.2472\n",
      "Epoch 333/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 141.2357 - mean_absolute_error: 9.4076\n",
      "Epoch 334/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 160.3670 - mean_absolute_error: 9.8438\n",
      "Epoch 335/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 148.7974 - mean_absolute_error: 9.6689\n",
      "Epoch 336/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 138.5131 - mean_absolute_error: 9.3080\n",
      "Epoch 337/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 132.6616 - mean_absolute_error: 9.1503\n",
      "Epoch 338/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 146.4571 - mean_absolute_error: 9.5357\n",
      "Epoch 339/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 146.4849 - mean_absolute_error: 9.6830\n",
      "Epoch 340/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 137.8922 - mean_absolute_error: 9.3304\n",
      "Epoch 341/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 141.0365 - mean_absolute_error: 9.2817\n",
      "Epoch 342/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 134.7217 - mean_absolute_error: 8.9034\n",
      "Epoch 343/500\n",
      "29/29 [==============================] - 0s 961us/step - loss: 139.0865 - mean_absolute_error: 9.4162\n",
      "Epoch 344/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 134.4965 - mean_absolute_error: 9.0886\n",
      "Epoch 345/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 136.7856 - mean_absolute_error: 9.4034\n",
      "Epoch 346/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 144.4379 - mean_absolute_error: 9.3925\n",
      "Epoch 347/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 156.1984 - mean_absolute_error: 9.8004\n",
      "Epoch 348/500\n",
      "29/29 [==============================] - 0s 926us/step - loss: 126.0511 - mean_absolute_error: 8.7469\n",
      "Epoch 349/500\n",
      "29/29 [==============================] - 0s 890us/step - loss: 134.8986 - mean_absolute_error: 8.9902\n",
      "Epoch 350/500\n",
      "29/29 [==============================] - 0s 961us/step - loss: 162.0992 - mean_absolute_error: 9.9218\n",
      "Epoch 351/500\n",
      "29/29 [==============================] - 0s 819us/step - loss: 122.2516 - mean_absolute_error: 8.6955\n",
      "Epoch 352/500\n",
      "29/29 [==============================] - 0s 961us/step - loss: 129.8449 - mean_absolute_error: 8.9646\n",
      "Epoch 353/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 997us/step - loss: 139.7194 - mean_absolute_error: 9.2079\n",
      "Epoch 354/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 150.1715 - mean_absolute_error: 9.4752\n",
      "Epoch 355/500\n",
      "29/29 [==============================] - 0s 890us/step - loss: 124.1142 - mean_absolute_error: 8.7405\n",
      "Epoch 356/500\n",
      "29/29 [==============================] - 0s 926us/step - loss: 144.8038 - mean_absolute_error: 9.4692\n",
      "Epoch 357/500\n",
      "29/29 [==============================] - 0s 855us/step - loss: 148.2777 - mean_absolute_error: 9.6175\n",
      "Epoch 358/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 141.9351 - mean_absolute_error: 9.1153\n",
      "Epoch 359/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 151.4787 - mean_absolute_error: 9.4953\n",
      "Epoch 360/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 135.3799 - mean_absolute_error: 9.1929\n",
      "Epoch 361/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 138.8728 - mean_absolute_error: 9.2039\n",
      "Epoch 362/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 137.6101 - mean_absolute_error: 9.3877\n",
      "Epoch 363/500\n",
      "29/29 [==============================] - 0s 819us/step - loss: 130.8462 - mean_absolute_error: 8.8620\n",
      "Epoch 364/500\n",
      "29/29 [==============================] - 0s 783us/step - loss: 135.6273 - mean_absolute_error: 9.2229\n",
      "Epoch 365/500\n",
      "29/29 [==============================] - 0s 890us/step - loss: 153.7400 - mean_absolute_error: 9.6067\n",
      "Epoch 366/500\n",
      "29/29 [==============================] - 0s 891us/step - loss: 136.4256 - mean_absolute_error: 9.2573\n",
      "Epoch 367/500\n",
      "29/29 [==============================] - 0s 926us/step - loss: 143.1412 - mean_absolute_error: 9.2894\n",
      "Epoch 368/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 139.3687 - mean_absolute_error: 9.4352\n",
      "Epoch 369/500\n",
      "29/29 [==============================] - 0s 855us/step - loss: 139.0452 - mean_absolute_error: 9.0875\n",
      "Epoch 370/500\n",
      "29/29 [==============================] - 0s 820us/step - loss: 148.3048 - mean_absolute_error: 9.5739\n",
      "Epoch 371/500\n",
      "29/29 [==============================] - 0s 890us/step - loss: 119.1774 - mean_absolute_error: 8.5554\n",
      "Epoch 372/500\n",
      "29/29 [==============================] - 0s 819us/step - loss: 145.4116 - mean_absolute_error: 9.2704\n",
      "Epoch 373/500\n",
      "29/29 [==============================] - 0s 767us/step - loss: 158.3541 - mean_absolute_error: 9.9280\n",
      "Epoch 374/500\n",
      "29/29 [==============================] - 0s 890us/step - loss: 144.2834 - mean_absolute_error: 9.4558\n",
      "Epoch 375/500\n",
      "29/29 [==============================] - 0s 749us/step - loss: 142.8928 - mean_absolute_error: 9.4585\n",
      "Epoch 376/500\n",
      "29/29 [==============================] - 0s 961us/step - loss: 154.9272 - mean_absolute_error: 9.6763\n",
      "Epoch 377/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 156.9843 - mean_absolute_error: 9.9084\n",
      "Epoch 378/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 131.2447 - mean_absolute_error: 8.7034\n",
      "Epoch 379/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 134.5708 - mean_absolute_error: 9.0574\n",
      "Epoch 380/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 144.5681 - mean_absolute_error: 9.2500\n",
      "Epoch 381/500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 142.3308 - mean_absolute_error: 9.2462\n",
      "Epoch 382/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 133.8802 - mean_absolute_error: 9.1716\n",
      "Epoch 383/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 141.1437 - mean_absolute_error: 9.1463\n",
      "Epoch 384/500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 137.0160 - mean_absolute_error: 9.2341\n",
      "Epoch 385/500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 142.2378 - mean_absolute_error: 9.3088\n",
      "Epoch 386/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 140.2589 - mean_absolute_error: 9.3113\n",
      "Epoch 387/500\n",
      "29/29 [==============================] - 0s 926us/step - loss: 153.0607 - mean_absolute_error: 9.6302\n",
      "Epoch 388/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 138.8348 - mean_absolute_error: 9.2079\n",
      "Epoch 389/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 147.9553 - mean_absolute_error: 9.4502\n",
      "Epoch 390/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 153.9176 - mean_absolute_error: 9.8031\n",
      "Epoch 391/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 162.0741 - mean_absolute_error: 9.9616\n",
      "Epoch 392/500\n",
      "29/29 [==============================] - 0s 891us/step - loss: 133.1292 - mean_absolute_error: 8.7961\n",
      "Epoch 393/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 149.4785 - mean_absolute_error: 9.4789\n",
      "Epoch 394/500\n",
      "29/29 [==============================] - 0s 926us/step - loss: 147.5451 - mean_absolute_error: 9.3511\n",
      "Epoch 395/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 130.1436 - mean_absolute_error: 9.1210\n",
      "Epoch 396/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 144.4594 - mean_absolute_error: 9.2975\n",
      "Epoch 397/500\n",
      "29/29 [==============================] - 0s 819us/step - loss: 140.1725 - mean_absolute_error: 9.3182\n",
      "Epoch 398/500\n",
      "29/29 [==============================] - 0s 890us/step - loss: 149.9833 - mean_absolute_error: 9.4926\n",
      "Epoch 399/500\n",
      "29/29 [==============================] - 0s 855us/step - loss: 150.5137 - mean_absolute_error: 9.7027\n",
      "Epoch 400/500\n",
      "29/29 [==============================] - 0s 819us/step - loss: 135.0660 - mean_absolute_error: 9.0911\n",
      "Epoch 401/500\n",
      "29/29 [==============================] - 0s 784us/step - loss: 137.6174 - mean_absolute_error: 9.3324\n",
      "Epoch 402/500\n",
      "29/29 [==============================] - 0s 890us/step - loss: 147.8121 - mean_absolute_error: 9.6009\n",
      "Epoch 403/500\n",
      "29/29 [==============================] - 0s 925us/step - loss: 137.7590 - mean_absolute_error: 9.0970\n",
      "Epoch 404/500\n",
      "29/29 [==============================] - 0s 963us/step - loss: 151.0550 - mean_absolute_error: 9.7982\n",
      "Epoch 405/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 149.7686 - mean_absolute_error: 9.5915\n",
      "Epoch 406/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 141.3475 - mean_absolute_error: 9.2984\n",
      "Epoch 407/500\n",
      "29/29 [==============================] - 0s 891us/step - loss: 133.1558 - mean_absolute_error: 8.9903\n",
      "Epoch 408/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 131.1494 - mean_absolute_error: 8.8559\n",
      "Epoch 409/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 149.7592 - mean_absolute_error: 9.6047\n",
      "Epoch 410/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 138.6661 - mean_absolute_error: 9.4788\n",
      "Epoch 411/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 123.3409 - mean_absolute_error: 8.8163\n",
      "Epoch 412/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 131.7817 - mean_absolute_error: 9.1230\n",
      "Epoch 413/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 139.0167 - mean_absolute_error: 9.1669\n",
      "Epoch 414/500\n",
      "29/29 [==============================] - 0s 963us/step - loss: 141.0455 - mean_absolute_error: 9.1914\n",
      "Epoch 415/500\n",
      "29/29 [==============================] - 0s 963us/step - loss: 133.3936 - mean_absolute_error: 9.1195\n",
      "Epoch 416/500\n",
      "29/29 [==============================] - 0s 998us/step - loss: 134.9980 - mean_absolute_error: 9.1890\n",
      "Epoch 417/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 130.2501 - mean_absolute_error: 8.9059\n",
      "Epoch 418/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 146.2580 - mean_absolute_error: 9.5380\n",
      "Epoch 419/500\n",
      "29/29 [==============================] - 0s 926us/step - loss: 130.3255 - mean_absolute_error: 9.0853\n",
      "Epoch 420/500\n",
      "29/29 [==============================] - 0s 855us/step - loss: 135.8047 - mean_absolute_error: 9.1426\n",
      "Epoch 421/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 134.1827 - mean_absolute_error: 9.1639\n",
      "Epoch 422/500\n",
      "29/29 [==============================] - 0s 961us/step - loss: 145.4576 - mean_absolute_error: 9.5510\n",
      "Epoch 423/500\n",
      "29/29 [==============================] - 0s 926us/step - loss: 137.6431 - mean_absolute_error: 9.0632\n",
      "Epoch 424/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 961us/step - loss: 138.7788 - mean_absolute_error: 9.2184\n",
      "Epoch 425/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 134.7216 - mean_absolute_error: 9.1325\n",
      "Epoch 426/500\n",
      "29/29 [==============================] - 0s 996us/step - loss: 150.1209 - mean_absolute_error: 9.5547\n",
      "Epoch 427/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 137.6157 - mean_absolute_error: 9.1455\n",
      "Epoch 428/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 173.8473 - mean_absolute_error: 10.1684\n",
      "Epoch 429/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 152.8088 - mean_absolute_error: 9.7427\n",
      "Epoch 430/500\n",
      "29/29 [==============================] - 0s 996us/step - loss: 146.6423 - mean_absolute_error: 9.3798\n",
      "Epoch 431/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 142.5208 - mean_absolute_error: 9.1944\n",
      "Epoch 432/500\n",
      "29/29 [==============================] - 0s 961us/step - loss: 150.4960 - mean_absolute_error: 9.2626\n",
      "Epoch 433/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 144.0936 - mean_absolute_error: 9.3106\n",
      "Epoch 434/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 137.8321 - mean_absolute_error: 9.1951\n",
      "Epoch 435/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 134.2660 - mean_absolute_error: 9.0327\n",
      "Epoch 436/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 145.6361 - mean_absolute_error: 9.3570\n",
      "Epoch 437/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 137.2032 - mean_absolute_error: 8.9717\n",
      "Epoch 438/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 156.4715 - mean_absolute_error: 9.7784\n",
      "Epoch 439/500\n",
      "29/29 [==============================] - 0s 891us/step - loss: 144.5375 - mean_absolute_error: 9.4649\n",
      "Epoch 440/500\n",
      "29/29 [==============================] - 0s 804us/step - loss: 146.0480 - mean_absolute_error: 9.6603\n",
      "Epoch 441/500\n",
      "29/29 [==============================] - 0s 926us/step - loss: 132.7442 - mean_absolute_error: 9.0083\n",
      "Epoch 442/500\n",
      "29/29 [==============================] - 0s 820us/step - loss: 150.3158 - mean_absolute_error: 9.4876\n",
      "Epoch 443/500\n",
      "29/29 [==============================] - 0s 784us/step - loss: 130.5726 - mean_absolute_error: 8.9686\n",
      "Epoch 444/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 135.8817 - mean_absolute_error: 9.0160\n",
      "Epoch 445/500\n",
      "29/29 [==============================] - 0s 963us/step - loss: 130.0740 - mean_absolute_error: 8.9677\n",
      "Epoch 446/500\n",
      "29/29 [==============================] - 0s 855us/step - loss: 138.6381 - mean_absolute_error: 9.1724\n",
      "Epoch 447/500\n",
      "29/29 [==============================] - 0s 712us/step - loss: 147.4794 - mean_absolute_error: 9.4733\n",
      "Epoch 448/500\n",
      "29/29 [==============================] - 0s 926us/step - loss: 151.1042 - mean_absolute_error: 9.7416\n",
      "Epoch 449/500\n",
      "29/29 [==============================] - 0s 926us/step - loss: 155.9441 - mean_absolute_error: 9.6901\n",
      "Epoch 450/500\n",
      "29/29 [==============================] - 0s 784us/step - loss: 139.4680 - mean_absolute_error: 9.5808\n",
      "Epoch 451/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 137.4489 - mean_absolute_error: 9.2536\n",
      "Epoch 452/500\n",
      "29/29 [==============================] - 0s 926us/step - loss: 138.8123 - mean_absolute_error: 9.3335\n",
      "Epoch 453/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 139.9289 - mean_absolute_error: 9.3180\n",
      "Epoch 454/500\n",
      "29/29 [==============================] - 0s 926us/step - loss: 144.9177 - mean_absolute_error: 9.2650\n",
      "Epoch 455/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 144.6182 - mean_absolute_error: 9.2990\n",
      "Epoch 456/500\n",
      "29/29 [==============================] - 0s 748us/step - loss: 137.0715 - mean_absolute_error: 9.0487\n",
      "Epoch 457/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 137.1573 - mean_absolute_error: 9.1367\n",
      "Epoch 458/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 134.8764 - mean_absolute_error: 9.1451\n",
      "Epoch 459/500\n",
      "29/29 [==============================] - 0s 998us/step - loss: 144.3630 - mean_absolute_error: 9.6104\n",
      "Epoch 460/500\n",
      "29/29 [==============================] - 0s 927us/step - loss: 129.3137 - mean_absolute_error: 9.0756\n",
      "Epoch 461/500\n",
      "29/29 [==============================] - 0s 926us/step - loss: 152.9984 - mean_absolute_error: 9.6463\n",
      "Epoch 462/500\n",
      "29/29 [==============================] - 0s 963us/step - loss: 146.3448 - mean_absolute_error: 9.3250\n",
      "Epoch 463/500\n",
      "29/29 [==============================] - 0s 926us/step - loss: 155.4495 - mean_absolute_error: 9.8584\n",
      "Epoch 464/500\n",
      "29/29 [==============================] - 0s 926us/step - loss: 137.3540 - mean_absolute_error: 9.1953\n",
      "Epoch 465/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 132.8012 - mean_absolute_error: 9.1723\n",
      "Epoch 466/500\n",
      "29/29 [==============================] - 0s 998us/step - loss: 149.4801 - mean_absolute_error: 9.6492\n",
      "Epoch 467/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 150.7707 - mean_absolute_error: 9.5535\n",
      "Epoch 468/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 136.6534 - mean_absolute_error: 9.1036\n",
      "Epoch 469/500\n",
      "29/29 [==============================] - 0s 975us/step - loss: 130.2617 - mean_absolute_error: 8.9850\n",
      "Epoch 470/500\n",
      "29/29 [==============================] - 0s 998us/step - loss: 144.5286 - mean_absolute_error: 9.4991\n",
      "Epoch 471/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 127.6374 - mean_absolute_error: 8.8652\n",
      "Epoch 472/500\n",
      "29/29 [==============================] - 0s 925us/step - loss: 137.2768 - mean_absolute_error: 9.1297\n",
      "Epoch 473/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 139.4786 - mean_absolute_error: 9.3336\n",
      "Epoch 474/500\n",
      "29/29 [==============================] - 0s 998us/step - loss: 136.2994 - mean_absolute_error: 9.0465\n",
      "Epoch 475/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 139.6373 - mean_absolute_error: 9.1155\n",
      "Epoch 476/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 138.4400 - mean_absolute_error: 9.1929\n",
      "Epoch 477/500\n",
      "29/29 [==============================] - 0s 927us/step - loss: 139.8157 - mean_absolute_error: 9.3766\n",
      "Epoch 478/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 144.8219 - mean_absolute_error: 9.5393\n",
      "Epoch 479/500\n",
      "29/29 [==============================] - 0s 820us/step - loss: 145.5093 - mean_absolute_error: 9.2253\n",
      "Epoch 480/500\n",
      "29/29 [==============================] - 0s 892us/step - loss: 140.0185 - mean_absolute_error: 9.2147\n",
      "Epoch 481/500\n",
      "29/29 [==============================] - 0s 926us/step - loss: 148.1775 - mean_absolute_error: 9.5299\n",
      "Epoch 482/500\n",
      "29/29 [==============================] - 0s 926us/step - loss: 141.5827 - mean_absolute_error: 9.2398\n",
      "Epoch 483/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 134.6983 - mean_absolute_error: 8.9823\n",
      "Epoch 484/500\n",
      "29/29 [==============================] - 0s 981us/step - loss: 135.3321 - mean_absolute_error: 9.1808\n",
      "Epoch 485/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 136.6561 - mean_absolute_error: 9.1018\n",
      "Epoch 486/500\n",
      "29/29 [==============================] - 0s 961us/step - loss: 144.7333 - mean_absolute_error: 9.3093\n",
      "Epoch 487/500\n",
      "29/29 [==============================] - 0s 960us/step - loss: 153.5314 - mean_absolute_error: 9.7460\n",
      "Epoch 488/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 134.0539 - mean_absolute_error: 8.9771\n",
      "Epoch 489/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 139.2210 - mean_absolute_error: 9.2158\n",
      "Epoch 490/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 126.0784 - mean_absolute_error: 8.8239\n",
      "Epoch 491/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 136.9695 - mean_absolute_error: 9.3563\n",
      "Epoch 492/500\n",
      "29/29 [==============================] - 0s 926us/step - loss: 138.7864 - mean_absolute_error: 9.3664\n",
      "Epoch 493/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 140.9204 - mean_absolute_error: 9.3128\n",
      "Epoch 494/500\n",
      "29/29 [==============================] - 0s 998us/step - loss: 143.5445 - mean_absolute_error: 9.3047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 495/500\n",
      "29/29 [==============================] - 0s 986us/step - loss: 156.2520 - mean_absolute_error: 9.6186\n",
      "Epoch 496/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 147.7553 - mean_absolute_error: 9.5022\n",
      "Epoch 497/500\n",
      "29/29 [==============================] - 0s 927us/step - loss: 150.3767 - mean_absolute_error: 9.4117\n",
      "Epoch 498/500\n",
      "29/29 [==============================] - 0s 819us/step - loss: 131.4209 - mean_absolute_error: 8.9524\n",
      "Epoch 499/500\n",
      "29/29 [==============================] - 0s 854us/step - loss: 137.0987 - mean_absolute_error: 9.3603\n",
      "Epoch 500/500\n",
      "29/29 [==============================] - 0s 961us/step - loss: 141.4353 - mean_absolute_error: 9.1977\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d379a1b3a0>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a model\n",
    "model_NN_age = Sequential()\n",
    "model_NN_age.add(Dense(7, input_dim=20, activation='relu'))\n",
    "model_NN_age.add(Dense(5, activation='relu'))\n",
    "model_NN_age.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Compiling model\n",
    "model_NN_age.compile(loss='mean_squared_error', optimizer='nadam', metrics=['mean_absolute_error'])\n",
    "\n",
    "# Training a model\n",
    "model_NN_age.fit(X_data_age_train, y_data_age_train, epochs=500, batch_size=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithms predict almost the same. Use a random forest to fill data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF, mae: 9.4103006993007\n",
      "GB, mae: 9.227447325455945\n",
      "NN, mae: 9.68711571259932\n"
     ]
    }
   ],
   "source": [
    "print('RF, mae:', mean_absolute_error(model_RF_age.predict(X_data_age_test), y_data_age_test))\n",
    "print('GB, mae:', mean_absolute_error(model_GB_age.predict(X_data_age_test), y_data_age_test))\n",
    "print('NN, mae:', mean_absolute_error(model_NN_age.predict(X_data_age_test), y_data_age_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a complete dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Family</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>C</th>\n",
       "      <th>...</th>\n",
       "      <th>S</th>\n",
       "      <th>Cabin_type_0</th>\n",
       "      <th>Cabin_type_A</th>\n",
       "      <th>Cabin_type_B</th>\n",
       "      <th>Cabin_type_C</th>\n",
       "      <th>Cabin_type_D</th>\n",
       "      <th>Cabin_type_E</th>\n",
       "      <th>Cabin_type_F</th>\n",
       "      <th>Cabin_type_G</th>\n",
       "      <th>Cabin_type_T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8792</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>69.5500</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>177 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Age  SibSp  Parch     Fare  Survived  Family  female  male  C  \\\n",
       "0         3    0      0      0   8.4583         0       0       0     1  0   \n",
       "1         2    1      0      0  13.0000         1       0       0     1  0   \n",
       "2         3    1      0      0   7.2250         1       0       1     0  1   \n",
       "3         3    1      0      0   7.2250         0       0       0     1  1   \n",
       "4         3    1      0      0   7.8792         1       0       1     0  0   \n",
       "..      ...  ...    ...    ...      ...       ...     ...     ...   ... ..   \n",
       "172       3    1      0      0   7.2292         0       0       0     1  1   \n",
       "173       3    0      8      2  69.5500         0      10       1     0  0   \n",
       "174       3    1      0      0   9.5000         0       0       0     1  0   \n",
       "175       3    1      0      0   7.8958         0       0       0     1  0   \n",
       "176       3    1      1      2  23.4500         0       3       1     0  0   \n",
       "\n",
       "     ...  S  Cabin_type_0  Cabin_type_A  Cabin_type_B  Cabin_type_C  \\\n",
       "0    ...  0             1             0             0             0   \n",
       "1    ...  1             1             0             0             0   \n",
       "2    ...  0             1             0             0             0   \n",
       "3    ...  0             1             0             0             0   \n",
       "4    ...  0             1             0             0             0   \n",
       "..   ... ..           ...           ...           ...           ...   \n",
       "172  ...  0             1             0             0             0   \n",
       "173  ...  1             1             0             0             0   \n",
       "174  ...  1             1             0             0             0   \n",
       "175  ...  1             1             0             0             0   \n",
       "176  ...  1             1             0             0             0   \n",
       "\n",
       "     Cabin_type_D  Cabin_type_E  Cabin_type_F  Cabin_type_G  Cabin_type_T  \n",
       "0               0             0             0             0             0  \n",
       "1               0             0             0             0             0  \n",
       "2               0             0             0             0             0  \n",
       "3               0             0             0             0             0  \n",
       "4               0             0             0             0             0  \n",
       "..            ...           ...           ...           ...           ...  \n",
       "172             0             0             0             0             0  \n",
       "173             0             0             0             0             0  \n",
       "174             0             0             0             0             0  \n",
       "175             0             0             0             0             0  \n",
       "176             0             0             0             0             0  \n",
       "\n",
       "[177 rows x 21 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_nan_age['Age'] = pd.DataFrame(model_RF.predict(X_data_nan_age))\n",
    "data_nan_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Family</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>C</th>\n",
       "      <th>...</th>\n",
       "      <th>S</th>\n",
       "      <th>Cabin_type_0</th>\n",
       "      <th>Cabin_type_A</th>\n",
       "      <th>Cabin_type_B</th>\n",
       "      <th>Cabin_type_C</th>\n",
       "      <th>Cabin_type_D</th>\n",
       "      <th>Cabin_type_E</th>\n",
       "      <th>Cabin_type_F</th>\n",
       "      <th>Cabin_type_G</th>\n",
       "      <th>Cabin_type_T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>69.5500</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass   Age  SibSp  Parch     Fare  Survived  Family  female  male  C  \\\n",
       "0         3  22.0      1      0   7.2500         0       1       0     1  0   \n",
       "1         1  38.0      1      0  71.2833         1       1       1     0  1   \n",
       "2         3  26.0      0      0   7.9250         1       0       1     0  0   \n",
       "3         1  35.0      1      0  53.1000         1       1       1     0  0   \n",
       "4         3  35.0      0      0   8.0500         0       0       0     1  0   \n",
       "..      ...   ...    ...    ...      ...       ...     ...     ...   ... ..   \n",
       "886       3   1.0      0      0   7.2292         0       0       0     1  1   \n",
       "887       3   0.0      8      2  69.5500         0      10       1     0  0   \n",
       "888       3   1.0      0      0   9.5000         0       0       0     1  0   \n",
       "889       3   1.0      0      0   7.8958         0       0       0     1  0   \n",
       "890       3   1.0      1      2  23.4500         0       3       1     0  0   \n",
       "\n",
       "     ...  S  Cabin_type_0  Cabin_type_A  Cabin_type_B  Cabin_type_C  \\\n",
       "0    ...  1             1             0             0             0   \n",
       "1    ...  0             0             0             0             1   \n",
       "2    ...  1             1             0             0             0   \n",
       "3    ...  1             0             0             0             1   \n",
       "4    ...  1             1             0             0             0   \n",
       "..   ... ..           ...           ...           ...           ...   \n",
       "886  ...  0             1             0             0             0   \n",
       "887  ...  1             1             0             0             0   \n",
       "888  ...  1             1             0             0             0   \n",
       "889  ...  1             1             0             0             0   \n",
       "890  ...  1             1             0             0             0   \n",
       "\n",
       "     Cabin_type_D  Cabin_type_E  Cabin_type_F  Cabin_type_G  Cabin_type_T  \n",
       "0               0             0             0             0             0  \n",
       "1               0             0             0             0             0  \n",
       "2               0             0             0             0             0  \n",
       "3               0             0             0             0             0  \n",
       "4               0             0             0             0             0  \n",
       "..            ...           ...           ...           ...           ...  \n",
       "886             0             0             0             0             0  \n",
       "887             0             0             0             0             0  \n",
       "888             0             0             0             0             0  \n",
       "889             0             0             0             0             0  \n",
       "890             0             0             0             0             0  \n",
       "\n",
       "[891 rows x 21 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([data_age, data_nan_age]).reset_index().drop('index', axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model for recognition 'Survived'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test = train_test_split(data, random_state=42, test_size=0.3)\n",
    "\n",
    "X_data_train = data_age_train.drop('Survived', axis=1)\n",
    "y_data_train = data_age_train['Survived']\n",
    "X_data_test = data_age_test.drop('Survived', axis=1)\n",
    "y_data_test = data_age_test['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8111888111888111"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_RF = RandomForestClassifier(random_state=42,\n",
    "                               # число деревьев в лесу\n",
    "                               n_estimators=500,\n",
    "                               # функция для impurity ('gini' или 'entropy')\n",
    "                               criterion='gini',\n",
    "                               max_depth=5,\n",
    "                               # Вычислять out-of-bag ошибку\n",
    "                               oob_score=True,\n",
    "                               # использовать результаты предыдущего вызова и нарастить предыдущий лес \n",
    "                               warm_start=False,\n",
    "                               # веса классов для балансировки обучения\n",
    "                               class_weight=None\n",
    "                              )\n",
    "# обучаем модель на тренировочных данных\n",
    "model_RF.fit(X_data_train, y_data_train)\n",
    "\n",
    "y_pred = model_RF.predict(X_data_test)\n",
    "accuracy_score(y_pred, y_data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7902097902097902"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_GB = GradientBoostingClassifier(n_estimators=500, \n",
    "                                    learning_rate=1.0,\n",
    "                                    max_depth=1, \n",
    "                                    random_state=42)\n",
    "model_GB.fit(X_data_train, y_data_train)\n",
    "\n",
    "y_pred = model_GB.predict(X_data_test)\n",
    "accuracy_score(y_pred, y_data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Converting pandas dataframe to numpy array\n",
    "X_data_train = X_data_train.values\n",
    "y_data_train = y_data_train.values\n",
    "X_data_test = X_data_test.values\n",
    "y_data_test = y_data_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data_train_bin = np_utils.to_categorical(y_data_train)\n",
    "y_data_test_bin = np_utils.to_categorical(y_data_test)\n",
    "y_data_test_bin[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 3.9211 - accuracy: 0.5649\n",
      "Epoch 2/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.6662 - accuracy: 0.6771\n",
      "Epoch 3/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5729 - accuracy: 0.7315\n",
      "Epoch 4/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.6130 - accuracy: 0.6935\n",
      "Epoch 5/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.6036 - accuracy: 0.6919\n",
      "Epoch 6/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5900 - accuracy: 0.6914\n",
      "Epoch 7/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5954 - accuracy: 0.7130\n",
      "Epoch 8/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5800 - accuracy: 0.7159\n",
      "Epoch 9/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5573 - accuracy: 0.7189\n",
      "Epoch 10/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5731 - accuracy: 0.7400\n",
      "Epoch 11/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5491 - accuracy: 0.7155\n",
      "Epoch 12/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5773 - accuracy: 0.6979\n",
      "Epoch 13/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5571 - accuracy: 0.7479\n",
      "Epoch 14/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5513 - accuracy: 0.7444\n",
      "Epoch 15/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5464 - accuracy: 0.7343\n",
      "Epoch 16/500\n",
      "29/29 [==============================] - 0s 998us/step - loss: 0.5457 - accuracy: 0.7293\n",
      "Epoch 17/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5089 - accuracy: 0.7487\n",
      "Epoch 18/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5545 - accuracy: 0.7386\n",
      "Epoch 19/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5072 - accuracy: 0.7785\n",
      "Epoch 20/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5017 - accuracy: 0.7622\n",
      "Epoch 21/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4851 - accuracy: 0.8234\n",
      "Epoch 22/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5021 - accuracy: 0.7638\n",
      "Epoch 23/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5115 - accuracy: 0.7713\n",
      "Epoch 24/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4743 - accuracy: 0.7916\n",
      "Epoch 25/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 0.5093 - accuracy: 0.7690\n",
      "Epoch 26/500\n",
      "29/29 [==============================] - 0s 998us/step - loss: 0.4762 - accuracy: 0.7778\n",
      "Epoch 27/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5136 - accuracy: 0.7317\n",
      "Epoch 28/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4295 - accuracy: 0.8226\n",
      "Epoch 29/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4293 - accuracy: 0.8091\n",
      "Epoch 30/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4768 - accuracy: 0.7904\n",
      "Epoch 31/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4896 - accuracy: 0.7833\n",
      "Epoch 32/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4779 - accuracy: 0.7935\n",
      "Epoch 33/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5181 - accuracy: 0.7618\n",
      "Epoch 34/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4414 - accuracy: 0.8211\n",
      "Epoch 35/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4371 - accuracy: 0.8009\n",
      "Epoch 36/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4406 - accuracy: 0.8108\n",
      "Epoch 37/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4206 - accuracy: 0.8106\n",
      "Epoch 38/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4153 - accuracy: 0.8129\n",
      "Epoch 39/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4229 - accuracy: 0.8191\n",
      "Epoch 40/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4017 - accuracy: 0.8342\n",
      "Epoch 41/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4197 - accuracy: 0.8155\n",
      "Epoch 42/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4447 - accuracy: 0.8084\n",
      "Epoch 43/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4299 - accuracy: 0.8169\n",
      "Epoch 44/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4295 - accuracy: 0.8155\n",
      "Epoch 45/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 0.4774 - accuracy: 0.8222\n",
      "Epoch 46/500\n",
      "29/29 [==============================] - 0s 926us/step - loss: 0.4048 - accuracy: 0.8156\n",
      "Epoch 47/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4052 - accuracy: 0.8270\n",
      "Epoch 48/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 0.4223 - accuracy: 0.8035\n",
      "Epoch 49/500\n",
      "29/29 [==============================] - 0s 891us/step - loss: 0.3966 - accuracy: 0.8294\n",
      "Epoch 50/500\n",
      "29/29 [==============================] - 0s 961us/step - loss: 0.4140 - accuracy: 0.8159\n",
      "Epoch 51/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4182 - accuracy: 0.8051\n",
      "Epoch 52/500\n",
      "29/29 [==============================] - 0s 890us/step - loss: 0.3860 - accuracy: 0.8345\n",
      "Epoch 53/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3746 - accuracy: 0.8313\n",
      "Epoch 54/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3861 - accuracy: 0.8395\n",
      "Epoch 55/500\n",
      "29/29 [==============================] - 0s 963us/step - loss: 0.3818 - accuracy: 0.8325\n",
      "Epoch 56/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4214 - accuracy: 0.8346\n",
      "Epoch 57/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 0.4061 - accuracy: 0.8186\n",
      "Epoch 58/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3913 - accuracy: 0.8394\n",
      "Epoch 59/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3923 - accuracy: 0.8224\n",
      "Epoch 60/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3837 - accuracy: 0.8212\n",
      "Epoch 61/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3935 - accuracy: 0.8148\n",
      "Epoch 62/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4134 - accuracy: 0.8126\n",
      "Epoch 63/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4110 - accuracy: 0.8168\n",
      "Epoch 64/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4081 - accuracy: 0.8234\n",
      "Epoch 65/500\n",
      "29/29 [==============================] - 0s 998us/step - loss: 0.4192 - accuracy: 0.8054\n",
      "Epoch 66/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3944 - accuracy: 0.8167\n",
      "Epoch 67/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3820 - accuracy: 0.8342\n",
      "Epoch 68/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3858 - accuracy: 0.8377\n",
      "Epoch 69/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3869 - accuracy: 0.8407\n",
      "Epoch 70/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4011 - accuracy: 0.8329\n",
      "Epoch 71/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4209 - accuracy: 0.8186\n",
      "Epoch 72/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4289 - accuracy: 0.7997\n",
      "Epoch 73/500\n",
      "29/29 [==============================] - 0s 855us/step - loss: 0.3930 - accuracy: 0.8397\n",
      "Epoch 74/500\n",
      "29/29 [==============================] - 0s 927us/step - loss: 0.4153 - accuracy: 0.8212\n",
      "Epoch 75/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4161 - accuracy: 0.8058\n",
      "Epoch 76/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4218 - accuracy: 0.7890\n",
      "Epoch 77/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 0.4346 - accuracy: 0.8184\n",
      "Epoch 78/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 0.3357 - accuracy: 0.8657\n",
      "Epoch 79/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 0.3708 - accuracy: 0.8332\n",
      "Epoch 80/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4262 - accuracy: 0.8023\n",
      "Epoch 81/500\n",
      "29/29 [==============================] - 0s 926us/step - loss: 0.4253 - accuracy: 0.7933\n",
      "Epoch 82/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4263 - accuracy: 0.8118\n",
      "Epoch 83/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3789 - accuracy: 0.8400\n",
      "Epoch 84/500\n",
      "29/29 [==============================] - 0s 926us/step - loss: 0.4030 - accuracy: 0.8071\n",
      "Epoch 85/500\n",
      "29/29 [==============================] - 0s 999us/step - loss: 0.3853 - accuracy: 0.8385\n",
      "Epoch 86/500\n",
      "29/29 [==============================] - 0s 980us/step - loss: 0.4141 - accuracy: 0.8245\n",
      "Epoch 87/500\n",
      "29/29 [==============================] - 0s 999us/step - loss: 0.4366 - accuracy: 0.7986\n",
      "Epoch 88/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3880 - accuracy: 0.8058\n",
      "Epoch 89/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3937 - accuracy: 0.8244\n",
      "Epoch 90/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4198 - accuracy: 0.8049\n",
      "Epoch 91/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 0.4076 - accuracy: 0.8074\n",
      "Epoch 92/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 0.3581 - accuracy: 0.8303\n",
      "Epoch 93/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3605 - accuracy: 0.8387\n",
      "Epoch 94/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3926 - accuracy: 0.8171\n",
      "Epoch 95/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3704 - accuracy: 0.8565\n",
      "Epoch 96/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 0.3517 - accuracy: 0.8661\n",
      "Epoch 97/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4733 - accuracy: 0.7778\n",
      "Epoch 98/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4075 - accuracy: 0.8250\n",
      "Epoch 99/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3942 - accuracy: 0.8361\n",
      "Epoch 100/500\n",
      "29/29 [==============================] - 0s 998us/step - loss: 0.3718 - accuracy: 0.8398\n",
      "Epoch 101/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 0.3690 - accuracy: 0.8272\n",
      "Epoch 102/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3716 - accuracy: 0.8253\n",
      "Epoch 103/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 0.3963 - accuracy: 0.8065\n",
      "Epoch 104/500\n",
      "29/29 [==============================] - 0s 979us/step - loss: 0.3896 - accuracy: 0.8120\n",
      "Epoch 105/500\n",
      "29/29 [==============================] - 0s 998us/step - loss: 0.3546 - accuracy: 0.8479\n",
      "Epoch 106/500\n",
      "29/29 [==============================] - 0s 998us/step - loss: 0.3549 - accuracy: 0.8457\n",
      "Epoch 107/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 0.3546 - accuracy: 0.8360\n",
      "Epoch 108/500\n",
      "29/29 [==============================] - 0s 978us/step - loss: 0.3497 - accuracy: 0.8247\n",
      "Epoch 109/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3766 - accuracy: 0.8351\n",
      "Epoch 110/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 0.4227 - accuracy: 0.8047\n",
      "Epoch 111/500\n",
      "29/29 [==============================] - 0s 998us/step - loss: 0.4017 - accuracy: 0.8121\n",
      "Epoch 112/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 0.4236 - accuracy: 0.7953\n",
      "Epoch 113/500\n",
      "29/29 [==============================] - 0s 998us/step - loss: 0.4093 - accuracy: 0.8133\n",
      "Epoch 114/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 0.3622 - accuracy: 0.8354\n",
      "Epoch 115/500\n",
      "29/29 [==============================] - 0s 932us/step - loss: 0.3891 - accuracy: 0.8215\n",
      "Epoch 116/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3744 - accuracy: 0.8500\n",
      "Epoch 117/500\n",
      "29/29 [==============================] - 0s 998us/step - loss: 0.3644 - accuracy: 0.8362\n",
      "Epoch 118/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3857 - accuracy: 0.8335\n",
      "Epoch 119/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3938 - accuracy: 0.8284\n",
      "Epoch 120/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3412 - accuracy: 0.8577\n",
      "Epoch 121/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 0.3688 - accuracy: 0.8179\n",
      "Epoch 122/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4009 - accuracy: 0.8216\n",
      "Epoch 123/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3597 - accuracy: 0.8402\n",
      "Epoch 124/500\n",
      "29/29 [==============================] - 0s 978us/step - loss: 0.3637 - accuracy: 0.8517\n",
      "Epoch 125/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3921 - accuracy: 0.8195\n",
      "Epoch 126/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3723 - accuracy: 0.8445\n",
      "Epoch 127/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3704 - accuracy: 0.8248\n",
      "Epoch 128/500\n",
      "29/29 [==============================] - 0s 998us/step - loss: 0.3879 - accuracy: 0.8346\n",
      "Epoch 129/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3901 - accuracy: 0.8377\n",
      "Epoch 130/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3720 - accuracy: 0.8345\n",
      "Epoch 131/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3448 - accuracy: 0.8410\n",
      "Epoch 132/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3718 - accuracy: 0.8313\n",
      "Epoch 133/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 0.3996 - accuracy: 0.8129\n",
      "Epoch 134/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3494 - accuracy: 0.8369\n",
      "Epoch 135/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3634 - accuracy: 0.8456\n",
      "Epoch 136/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4105 - accuracy: 0.8227\n",
      "Epoch 137/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 0.3917 - accuracy: 0.8206\n",
      "Epoch 138/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 0.3784 - accuracy: 0.8267\n",
      "Epoch 139/500\n",
      "29/29 [==============================] - 0s 890us/step - loss: 0.3541 - accuracy: 0.8473\n",
      "Epoch 140/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 0.3380 - accuracy: 0.8489\n",
      "Epoch 141/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 0.3381 - accuracy: 0.8574\n",
      "Epoch 142/500\n",
      "29/29 [==============================] - 0s 926us/step - loss: 0.4197 - accuracy: 0.8169\n",
      "Epoch 143/500\n",
      "29/29 [==============================] - 0s 995us/step - loss: 0.3347 - accuracy: 0.8496\n",
      "Epoch 144/500\n",
      "29/29 [==============================] - 0s 991us/step - loss: 0.3761 - accuracy: 0.8262\n",
      "Epoch 145/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 0.3551 - accuracy: 0.8470\n",
      "Epoch 146/500\n",
      "29/29 [==============================] - 0s 995us/step - loss: 0.3961 - accuracy: 0.8508\n",
      "Epoch 147/500\n",
      "29/29 [==============================] - 0s 926us/step - loss: 0.3743 - accuracy: 0.8340\n",
      "Epoch 148/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3632 - accuracy: 0.8497\n",
      "Epoch 149/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 0.3604 - accuracy: 0.8371\n",
      "Epoch 150/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3565 - accuracy: 0.8419\n",
      "Epoch 151/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3233 - accuracy: 0.8608\n",
      "Epoch 152/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3460 - accuracy: 0.8479\n",
      "Epoch 153/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3371 - accuracy: 0.8518\n",
      "Epoch 154/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3581 - accuracy: 0.8528\n",
      "Epoch 155/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3542 - accuracy: 0.8413\n",
      "Epoch 156/500\n",
      "29/29 [==============================] - 0s 926us/step - loss: 0.3720 - accuracy: 0.8389\n",
      "Epoch 157/500\n",
      "29/29 [==============================] - 0s 926us/step - loss: 0.3687 - accuracy: 0.8266\n",
      "Epoch 158/500\n",
      "29/29 [==============================] - 0s 927us/step - loss: 0.3838 - accuracy: 0.8345\n",
      "Epoch 159/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4012 - accuracy: 0.8181\n",
      "Epoch 160/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4000 - accuracy: 0.7978\n",
      "Epoch 161/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3231 - accuracy: 0.8646\n",
      "Epoch 162/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3623 - accuracy: 0.8570\n",
      "Epoch 163/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3475 - accuracy: 0.8350\n",
      "Epoch 164/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3829 - accuracy: 0.8335\n",
      "Epoch 165/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3625 - accuracy: 0.8534\n",
      "Epoch 166/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 0.3565 - accuracy: 0.8363\n",
      "Epoch 167/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 0.3341 - accuracy: 0.8561\n",
      "Epoch 168/500\n",
      "29/29 [==============================] - 0s 926us/step - loss: 0.3893 - accuracy: 0.8248\n",
      "Epoch 169/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 0.4045 - accuracy: 0.8404\n",
      "Epoch 170/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 0.3667 - accuracy: 0.8367\n",
      "Epoch 171/500\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.3677 - accuracy: 0.85 - 0s 998us/step - loss: 0.3708 - accuracy: 0.8425\n",
      "Epoch 172/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 0.3329 - accuracy: 0.8449\n",
      "Epoch 173/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3738 - accuracy: 0.8209\n",
      "Epoch 174/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 0.3457 - accuracy: 0.8387\n",
      "Epoch 175/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 0.3354 - accuracy: 0.8270\n",
      "Epoch 176/500\n",
      "29/29 [==============================] - 0s 999us/step - loss: 0.3618 - accuracy: 0.8360\n",
      "Epoch 177/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3816 - accuracy: 0.8296\n",
      "Epoch 178/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3707 - accuracy: 0.8237\n",
      "Epoch 179/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3811 - accuracy: 0.8228\n",
      "Epoch 180/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3794 - accuracy: 0.8226\n",
      "Epoch 181/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 0.3376 - accuracy: 0.8505\n",
      "Epoch 182/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3431 - accuracy: 0.8397\n",
      "Epoch 183/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3439 - accuracy: 0.8406\n",
      "Epoch 184/500\n",
      "29/29 [==============================] - 0s 998us/step - loss: 0.3561 - accuracy: 0.8374\n",
      "Epoch 185/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3654 - accuracy: 0.8502\n",
      "Epoch 186/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3244 - accuracy: 0.8548\n",
      "Epoch 187/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3344 - accuracy: 0.8611\n",
      "Epoch 188/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4013 - accuracy: 0.8239\n",
      "Epoch 189/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3512 - accuracy: 0.8435\n",
      "Epoch 190/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 0.3380 - accuracy: 0.8538\n",
      "Epoch 191/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 0.2996 - accuracy: 0.8723\n",
      "Epoch 192/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 0.3171 - accuracy: 0.8570\n",
      "Epoch 193/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 0.3575 - accuracy: 0.8403\n",
      "Epoch 194/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 0.3730 - accuracy: 0.8309\n",
      "Epoch 195/500\n",
      "29/29 [==============================] - 0s 926us/step - loss: 0.3486 - accuracy: 0.8217\n",
      "Epoch 196/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3337 - accuracy: 0.8492\n",
      "Epoch 197/500\n",
      "29/29 [==============================] - 0s 890us/step - loss: 0.3207 - accuracy: 0.8628\n",
      "Epoch 198/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 0.3560 - accuracy: 0.8424\n",
      "Epoch 199/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3528 - accuracy: 0.8385\n",
      "Epoch 200/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 0.3444 - accuracy: 0.8587\n",
      "Epoch 201/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3357 - accuracy: 0.8576\n",
      "Epoch 202/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 0.3273 - accuracy: 0.8471\n",
      "Epoch 203/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 0.3495 - accuracy: 0.8389\n",
      "Epoch 204/500\n",
      "29/29 [==============================] - 0s 963us/step - loss: 0.3422 - accuracy: 0.8493\n",
      "Epoch 205/500\n",
      "29/29 [==============================] - 0s 963us/step - loss: 0.3614 - accuracy: 0.8414\n",
      "Epoch 206/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3402 - accuracy: 0.8681\n",
      "Epoch 207/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3088 - accuracy: 0.8460\n",
      "Epoch 208/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4382 - accuracy: 0.8316\n",
      "Epoch 209/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 0.3813 - accuracy: 0.8208\n",
      "Epoch 210/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3227 - accuracy: 0.8603\n",
      "Epoch 211/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3600 - accuracy: 0.8279\n",
      "Epoch 212/500\n",
      "29/29 [==============================] - 0s 998us/step - loss: 0.3278 - accuracy: 0.8528\n",
      "Epoch 213/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 0.3204 - accuracy: 0.8470\n",
      "Epoch 214/500\n",
      "29/29 [==============================] - 0s 963us/step - loss: 0.3394 - accuracy: 0.8470\n",
      "Epoch 215/500\n",
      "29/29 [==============================] - 0s 999us/step - loss: 0.3375 - accuracy: 0.8413\n",
      "Epoch 216/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3453 - accuracy: 0.8342\n",
      "Epoch 217/500\n",
      "29/29 [==============================] - 0s 998us/step - loss: 0.3239 - accuracy: 0.8432\n",
      "Epoch 218/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3626 - accuracy: 0.8307\n",
      "Epoch 219/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3076 - accuracy: 0.8608\n",
      "Epoch 220/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3311 - accuracy: 0.8627\n",
      "Epoch 221/500\n",
      "29/29 [==============================] - 0s 960us/step - loss: 0.3130 - accuracy: 0.8596\n",
      "Epoch 222/500\n",
      "29/29 [==============================] - 0s 998us/step - loss: 0.3601 - accuracy: 0.8292\n",
      "Epoch 223/500\n",
      "29/29 [==============================] - 0s 942us/step - loss: 0.3547 - accuracy: 0.8390\n",
      "Epoch 224/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.4014 - accuracy: 0.8328\n",
      "Epoch 225/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 0.3553 - accuracy: 0.8288\n",
      "Epoch 226/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3125 - accuracy: 0.8636\n",
      "Epoch 227/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 0.3075 - accuracy: 0.8632\n",
      "Epoch 228/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3483 - accuracy: 0.8458\n",
      "Epoch 229/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3837 - accuracy: 0.8332\n",
      "Epoch 230/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 0.4041 - accuracy: 0.8146\n",
      "Epoch 231/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3826 - accuracy: 0.8362\n",
      "Epoch 232/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8655\n",
      "Epoch 233/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 0.3232 - accuracy: 0.8277\n",
      "Epoch 234/500\n",
      "29/29 [==============================] - 0s 927us/step - loss: 0.3121 - accuracy: 0.8564\n",
      "Epoch 235/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3542 - accuracy: 0.8531\n",
      "Epoch 236/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3442 - accuracy: 0.8468\n",
      "Epoch 237/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3474 - accuracy: 0.8495\n",
      "Epoch 238/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 0.3498 - accuracy: 0.8450\n",
      "Epoch 239/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 0.3165 - accuracy: 0.8438\n",
      "Epoch 240/500\n",
      "29/29 [==============================] - 0s 963us/step - loss: 0.3625 - accuracy: 0.8347\n",
      "Epoch 241/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3200 - accuracy: 0.8609\n",
      "Epoch 242/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 962us/step - loss: 0.3936 - accuracy: 0.8259\n",
      "Epoch 243/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3002 - accuracy: 0.8663\n",
      "Epoch 244/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2967 - accuracy: 0.8888\n",
      "Epoch 245/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3568 - accuracy: 0.8325\n",
      "Epoch 246/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3231 - accuracy: 0.8558\n",
      "Epoch 247/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3421 - accuracy: 0.8382\n",
      "Epoch 248/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3444 - accuracy: 0.8420\n",
      "Epoch 249/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 0.4005 - accuracy: 0.8293\n",
      "Epoch 250/500\n",
      "29/29 [==============================] - 0s 969us/step - loss: 0.3568 - accuracy: 0.8412\n",
      "Epoch 251/500\n",
      "29/29 [==============================] - 0s 999us/step - loss: 0.3405 - accuracy: 0.8387\n",
      "Epoch 252/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3139 - accuracy: 0.8644\n",
      "Epoch 253/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 0.3374 - accuracy: 0.8469\n",
      "Epoch 254/500\n",
      "29/29 [==============================] - 0s 999us/step - loss: 0.3066 - accuracy: 0.8509\n",
      "Epoch 255/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8493\n",
      "Epoch 256/500\n",
      "29/29 [==============================] - 0s 998us/step - loss: 0.3351 - accuracy: 0.8531\n",
      "Epoch 257/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 0.3293 - accuracy: 0.8536\n",
      "Epoch 258/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3269 - accuracy: 0.8642\n",
      "Epoch 259/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3381 - accuracy: 0.8351\n",
      "Epoch 260/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3370 - accuracy: 0.8510\n",
      "Epoch 261/500\n",
      "29/29 [==============================] - 0s 967us/step - loss: 0.3534 - accuracy: 0.8464\n",
      "Epoch 262/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3274 - accuracy: 0.8458\n",
      "Epoch 263/500\n",
      "29/29 [==============================] - 0s 996us/step - loss: 0.3317 - accuracy: 0.8641\n",
      "Epoch 264/500\n",
      "29/29 [==============================] - 0s 926us/step - loss: 0.3751 - accuracy: 0.8219\n",
      "Epoch 265/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2953 - accuracy: 0.8774\n",
      "Epoch 266/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3351 - accuracy: 0.8514\n",
      "Epoch 267/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2921 - accuracy: 0.8769\n",
      "Epoch 268/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3232 - accuracy: 0.8602\n",
      "Epoch 269/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 0.3128 - accuracy: 0.8742\n",
      "Epoch 270/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3227 - accuracy: 0.8589\n",
      "Epoch 271/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 0.3402 - accuracy: 0.8553\n",
      "Epoch 272/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2991 - accuracy: 0.8594\n",
      "Epoch 273/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3271 - accuracy: 0.8518\n",
      "Epoch 274/500\n",
      "29/29 [==============================] - 0s 963us/step - loss: 0.3315 - accuracy: 0.8445\n",
      "Epoch 275/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3308 - accuracy: 0.8516\n",
      "Epoch 276/500\n",
      "29/29 [==============================] - 0s 998us/step - loss: 0.3093 - accuracy: 0.8694\n",
      "Epoch 277/500\n",
      "29/29 [==============================] - 0s 996us/step - loss: 0.3433 - accuracy: 0.8458\n",
      "Epoch 278/500\n",
      "29/29 [==============================] - 0s 999us/step - loss: 0.3523 - accuracy: 0.8549\n",
      "Epoch 279/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3234 - accuracy: 0.8497\n",
      "Epoch 280/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3009 - accuracy: 0.8637\n",
      "Epoch 281/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 0.3322 - accuracy: 0.8467\n",
      "Epoch 282/500\n",
      "29/29 [==============================] - 0s 966us/step - loss: 0.3014 - accuracy: 0.8687\n",
      "Epoch 283/500\n",
      "29/29 [==============================] - 0s 955us/step - loss: 0.3221 - accuracy: 0.8508\n",
      "Epoch 284/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3225 - accuracy: 0.8508\n",
      "Epoch 285/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 0.3447 - accuracy: 0.8532\n",
      "Epoch 286/500\n",
      "29/29 [==============================] - 0s 963us/step - loss: 0.2899 - accuracy: 0.8813\n",
      "Epoch 287/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3046 - accuracy: 0.8633\n",
      "Epoch 288/500\n",
      "29/29 [==============================] - 0s 999us/step - loss: 0.2899 - accuracy: 0.8776\n",
      "Epoch 289/500\n",
      "29/29 [==============================] - 0s 960us/step - loss: 0.3221 - accuracy: 0.8599\n",
      "Epoch 290/500\n",
      "29/29 [==============================] - 0s 961us/step - loss: 0.3218 - accuracy: 0.8786\n",
      "Epoch 291/500\n",
      "29/29 [==============================] - 0s 927us/step - loss: 0.3118 - accuracy: 0.8745\n",
      "Epoch 292/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3260 - accuracy: 0.8503\n",
      "Epoch 293/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 0.3125 - accuracy: 0.8559\n",
      "Epoch 294/500\n",
      "29/29 [==============================] - 0s 964us/step - loss: 0.3215 - accuracy: 0.8501\n",
      "Epoch 295/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3146 - accuracy: 0.8515\n",
      "Epoch 296/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 0.3353 - accuracy: 0.8443\n",
      "Epoch 297/500\n",
      "29/29 [==============================] - 0s 998us/step - loss: 0.2975 - accuracy: 0.8757\n",
      "Epoch 298/500\n",
      "29/29 [==============================] - 0s 998us/step - loss: 0.2752 - accuracy: 0.8705\n",
      "Epoch 299/500\n",
      "29/29 [==============================] - 0s 926us/step - loss: 0.3073 - accuracy: 0.8610\n",
      "Epoch 300/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 0.3128 - accuracy: 0.8647\n",
      "Epoch 301/500\n",
      "29/29 [==============================] - 0s 950us/step - loss: 0.3244 - accuracy: 0.8707\n",
      "Epoch 302/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 0.3618 - accuracy: 0.8530\n",
      "Epoch 303/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 0.3977 - accuracy: 0.8298\n",
      "Epoch 304/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3353 - accuracy: 0.8487\n",
      "Epoch 305/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 0.3280 - accuracy: 0.8497\n",
      "Epoch 306/500\n",
      "29/29 [==============================] - 0s 999us/step - loss: 0.3429 - accuracy: 0.8345\n",
      "Epoch 307/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 0.3176 - accuracy: 0.8697\n",
      "Epoch 308/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2866 - accuracy: 0.8717\n",
      "Epoch 309/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3002 - accuracy: 0.8790\n",
      "Epoch 310/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 0.3677 - accuracy: 0.8434\n",
      "Epoch 311/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3328 - accuracy: 0.8523\n",
      "Epoch 312/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3417 - accuracy: 0.8434\n",
      "Epoch 313/500\n",
      "29/29 [==============================] - 0s 963us/step - loss: 0.3163 - accuracy: 0.8580\n",
      "Epoch 314/500\n",
      "29/29 [==============================] - 0s 926us/step - loss: 0.3159 - accuracy: 0.8547\n",
      "Epoch 315/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3541 - accuracy: 0.8384\n",
      "Epoch 316/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 0.3004 - accuracy: 0.8568\n",
      "Epoch 317/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 0.3559 - accuracy: 0.8453\n",
      "Epoch 318/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3054 - accuracy: 0.8695\n",
      "Epoch 319/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2856 - accuracy: 0.8784\n",
      "Epoch 320/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3176 - accuracy: 0.8556\n",
      "Epoch 321/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3075 - accuracy: 0.8544\n",
      "Epoch 322/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3308 - accuracy: 0.8379\n",
      "Epoch 323/500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.3336 - accuracy: 0.8474\n",
      "Epoch 324/500\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2643 - accuracy: 0.8890\n",
      "Epoch 325/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3534 - accuracy: 0.8519\n",
      "Epoch 326/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8594\n",
      "Epoch 327/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2960 - accuracy: 0.8771\n",
      "Epoch 328/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3204 - accuracy: 0.8674\n",
      "Epoch 329/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3147 - accuracy: 0.8494\n",
      "Epoch 330/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3037 - accuracy: 0.8657\n",
      "Epoch 331/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3016 - accuracy: 0.8614\n",
      "Epoch 332/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3379 - accuracy: 0.8553\n",
      "Epoch 333/500\n",
      "29/29 [==============================] - 0s 943us/step - loss: 0.3288 - accuracy: 0.8567\n",
      "Epoch 334/500\n",
      "29/29 [==============================] - 0s 998us/step - loss: 0.2737 - accuracy: 0.8745\n",
      "Epoch 335/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3650 - accuracy: 0.8483\n",
      "Epoch 336/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2860 - accuracy: 0.8712\n",
      "Epoch 337/500\n",
      "29/29 [==============================] - 0s 961us/step - loss: 0.2878 - accuracy: 0.8692\n",
      "Epoch 338/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3083 - accuracy: 0.8538\n",
      "Epoch 339/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 0.3022 - accuracy: 0.8522\n",
      "Epoch 340/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2727 - accuracy: 0.8900\n",
      "Epoch 341/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3502 - accuracy: 0.8308\n",
      "Epoch 342/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 0.2993 - accuracy: 0.8552\n",
      "Epoch 343/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2864 - accuracy: 0.8755\n",
      "Epoch 344/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8403\n",
      "Epoch 345/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3148 - accuracy: 0.8554\n",
      "Epoch 346/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3306 - accuracy: 0.8544\n",
      "Epoch 347/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3381 - accuracy: 0.8511\n",
      "Epoch 348/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3031 - accuracy: 0.8856\n",
      "Epoch 349/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2944 - accuracy: 0.8685\n",
      "Epoch 350/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3158 - accuracy: 0.8562\n",
      "Epoch 351/500\n",
      "29/29 [==============================] - 0s 960us/step - loss: 0.3074 - accuracy: 0.8717\n",
      "Epoch 352/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2881 - accuracy: 0.8688\n",
      "Epoch 353/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3365 - accuracy: 0.8443\n",
      "Epoch 354/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3536 - accuracy: 0.8526\n",
      "Epoch 355/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3605 - accuracy: 0.8475\n",
      "Epoch 356/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3344 - accuracy: 0.8467\n",
      "Epoch 357/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3024 - accuracy: 0.8628\n",
      "Epoch 358/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2970 - accuracy: 0.8678\n",
      "Epoch 359/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2781 - accuracy: 0.8835\n",
      "Epoch 360/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2957 - accuracy: 0.8786\n",
      "Epoch 361/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3183 - accuracy: 0.8586\n",
      "Epoch 362/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3139 - accuracy: 0.8649\n",
      "Epoch 363/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3069 - accuracy: 0.8540\n",
      "Epoch 364/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3253 - accuracy: 0.8477\n",
      "Epoch 365/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2889 - accuracy: 0.8590\n",
      "Epoch 366/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3246 - accuracy: 0.8706\n",
      "Epoch 367/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2911 - accuracy: 0.8719\n",
      "Epoch 368/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 0.3089 - accuracy: 0.8638\n",
      "Epoch 369/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 0.2832 - accuracy: 0.8875\n",
      "Epoch 370/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3264 - accuracy: 0.8694\n",
      "Epoch 371/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2914 - accuracy: 0.8557\n",
      "Epoch 372/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3326 - accuracy: 0.8238\n",
      "Epoch 373/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3204 - accuracy: 0.8546\n",
      "Epoch 374/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2921 - accuracy: 0.8650\n",
      "Epoch 375/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2839 - accuracy: 0.8691\n",
      "Epoch 376/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3246 - accuracy: 0.8568\n",
      "Epoch 377/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2834 - accuracy: 0.8870\n",
      "Epoch 378/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3167 - accuracy: 0.8589\n",
      "Epoch 379/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3030 - accuracy: 0.8674\n",
      "Epoch 380/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 0.2900 - accuracy: 0.8729\n",
      "Epoch 381/500\n",
      "29/29 [==============================] - 0s 927us/step - loss: 0.2997 - accuracy: 0.8804\n",
      "Epoch 382/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2878 - accuracy: 0.8846\n",
      "Epoch 383/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 0.2914 - accuracy: 0.8861\n",
      "Epoch 384/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2843 - accuracy: 0.8849\n",
      "Epoch 385/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3243 - accuracy: 0.8460\n",
      "Epoch 386/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3019 - accuracy: 0.8794\n",
      "Epoch 387/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3106 - accuracy: 0.8586\n",
      "Epoch 388/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3007 - accuracy: 0.8591\n",
      "Epoch 389/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2919 - accuracy: 0.8786\n",
      "Epoch 390/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3189 - accuracy: 0.8526\n",
      "Epoch 391/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3340 - accuracy: 0.8431\n",
      "Epoch 392/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3144 - accuracy: 0.8681\n",
      "Epoch 393/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3609 - accuracy: 0.8467\n",
      "Epoch 394/500\n",
      "29/29 [==============================] - 0s 999us/step - loss: 0.2993 - accuracy: 0.8667\n",
      "Epoch 395/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2921 - accuracy: 0.8739\n",
      "Epoch 396/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3337 - accuracy: 0.8758\n",
      "Epoch 397/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2880 - accuracy: 0.8694\n",
      "Epoch 398/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3051 - accuracy: 0.8501\n",
      "Epoch 399/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8508\n",
      "Epoch 400/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3429 - accuracy: 0.8425\n",
      "Epoch 401/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2812 - accuracy: 0.8765\n",
      "Epoch 402/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2904 - accuracy: 0.8691\n",
      "Epoch 403/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3267 - accuracy: 0.8629\n",
      "Epoch 404/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3093 - accuracy: 0.8717\n",
      "Epoch 405/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2968 - accuracy: 0.8608\n",
      "Epoch 406/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.8506\n",
      "Epoch 407/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2953 - accuracy: 0.8729\n",
      "Epoch 408/500\n",
      "29/29 [==============================] - 0s 998us/step - loss: 0.3074 - accuracy: 0.8690\n",
      "Epoch 409/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2894 - accuracy: 0.8781\n",
      "Epoch 410/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3004 - accuracy: 0.8723\n",
      "Epoch 411/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3059 - accuracy: 0.8630\n",
      "Epoch 412/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3586 - accuracy: 0.8452\n",
      "Epoch 413/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8496\n",
      "Epoch 414/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3118 - accuracy: 0.8747\n",
      "Epoch 415/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3448 - accuracy: 0.8578\n",
      "Epoch 416/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3028 - accuracy: 0.8645\n",
      "Epoch 417/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2969 - accuracy: 0.8471\n",
      "Epoch 418/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3067 - accuracy: 0.8697\n",
      "Epoch 419/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3109 - accuracy: 0.8692\n",
      "Epoch 420/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3211 - accuracy: 0.8669\n",
      "Epoch 421/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2497 - accuracy: 0.8935\n",
      "Epoch 422/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3311 - accuracy: 0.8612\n",
      "Epoch 423/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2685 - accuracy: 0.8856\n",
      "Epoch 424/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3070 - accuracy: 0.8604\n",
      "Epoch 425/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2897 - accuracy: 0.8850\n",
      "Epoch 426/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2729 - accuracy: 0.8673\n",
      "Epoch 427/500\n",
      "29/29 [==============================] - 0s 998us/step - loss: 0.3134 - accuracy: 0.8583\n",
      "Epoch 428/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2604 - accuracy: 0.8912\n",
      "Epoch 429/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3042 - accuracy: 0.8662\n",
      "Epoch 430/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2906 - accuracy: 0.8780\n",
      "Epoch 431/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3341 - accuracy: 0.8452\n",
      "Epoch 432/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3395 - accuracy: 0.8561\n",
      "Epoch 433/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3218 - accuracy: 0.8506\n",
      "Epoch 434/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3066 - accuracy: 0.8601\n",
      "Epoch 435/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3211 - accuracy: 0.8747\n",
      "Epoch 436/500\n",
      "29/29 [==============================] - 0s 961us/step - loss: 0.2788 - accuracy: 0.8656\n",
      "Epoch 437/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2873 - accuracy: 0.8645\n",
      "Epoch 438/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2829 - accuracy: 0.8731\n",
      "Epoch 439/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3402 - accuracy: 0.8447\n",
      "Epoch 440/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3500 - accuracy: 0.8229\n",
      "Epoch 441/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3173 - accuracy: 0.8512\n",
      "Epoch 442/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3096 - accuracy: 0.8569\n",
      "Epoch 443/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3127 - accuracy: 0.8758\n",
      "Epoch 444/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3106 - accuracy: 0.8656\n",
      "Epoch 445/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2538 - accuracy: 0.8929\n",
      "Epoch 446/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2652 - accuracy: 0.8884\n",
      "Epoch 447/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2792 - accuracy: 0.8818\n",
      "Epoch 448/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2953 - accuracy: 0.8739\n",
      "Epoch 449/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2615 - accuracy: 0.8911\n",
      "Epoch 450/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2869 - accuracy: 0.8736\n",
      "Epoch 451/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2667 - accuracy: 0.8801\n",
      "Epoch 452/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2861 - accuracy: 0.8566\n",
      "Epoch 453/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2855 - accuracy: 0.8697\n",
      "Epoch 454/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2498 - accuracy: 0.8917\n",
      "Epoch 455/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2683 - accuracy: 0.8845\n",
      "Epoch 456/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2698 - accuracy: 0.8867\n",
      "Epoch 457/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2942 - accuracy: 0.8660\n",
      "Epoch 458/500\n",
      "29/29 [==============================] - 0s 962us/step - loss: 0.2915 - accuracy: 0.8687\n",
      "Epoch 459/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3231 - accuracy: 0.8550\n",
      "Epoch 460/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2762 - accuracy: 0.8839\n",
      "Epoch 461/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2805 - accuracy: 0.8875\n",
      "Epoch 462/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2842 - accuracy: 0.8762\n",
      "Epoch 463/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3426 - accuracy: 0.8499\n",
      "Epoch 464/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2532 - accuracy: 0.8982\n",
      "Epoch 465/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2836 - accuracy: 0.8765\n",
      "Epoch 466/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2782 - accuracy: 0.8739\n",
      "Epoch 467/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2850 - accuracy: 0.8822\n",
      "Epoch 468/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2946 - accuracy: 0.8742\n",
      "Epoch 469/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3093 - accuracy: 0.8571\n",
      "Epoch 470/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2790 - accuracy: 0.8833\n",
      "Epoch 471/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3460 - accuracy: 0.8655\n",
      "Epoch 472/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3138 - accuracy: 0.8623\n",
      "Epoch 473/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3118 - accuracy: 0.8631\n",
      "Epoch 474/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2778 - accuracy: 0.8645\n",
      "Epoch 475/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2941 - accuracy: 0.8706\n",
      "Epoch 476/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2802 - accuracy: 0.8731\n",
      "Epoch 477/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2911 - accuracy: 0.8706\n",
      "Epoch 478/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3399 - accuracy: 0.8517\n",
      "Epoch 479/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3187 - accuracy: 0.8565\n",
      "Epoch 480/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2737 - accuracy: 0.8715\n",
      "Epoch 481/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3109 - accuracy: 0.8572\n",
      "Epoch 482/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3182 - accuracy: 0.8416\n",
      "Epoch 483/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2464 - accuracy: 0.8968\n",
      "Epoch 484/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2944 - accuracy: 0.8571\n",
      "Epoch 485/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3135 - accuracy: 0.8571\n",
      "Epoch 486/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2820 - accuracy: 0.8766\n",
      "Epoch 487/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2417 - accuracy: 0.8929\n",
      "Epoch 488/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2897 - accuracy: 0.8650\n",
      "Epoch 489/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2943 - accuracy: 0.8662\n",
      "Epoch 490/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2653 - accuracy: 0.8876\n",
      "Epoch 491/500\n",
      "29/29 [==============================] - 0s 991us/step - loss: 0.2820 - accuracy: 0.8878\n",
      "Epoch 492/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3113 - accuracy: 0.8502\n",
      "Epoch 493/500\n",
      "29/29 [==============================] - 0s 997us/step - loss: 0.3252 - accuracy: 0.8513\n",
      "Epoch 494/500\n",
      "29/29 [==============================] - 0s 999us/step - loss: 0.3137 - accuracy: 0.8489\n",
      "Epoch 495/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2732 - accuracy: 0.8910\n",
      "Epoch 496/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2878 - accuracy: 0.8600\n",
      "Epoch 497/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2772 - accuracy: 0.8811\n",
      "Epoch 498/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3102 - accuracy: 0.8661\n",
      "Epoch 499/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3370 - accuracy: 0.8574\n",
      "Epoch 500/500\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3027 - accuracy: 0.8633\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d37af95b80>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a model\n",
    "model_NN = Sequential()\n",
    "model_NN.add(Dense(17, input_dim=20, activation='relu'))\n",
    "model_NN.add(Dense(15, activation='relu'))\n",
    "model_NN.add(Dense(10, activation='relu'))\n",
    "model_NN.add(Dense(7, activation='relu'))\n",
    "model_NN.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compiling model\n",
    "model_NN.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Training a model\n",
    "model_NN.fit(X_data_train, y_data_train_bin, epochs=500, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF, accuracy: 0.8111888111888111\n",
      "GB, accuracy: 0.7902097902097902\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7612 - accuracy: 0.7622\n",
      "NN, accuracy: 0.7622377872467041\n"
     ]
    }
   ],
   "source": [
    "print('RF, accuracy:', accuracy_score(model_RF.predict(X_data_test), y_data_test))\n",
    "print('GB, accuracy:', accuracy_score(model_GB.predict(X_data_test), y_data_test))\n",
    "print('NN, accuracy:', model_NN.evaluate(X_data_test, y_data_test_bin)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Аналогично обрабатываем данные для тестовой выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>3</td>\n",
       "      <td>Spector, Mr. Woolf</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A.5. 3236</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>1</td>\n",
       "      <td>Oliva y Ocana, Dona. Fermina</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17758</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>C105</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>3</td>\n",
       "      <td>Saether, Mr. Simon Sivertsen</td>\n",
       "      <td>male</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/O.Q. 3101262</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>3</td>\n",
       "      <td>Ware, Mr. Frederick</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>359309</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>3</td>\n",
       "      <td>Peter, Master. Michael J</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2668</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pclass                                          Name     Sex  \\\n",
       "PassengerId                                                                 \n",
       "892               3                              Kelly, Mr. James    male   \n",
       "893               3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "894               2                     Myles, Mr. Thomas Francis    male   \n",
       "895               3                              Wirz, Mr. Albert    male   \n",
       "896               3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "...             ...                                           ...     ...   \n",
       "1305              3                            Spector, Mr. Woolf    male   \n",
       "1306              1                  Oliva y Ocana, Dona. Fermina  female   \n",
       "1307              3                  Saether, Mr. Simon Sivertsen    male   \n",
       "1308              3                           Ware, Mr. Frederick    male   \n",
       "1309              3                      Peter, Master. Michael J    male   \n",
       "\n",
       "              Age  SibSp  Parch              Ticket      Fare Cabin Embarked  \n",
       "PassengerId                                                                   \n",
       "892          34.5      0      0              330911    7.8292   NaN        Q  \n",
       "893          47.0      1      0              363272    7.0000   NaN        S  \n",
       "894          62.0      0      0              240276    9.6875   NaN        Q  \n",
       "895          27.0      0      0              315154    8.6625   NaN        S  \n",
       "896          22.0      1      1             3101298   12.2875   NaN        S  \n",
       "...           ...    ...    ...                 ...       ...   ...      ...  \n",
       "1305          NaN      0      0           A.5. 3236    8.0500   NaN        S  \n",
       "1306         39.0      0      0            PC 17758  108.9000  C105        C  \n",
       "1307         38.5      0      0  SOTON/O.Q. 3101262    7.2500   NaN        S  \n",
       "1308          NaN      0      0              359309    8.0500   NaN        S  \n",
       "1309          NaN      1      1                2668   22.3583   NaN        C  \n",
       "\n",
       "[418 rows x 10 columns]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_control_test = pd.read_csv('test.csv', index_col='PassengerId')\n",
    "data_control_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived\n",
       "PassengerId          \n",
       "892                 1\n",
       "893                 0\n",
       "894                 1\n",
       "895                 0\n",
       "896                 0"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_control_test = pd.read_csv('out.csv')\n",
    "y_control_test.index = data_control_test.index\n",
    "y_control_test = y_control_test.drop('PassengerId', axis=1)\n",
    "y_control_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pclass                                          Name     Sex  \\\n",
       "PassengerId                                                                 \n",
       "892               3                              Kelly, Mr. James    male   \n",
       "893               3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "894               2                     Myles, Mr. Thomas Francis    male   \n",
       "895               3                              Wirz, Mr. Albert    male   \n",
       "896               3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "              Age  SibSp  Parch   Ticket     Fare Cabin Embarked  Survived  \n",
       "PassengerId                                                                 \n",
       "892          34.5      0      0   330911   7.8292   NaN        Q         1  \n",
       "893          47.0      1      0   363272   7.0000   NaN        S         0  \n",
       "894          62.0      0      0   240276   9.6875   NaN        Q         1  \n",
       "895          27.0      0      0   315154   8.6625   NaN        S         0  \n",
       "896          22.0      1      1  3101298  12.2875   NaN        S         0  "
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_control_test = data_control_test.join(y_control_test)\n",
    "data_control_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Age', 'Fare', 'Cabin']"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_control_test.columns[data_control_test.isna().any()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пропусков в Age: 86\n",
      "Пропусков в Fare: 1\n",
      "Пропусков в Cabin: 327\n"
     ]
    }
   ],
   "source": [
    "print('Пропусков в Age:', data_control_test['Age'].isna().sum())\n",
    "print('Пропусков в Fare:', data_control_test['Fare'].isna().sum())\n",
    "print('Пропусков в Cabin:', data_control_test['Cabin'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_control_test.loc[:, ['Cabin']] = data_control_test.loc[:, ['Cabin']].fillna('0')\n",
    "data_control_test.loc[:, ['Fare']] = data_control_test.loc[:, ['Fare']].fillna(data_control_test['Fare'].mean())\n",
    "data_control_test['Cabin'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Cabin_type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>0</td>\n",
       "      <td>Q</td>\n",
       "      <td>1</td>\n",
       "      <td>Cabin_type_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>Cabin_type_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>Q</td>\n",
       "      <td>1</td>\n",
       "      <td>Cabin_type_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>Cabin_type_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>Cabin_type_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>3</td>\n",
       "      <td>Spector, Mr. Woolf</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A.5. 3236</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>Cabin_type_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>1</td>\n",
       "      <td>Oliva y Ocana, Dona. Fermina</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17758</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>C105</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>Cabin_type_C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>3</td>\n",
       "      <td>Saether, Mr. Simon Sivertsen</td>\n",
       "      <td>male</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/O.Q. 3101262</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>Cabin_type_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>3</td>\n",
       "      <td>Ware, Mr. Frederick</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>359309</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>Cabin_type_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>3</td>\n",
       "      <td>Peter, Master. Michael J</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2668</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>Cabin_type_0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pclass                                          Name     Sex  \\\n",
       "PassengerId                                                                 \n",
       "892               3                              Kelly, Mr. James    male   \n",
       "893               3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "894               2                     Myles, Mr. Thomas Francis    male   \n",
       "895               3                              Wirz, Mr. Albert    male   \n",
       "896               3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "...             ...                                           ...     ...   \n",
       "1305              3                            Spector, Mr. Woolf    male   \n",
       "1306              1                  Oliva y Ocana, Dona. Fermina  female   \n",
       "1307              3                  Saether, Mr. Simon Sivertsen    male   \n",
       "1308              3                           Ware, Mr. Frederick    male   \n",
       "1309              3                      Peter, Master. Michael J    male   \n",
       "\n",
       "              Age  SibSp  Parch              Ticket      Fare Cabin Embarked  \\\n",
       "PassengerId                                                                    \n",
       "892          34.5      0      0              330911    7.8292     0        Q   \n",
       "893          47.0      1      0              363272    7.0000     0        S   \n",
       "894          62.0      0      0              240276    9.6875     0        Q   \n",
       "895          27.0      0      0              315154    8.6625     0        S   \n",
       "896          22.0      1      1             3101298   12.2875     0        S   \n",
       "...           ...    ...    ...                 ...       ...   ...      ...   \n",
       "1305          NaN      0      0           A.5. 3236    8.0500     0        S   \n",
       "1306         39.0      0      0            PC 17758  108.9000  C105        C   \n",
       "1307         38.5      0      0  SOTON/O.Q. 3101262    7.2500     0        S   \n",
       "1308          NaN      0      0              359309    8.0500     0        S   \n",
       "1309          NaN      1      1                2668   22.3583     0        C   \n",
       "\n",
       "             Survived    Cabin_type  \n",
       "PassengerId                          \n",
       "892                 1  Cabin_type_0  \n",
       "893                 0  Cabin_type_0  \n",
       "894                 1  Cabin_type_0  \n",
       "895                 0  Cabin_type_0  \n",
       "896                 0  Cabin_type_0  \n",
       "...               ...           ...  \n",
       "1305                0  Cabin_type_0  \n",
       "1306                1  Cabin_type_C  \n",
       "1307                1  Cabin_type_0  \n",
       "1308                0  Cabin_type_0  \n",
       "1309                0  Cabin_type_0  \n",
       "\n",
       "[418 rows x 12 columns]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_control_test['Cabin_type'] = data_control_test.apply(get_cabin_letter, axis=1)\n",
    "data_control_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>...</th>\n",
       "      <th>S</th>\n",
       "      <th>Cabin_type_0</th>\n",
       "      <th>Cabin_type_A</th>\n",
       "      <th>Cabin_type_B</th>\n",
       "      <th>Cabin_type_C</th>\n",
       "      <th>Cabin_type_D</th>\n",
       "      <th>Cabin_type_E</th>\n",
       "      <th>Cabin_type_F</th>\n",
       "      <th>Cabin_type_G</th>\n",
       "      <th>Family</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>0</td>\n",
       "      <td>Q</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>Q</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pclass                                          Name     Sex  \\\n",
       "PassengerId                                                                 \n",
       "892               3                              Kelly, Mr. James    male   \n",
       "893               3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "894               2                     Myles, Mr. Thomas Francis    male   \n",
       "895               3                              Wirz, Mr. Albert    male   \n",
       "896               3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "              Age  SibSp  Parch   Ticket     Fare Cabin Embarked  ...  S  \\\n",
       "PassengerId                                                       ...      \n",
       "892          34.5      0      0   330911   7.8292     0        Q  ...  0   \n",
       "893          47.0      1      0   363272   7.0000     0        S  ...  1   \n",
       "894          62.0      0      0   240276   9.6875     0        Q  ...  0   \n",
       "895          27.0      0      0   315154   8.6625     0        S  ...  1   \n",
       "896          22.0      1      1  3101298  12.2875     0        S  ...  1   \n",
       "\n",
       "            Cabin_type_0  Cabin_type_A  Cabin_type_B  Cabin_type_C  \\\n",
       "PassengerId                                                          \n",
       "892                    1             0             0             0   \n",
       "893                    1             0             0             0   \n",
       "894                    1             0             0             0   \n",
       "895                    1             0             0             0   \n",
       "896                    1             0             0             0   \n",
       "\n",
       "             Cabin_type_D  Cabin_type_E  Cabin_type_F  Cabin_type_G  Family  \n",
       "PassengerId                                                                  \n",
       "892                     0             0             0             0       0  \n",
       "893                     0             0             0             0       1  \n",
       "894                     0             0             0             0       0  \n",
       "895                     0             0             0             0       0  \n",
       "896                     0             0             0             0       2  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding new features\n",
    "data_control_test = pd.concat([data_control_test, pd.get_dummies(data_control_test['Sex'])], axis=1)\n",
    "data_control_test = pd.concat([data_control_test, pd.get_dummies(data_control_test['Embarked'])], axis=1)\n",
    "data_control_test = pd.concat([data_control_test, pd.get_dummies(data_control_test['Cabin_type'])], axis=1)\n",
    "data_control_test['Family'] = data_control_test['SibSp'] + data_control_test['Parch']\n",
    "data_control_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Name' 'Sex' 'Ticket' 'Cabin' 'Embarked' 'Cabin_type'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-243-1c61f4437504>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# delete categorical data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata_control_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Sex'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Ticket'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Cabin'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Embarked'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Cabin_type'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdata_control_test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3988\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[1;36m1.0\u001b[0m     \u001b[1;36m0.8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3989\u001b[0m         \"\"\"\n\u001b[1;32m-> 3990\u001b[1;33m         return super().drop(\n\u001b[0m\u001b[0;32m   3991\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3992\u001b[0m             \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3934\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3935\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3936\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3937\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3938\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3968\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3969\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3970\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3971\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3972\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   5016\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5017\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5018\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5019\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5020\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Name' 'Sex' 'Ticket' 'Cabin' 'Embarked' 'Cabin_type'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# delete categorical data\n",
    "data_control_test.drop(['Name', 'Sex','Ticket', 'Cabin', 'Embarked', 'Cabin_type'], axis=1, inplace=True)\n",
    "data_control_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in the NaN in the \"age\" column. Solve the regression problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Survived</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>C</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "      <th>Cabin_type_0</th>\n",
       "      <th>Cabin_type_A</th>\n",
       "      <th>Cabin_type_B</th>\n",
       "      <th>Cabin_type_C</th>\n",
       "      <th>Cabin_type_D</th>\n",
       "      <th>Cabin_type_E</th>\n",
       "      <th>Cabin_type_F</th>\n",
       "      <th>Cabin_type_G</th>\n",
       "      <th>Family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.7750</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>3</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7750</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>3</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>332 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass   Age  SibSp  Parch      Fare  Survived  female  male  C  Q  S  \\\n",
       "0         3  34.5      0      0    7.8292         1       0     1  0  1  0   \n",
       "1         3  47.0      1      0    7.0000         0       1     0  0  0  1   \n",
       "2         2  62.0      0      0    9.6875         1       0     1  0  1  0   \n",
       "3         3  27.0      0      0    8.6625         0       0     1  0  0  1   \n",
       "4         3  22.0      1      1   12.2875         0       1     0  0  0  1   \n",
       "..      ...   ...    ...    ...       ...       ...     ...   ... .. .. ..   \n",
       "327       3   3.0      1      1   13.7750         1       1     0  0  0  1   \n",
       "328       1  37.0      1      0   90.0000         1       1     0  0  1  0   \n",
       "329       3  28.0      0      0    7.7750         0       1     0  0  0  1   \n",
       "330       1  39.0      0      0  108.9000         1       1     0  1  0  0   \n",
       "331       3  38.5      0      0    7.2500         1       0     1  0  0  1   \n",
       "\n",
       "     Cabin_type_0  Cabin_type_A  Cabin_type_B  Cabin_type_C  Cabin_type_D  \\\n",
       "0               1             0             0             0             0   \n",
       "1               1             0             0             0             0   \n",
       "2               1             0             0             0             0   \n",
       "3               1             0             0             0             0   \n",
       "4               1             0             0             0             0   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "327             1             0             0             0             0   \n",
       "328             0             0             0             1             0   \n",
       "329             1             0             0             0             0   \n",
       "330             0             0             0             1             0   \n",
       "331             1             0             0             0             0   \n",
       "\n",
       "     Cabin_type_E  Cabin_type_F  Cabin_type_G  Family  \n",
       "0               0             0             0       0  \n",
       "1               0             0             0       1  \n",
       "2               0             0             0       0  \n",
       "3               0             0             0       0  \n",
       "4               0             0             0       2  \n",
       "..            ...           ...           ...     ...  \n",
       "327             0             0             0       2  \n",
       "328             0             0             0       1  \n",
       "329             0             0             0       0  \n",
       "330             0             0             0       0  \n",
       "331             0             0             0       0  \n",
       "\n",
       "[332 rows x 20 columns]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete lines, where age is NaN\n",
    "data_control_test_age = data_control_test.dropna(axis=0, how='any', subset=['Age']).reset_index().drop('PassengerId', axis=1)\n",
    "data_control_test_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Survived</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>C</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "      <th>Cabin_type_0</th>\n",
       "      <th>Cabin_type_A</th>\n",
       "      <th>Cabin_type_B</th>\n",
       "      <th>Cabin_type_C</th>\n",
       "      <th>Cabin_type_D</th>\n",
       "      <th>Cabin_type_E</th>\n",
       "      <th>Cabin_type_F</th>\n",
       "      <th>Cabin_type_G</th>\n",
       "      <th>Family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.6833</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>21.6792</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7208</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Pclass  Age  SibSp  Parch     Fare  Survived  female  male  C  Q  S  \\\n",
       "0        3  NaN      0      0   7.8958         0       0     1  0  0  1   \n",
       "1        1  NaN      0      0  31.6833         1       1     0  0  0  1   \n",
       "2        3  NaN      2      0  21.6792         0       0     1  1  0  0   \n",
       "3        3  NaN      1      2  23.4500         1       1     0  0  0  1   \n",
       "4        3  NaN      0      0   8.0500         0       1     0  0  0  1   \n",
       "..     ...  ...    ...    ...      ...       ...     ...   ... .. .. ..   \n",
       "81       3  NaN      0      0   7.7208         1       1     0  0  1  0   \n",
       "82       3  NaN      0      0   7.7500         0       1     0  0  1  0   \n",
       "83       3  NaN      0      0   8.0500         0       0     1  0  0  1   \n",
       "84       3  NaN      0      0   8.0500         0       0     1  0  0  1   \n",
       "85       3  NaN      1      1  22.3583         0       0     1  1  0  0   \n",
       "\n",
       "    Cabin_type_0  Cabin_type_A  Cabin_type_B  Cabin_type_C  Cabin_type_D  \\\n",
       "0              1             0             0             0             0   \n",
       "1              1             0             0             0             0   \n",
       "2              1             0             0             0             0   \n",
       "3              1             0             0             0             0   \n",
       "4              1             0             0             0             0   \n",
       "..           ...           ...           ...           ...           ...   \n",
       "81             1             0             0             0             0   \n",
       "82             1             0             0             0             0   \n",
       "83             1             0             0             0             0   \n",
       "84             1             0             0             0             0   \n",
       "85             1             0             0             0             0   \n",
       "\n",
       "    Cabin_type_E  Cabin_type_F  Cabin_type_G  Family  \n",
       "0              0             0             0       0  \n",
       "1              0             0             0       0  \n",
       "2              0             0             0       2  \n",
       "3              0             0             0       3  \n",
       "4              0             0             0       0  \n",
       "..           ...           ...           ...     ...  \n",
       "81             0             0             0       0  \n",
       "82             0             0             0       0  \n",
       "83             0             0             0       0  \n",
       "84             0             0             0       0  \n",
       "85             0             0             0       2  \n",
       "\n",
       "[86 rows x 20 columns]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete lines, where age is int/float\n",
    "data_control_test_nan_age = data_control_test.drop(data_control_test[data_control_test.Age >0].index).reset_index().drop('PassengerId', axis=1)\n",
    "data_control_test_nan_age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Для заполнения колонки Age обучим модель на первых 891 записях, где Age известно изначально. проверим на 892+ записях, где Age известно. И предскажем для 892+, где Age is NaТ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train sample length: 714\n",
      "test sample length: 332\n"
     ]
    }
   ],
   "source": [
    "X_data_control_test_age_train = data_age.drop('Age', axis=1)\n",
    "y_data_control_test_age_train = data_age['Age']\n",
    "X_data_control_test_age_test = data_control_test_age.drop('Age', axis=1)\n",
    "y_data_control_test_age_test = data_control_test_age['Age']\n",
    "\n",
    "print('train sample length:', len(X_data_control_test_age_train))\n",
    "print('test sample length:', len(X_data_control_test_age_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the data \"X_data_control_test_age_test\" there is no column \"Cabin_type_T\", so we delete it\n",
    "X_data_control_test_age_train = X_data_control_test_age_train.drop('Cabin_type_T', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features is 20 and input n_features is 19 ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-246-b9d91ce015ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mmodel_RF_age_control\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_data_control_test_age_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_data_control_test_age_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0my_age_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_RF_age_control\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_data_control_test_age_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_age_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_data_control_test_age_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    781\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m         \u001b[1;31m# Check data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 783\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    784\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m         \u001b[1;31m# Assign chunk of trees to jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    419\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 421\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    422\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    394\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 396\u001b[1;33m             raise ValueError(\"Number of features of the model must \"\n\u001b[0m\u001b[0;32m    397\u001b[0m                              \u001b[1;34m\"match the input. Model n_features is %s and \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m                              \u001b[1;34m\"input n_features is %s \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features is 20 and input n_features is 19 "
     ]
    }
   ],
   "source": [
    "model_RF_age_control = RandomForestRegressor(random_state=42,\n",
    "                               # число деревьев в лесу\n",
    "                               n_estimators=500,\n",
    "                               criterion='mae',\n",
    "                               max_depth=20,\n",
    "                               # Вычислять out-of-bag ошибку\n",
    "                               oob_score=True,\n",
    "                               warm_start=False\n",
    "                              )\n",
    "\n",
    "# train the model on training data\n",
    "model_RF_age_control.fit(X_data_control_test_age_train, y_data_control_test_age_train)\n",
    "\n",
    "y_age_pred = model_RF_age_control.predict(X_data_control_test_age_test)\n",
    "mean_absolute_error(y_age_pred, y_data_control_test_age_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_GB_age_control = GradientBoostingRegressor(random_state=42,\n",
    "                                  learning_rate=0.1,\n",
    "                                  n_estimators=700,\n",
    "                                  criterion='mae',\n",
    "                                  max_depth=1,\n",
    "                                  max_features='auto'\n",
    ")\n",
    "\n",
    "# train the model on training data\n",
    "model_GB_age_control.fit(X_data_control_test_age_train, y_data_control_test_age_train)\n",
    "\n",
    "y_age_pred = model_GB_age_control.predict(X_data_control_test_age_test)\n",
    "mean_absolute_error(y_age_pred, y_data_control_test_age_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-214-9fa8a4b1fc40>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#  Converting pandas dataframe to numpy array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_data_control_test_age_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_data_control_test_age_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0my_data_control_test_age_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_data_control_test_age_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mX_data_control_test_age_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_data_control_test_age_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my_data_control_test_age_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_data_control_test_age_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "#  Converting pandas dataframe to numpy array\n",
    "X_data_control_test_age_train = X_data_control_test_age_train.values\n",
    "y_data_control_test_age_train = y_data_control_test_age_train.values\n",
    "X_data_control_test_age_test = X_data_control_test_age_test.values\n",
    "y_data_control_test_age_test = y_data_control_test_age_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "36/36 [==============================] - 1s 798us/step - loss: 1115.0852 - mean_absolute_error: 30.2074\n",
      "Epoch 2/500\n",
      "36/36 [==============================] - 0s 883us/step - loss: 878.4867 - mean_absolute_error: 26.0614\n",
      "Epoch 3/500\n",
      "36/36 [==============================] - 0s 928us/step - loss: 752.2688 - mean_absolute_error: 23.7081\n",
      "Epoch 4/500\n",
      "36/36 [==============================] - 0s 940us/step - loss: 688.9910 - mean_absolute_error: 22.4016\n",
      "Epoch 5/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 719.2708 - mean_absolute_error: 22.8016\n",
      "Epoch 6/500\n",
      "36/36 [==============================] - 0s 912us/step - loss: 591.3575 - mean_absolute_error: 20.5809\n",
      "Epoch 7/500\n",
      "36/36 [==============================] - 0s 922us/step - loss: 566.0408 - mean_absolute_error: 20.0133\n",
      "Epoch 8/500\n",
      "36/36 [==============================] - 0s 912us/step - loss: 558.3508 - mean_absolute_error: 19.7146\n",
      "Epoch 9/500\n",
      "36/36 [==============================] - 0s 997us/step - loss: 525.1790 - mean_absolute_error: 18.9029\n",
      "Epoch 10/500\n",
      "36/36 [==============================] - 0s 969us/step - loss: 458.1526 - mean_absolute_error: 17.2629\n",
      "Epoch 11/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 392.2556 - mean_absolute_error: 15.3550\n",
      "Epoch 12/500\n",
      "36/36 [==============================] - 0s 814us/step - loss: 386.6145 - mean_absolute_error: 14.9144\n",
      "Epoch 13/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 367.5172 - mean_absolute_error: 14.3052\n",
      "Epoch 14/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 330.3272 - mean_absolute_error: 13.6068\n",
      "Epoch 15/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 294.2059 - mean_absolute_error: 13.0722\n",
      "Epoch 16/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 289.4350 - mean_absolute_error: 12.7449\n",
      "Epoch 17/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 289.3418 - mean_absolute_error: 12.8435\n",
      "Epoch 18/500\n",
      "36/36 [==============================] - 0s 998us/step - loss: 247.2583 - mean_absolute_error: 11.9155\n",
      "Epoch 19/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 249.4456 - mean_absolute_error: 12.0167\n",
      "Epoch 20/500\n",
      "36/36 [==============================] - 0s 884us/step - loss: 261.4526 - mean_absolute_error: 12.4352\n",
      "Epoch 21/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 228.4977 - mean_absolute_error: 11.6322\n",
      "Epoch 22/500\n",
      "36/36 [==============================] - 0s 883us/step - loss: 224.2497 - mean_absolute_error: 11.4181\n",
      "Epoch 23/500\n",
      "36/36 [==============================] - 0s 997us/step - loss: 224.2444 - mean_absolute_error: 11.4827\n",
      "Epoch 24/500\n",
      "36/36 [==============================] - 0s 931us/step - loss: 255.2616 - mean_absolute_error: 12.5178\n",
      "Epoch 25/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 223.1415 - mean_absolute_error: 11.6442\n",
      "Epoch 26/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 214.3545 - mean_absolute_error: 11.6264\n",
      "Epoch 27/500\n",
      "36/36 [==============================] - 0s 823us/step - loss: 217.9649 - mean_absolute_error: 11.5900\n",
      "Epoch 28/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 218.7071 - mean_absolute_error: 11.6365\n",
      "Epoch 29/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 210.2582 - mean_absolute_error: 11.4013\n",
      "Epoch 30/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 230.3109 - mean_absolute_error: 11.9431\n",
      "Epoch 31/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 231.7112 - mean_absolute_error: 12.1511\n",
      "Epoch 32/500\n",
      "36/36 [==============================] - 0s 969us/step - loss: 229.5674 - mean_absolute_error: 11.7780\n",
      "Epoch 33/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 199.2042 - mean_absolute_error: 10.8533\n",
      "Epoch 34/500\n",
      "36/36 [==============================] - 0s 856us/step - loss: 206.1339 - mean_absolute_error: 11.3468\n",
      "Epoch 35/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 213.4936 - mean_absolute_error: 11.6252\n",
      "Epoch 36/500\n",
      "36/36 [==============================] - 0s 912us/step - loss: 212.2736 - mean_absolute_error: 11.6430\n",
      "Epoch 37/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 223.1151 - mean_absolute_error: 11.7619\n",
      "Epoch 38/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 222.4002 - mean_absolute_error: 12.0774\n",
      "Epoch 39/500\n",
      "36/36 [==============================] - 0s 970us/step - loss: 203.9232 - mean_absolute_error: 11.2052\n",
      "Epoch 40/500\n",
      "36/36 [==============================] - 0s 912us/step - loss: 212.2315 - mean_absolute_error: 11.5738\n",
      "Epoch 41/500\n",
      "36/36 [==============================] - 0s 969us/step - loss: 195.9669 - mean_absolute_error: 11.0448\n",
      "Epoch 42/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 203.8067 - mean_absolute_error: 11.2713\n",
      "Epoch 43/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 218.0665 - mean_absolute_error: 11.7749\n",
      "Epoch 44/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 192.9094 - mean_absolute_error: 10.9607\n",
      "Epoch 45/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 209.9861 - mean_absolute_error: 11.5287\n",
      "Epoch 46/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 209.3158 - mean_absolute_error: 11.6502\n",
      "Epoch 47/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 206.0164 - mean_absolute_error: 11.4012\n",
      "Epoch 48/500\n",
      "36/36 [==============================] - 0s 883us/step - loss: 194.3921 - mean_absolute_error: 10.7986\n",
      "Epoch 49/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 193.8915 - mean_absolute_error: 11.0149\n",
      "Epoch 50/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 184.5392 - mean_absolute_error: 10.8208\n",
      "Epoch 51/500\n",
      "36/36 [==============================] - 0s 940us/step - loss: 187.7905 - mean_absolute_error: 10.8653\n",
      "Epoch 52/500\n",
      "36/36 [==============================] - 0s 928us/step - loss: 199.8140 - mean_absolute_error: 11.0164\n",
      "Epoch 53/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 184.3047 - mean_absolute_error: 10.7886\n",
      "Epoch 54/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 181.0785 - mean_absolute_error: 10.8347\n",
      "Epoch 55/500\n",
      "36/36 [==============================] - 0s 997us/step - loss: 179.5121 - mean_absolute_error: 10.5438\n",
      "Epoch 56/500\n",
      "36/36 [==============================] - 0s 969us/step - loss: 185.1024 - mean_absolute_error: 10.6037\n",
      "Epoch 57/500\n",
      "36/36 [==============================] - 0s 912us/step - loss: 204.5397 - mean_absolute_error: 11.3947\n",
      "Epoch 58/500\n",
      "36/36 [==============================] - 0s 990us/step - loss: 176.2097 - mean_absolute_error: 10.4337\n",
      "Epoch 59/500\n",
      "36/36 [==============================] - 0s 998us/step - loss: 183.5195 - mean_absolute_error: 10.7521\n",
      "Epoch 60/500\n",
      "36/36 [==============================] - 0s 996us/step - loss: 184.5702 - mean_absolute_error: 10.6165\n",
      "Epoch 61/500\n",
      "36/36 [==============================] - 0s 940us/step - loss: 206.2948 - mean_absolute_error: 11.4003\n",
      "Epoch 62/500\n",
      "36/36 [==============================] - 0s 969us/step - loss: 179.5927 - mean_absolute_error: 10.5303\n",
      "Epoch 63/500\n",
      "36/36 [==============================] - 0s 969us/step - loss: 173.6228 - mean_absolute_error: 10.4565\n",
      "Epoch 64/500\n",
      "36/36 [==============================] - 0s 798us/step - loss: 187.1770 - mean_absolute_error: 11.0330\n",
      "Epoch 65/500\n",
      "36/36 [==============================] - 0s 997us/step - loss: 181.0470 - mean_absolute_error: 10.6859\n",
      "Epoch 66/500\n",
      "36/36 [==============================] - 0s 856us/step - loss: 185.1269 - mean_absolute_error: 10.8435\n",
      "Epoch 67/500\n",
      "36/36 [==============================] - 0s 855us/step - loss: 201.5221 - mean_absolute_error: 11.2248\n",
      "Epoch 68/500\n",
      "36/36 [==============================] - 0s 883us/step - loss: 178.1505 - mean_absolute_error: 10.5709\n",
      "Epoch 69/500\n",
      "36/36 [==============================] - 0s 853us/step - loss: 163.3869 - mean_absolute_error: 10.1759\n",
      "Epoch 70/500\n",
      "36/36 [==============================] - 0s 879us/step - loss: 179.7275 - mean_absolute_error: 10.6400\n",
      "Epoch 71/500\n",
      "36/36 [==============================] - 0s 884us/step - loss: 179.6564 - mean_absolute_error: 10.7194\n",
      "Epoch 72/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 883us/step - loss: 162.7684 - mean_absolute_error: 10.0488\n",
      "Epoch 73/500\n",
      "36/36 [==============================] - 0s 969us/step - loss: 202.3923 - mean_absolute_error: 11.2065\n",
      "Epoch 74/500\n",
      "36/36 [==============================] - 0s 830us/step - loss: 177.8377 - mean_absolute_error: 10.6482\n",
      "Epoch 75/500\n",
      "36/36 [==============================] - 0s 781us/step - loss: 170.9542 - mean_absolute_error: 10.2421\n",
      "Epoch 76/500\n",
      "36/36 [==============================] - 0s 838us/step - loss: 165.3848 - mean_absolute_error: 10.2180\n",
      "Epoch 77/500\n",
      "36/36 [==============================] - 0s 846us/step - loss: 173.8074 - mean_absolute_error: 10.4930\n",
      "Epoch 78/500\n",
      "36/36 [==============================] - 0s 867us/step - loss: 162.0391 - mean_absolute_error: 10.1042\n",
      "Epoch 79/500\n",
      "36/36 [==============================] - 0s 883us/step - loss: 178.2261 - mean_absolute_error: 10.5377\n",
      "Epoch 80/500\n",
      "36/36 [==============================] - 0s 805us/step - loss: 165.2753 - mean_absolute_error: 10.1587\n",
      "Epoch 81/500\n",
      "36/36 [==============================] - 0s 883us/step - loss: 161.0063 - mean_absolute_error: 10.2084\n",
      "Epoch 82/500\n",
      "36/36 [==============================] - 0s 873us/step - loss: 163.1782 - mean_absolute_error: 10.0322\n",
      "Epoch 83/500\n",
      "36/36 [==============================] - 0s 868us/step - loss: 165.2011 - mean_absolute_error: 10.2841\n",
      "Epoch 84/500\n",
      "36/36 [==============================] - 0s 856us/step - loss: 167.3521 - mean_absolute_error: 10.0614\n",
      "Epoch 85/500\n",
      "36/36 [==============================] - 0s 854us/step - loss: 174.6234 - mean_absolute_error: 10.5189\n",
      "Epoch 86/500\n",
      "36/36 [==============================] - 0s 856us/step - loss: 177.7338 - mean_absolute_error: 10.5012\n",
      "Epoch 87/500\n",
      "36/36 [==============================] - 0s 859us/step - loss: 175.9860 - mean_absolute_error: 10.4108\n",
      "Epoch 88/500\n",
      "36/36 [==============================] - 0s 837us/step - loss: 163.2149 - mean_absolute_error: 10.1060\n",
      "Epoch 89/500\n",
      "36/36 [==============================] - 0s 798us/step - loss: 185.8612 - mean_absolute_error: 10.7466\n",
      "Epoch 90/500\n",
      "36/36 [==============================] - 0s 883us/step - loss: 177.3295 - mean_absolute_error: 10.2973\n",
      "Epoch 91/500\n",
      "36/36 [==============================] - 0s 826us/step - loss: 161.8792 - mean_absolute_error: 10.1566\n",
      "Epoch 92/500\n",
      "36/36 [==============================] - 0s 855us/step - loss: 155.5293 - mean_absolute_error: 9.8250\n",
      "Epoch 93/500\n",
      "36/36 [==============================] - 0s 997us/step - loss: 176.3056 - mean_absolute_error: 10.4008\n",
      "Epoch 94/500\n",
      "36/36 [==============================] - 0s 961us/step - loss: 177.5429 - mean_absolute_error: 10.5338\n",
      "Epoch 95/500\n",
      "36/36 [==============================] - 0s 997us/step - loss: 162.3750 - mean_absolute_error: 9.9533\n",
      "Epoch 96/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 167.4967 - mean_absolute_error: 10.1085\n",
      "Epoch 97/500\n",
      "36/36 [==============================] - 0s 998us/step - loss: 161.1167 - mean_absolute_error: 10.1019\n",
      "Epoch 98/500\n",
      "36/36 [==============================] - 0s 970us/step - loss: 149.7093 - mean_absolute_error: 9.6022\n",
      "Epoch 99/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 172.5553 - mean_absolute_error: 10.6174\n",
      "Epoch 100/500\n",
      "36/36 [==============================] - 0s 912us/step - loss: 158.9514 - mean_absolute_error: 9.8022\n",
      "Epoch 101/500\n",
      "36/36 [==============================] - 0s 941us/step - loss: 167.9980 - mean_absolute_error: 10.2462\n",
      "Epoch 102/500\n",
      "36/36 [==============================] - 0s 945us/step - loss: 151.3848 - mean_absolute_error: 9.9190\n",
      "Epoch 103/500\n",
      "36/36 [==============================] - 0s 997us/step - loss: 172.0038 - mean_absolute_error: 10.2803\n",
      "Epoch 104/500\n",
      "36/36 [==============================] - 0s 998us/step - loss: 163.7006 - mean_absolute_error: 10.1197\n",
      "Epoch 105/500\n",
      "36/36 [==============================] - 0s 969us/step - loss: 155.4330 - mean_absolute_error: 9.7030\n",
      "Epoch 106/500\n",
      "36/36 [==============================] - 0s 966us/step - loss: 167.3567 - mean_absolute_error: 9.9901\n",
      "Epoch 107/500\n",
      "36/36 [==============================] - 0s 969us/step - loss: 152.0101 - mean_absolute_error: 9.5092\n",
      "Epoch 108/500\n",
      "36/36 [==============================] - 0s 997us/step - loss: 154.6119 - mean_absolute_error: 9.7164\n",
      "Epoch 109/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 162.3035 - mean_absolute_error: 10.1337\n",
      "Epoch 110/500\n",
      "36/36 [==============================] - 0s 970us/step - loss: 157.5788 - mean_absolute_error: 9.6879\n",
      "Epoch 111/500\n",
      "36/36 [==============================] - 0s 941us/step - loss: 167.8124 - mean_absolute_error: 10.2003\n",
      "Epoch 112/500\n",
      "36/36 [==============================] - 0s 770us/step - loss: 163.2802 - mean_absolute_error: 9.9477\n",
      "Epoch 113/500\n",
      "36/36 [==============================] - 0s 883us/step - loss: 165.6391 - mean_absolute_error: 10.1195\n",
      "Epoch 114/500\n",
      "36/36 [==============================] - 0s 969us/step - loss: 169.2996 - mean_absolute_error: 10.2764\n",
      "Epoch 115/500\n",
      "36/36 [==============================] - 0s 906us/step - loss: 171.5035 - mean_absolute_error: 10.3559\n",
      "Epoch 116/500\n",
      "36/36 [==============================] - 0s 884us/step - loss: 163.7989 - mean_absolute_error: 9.9913\n",
      "Epoch 117/500\n",
      "36/36 [==============================] - 0s 910us/step - loss: 154.3763 - mean_absolute_error: 9.7382\n",
      "Epoch 118/500\n",
      "36/36 [==============================] - 0s 940us/step - loss: 179.4499 - mean_absolute_error: 10.4350\n",
      "Epoch 119/500\n",
      "36/36 [==============================] - 0s 969us/step - loss: 160.1660 - mean_absolute_error: 10.0058\n",
      "Epoch 120/500\n",
      "36/36 [==============================] - 0s 996us/step - loss: 152.9068 - mean_absolute_error: 9.6227\n",
      "Epoch 121/500\n",
      "36/36 [==============================] - 0s 856us/step - loss: 150.1425 - mean_absolute_error: 9.6617\n",
      "Epoch 122/500\n",
      "36/36 [==============================] - 0s 855us/step - loss: 154.0822 - mean_absolute_error: 9.5358\n",
      "Epoch 123/500\n",
      "36/36 [==============================] - 0s 940us/step - loss: 168.9284 - mean_absolute_error: 10.2196\n",
      "Epoch 124/500\n",
      "36/36 [==============================] - 0s 884us/step - loss: 156.7113 - mean_absolute_error: 9.8826\n",
      "Epoch 125/500\n",
      "36/36 [==============================] - 0s 969us/step - loss: 154.0298 - mean_absolute_error: 9.7584\n",
      "Epoch 126/500\n",
      "36/36 [==============================] - 0s 970us/step - loss: 164.7142 - mean_absolute_error: 10.1601\n",
      "Epoch 127/500\n",
      "36/36 [==============================] - 0s 996us/step - loss: 144.0672 - mean_absolute_error: 9.4546\n",
      "Epoch 128/500\n",
      "36/36 [==============================] - 0s 997us/step - loss: 148.5771 - mean_absolute_error: 9.5324\n",
      "Epoch 129/500\n",
      "36/36 [==============================] - 0s 940us/step - loss: 160.5044 - mean_absolute_error: 9.9982\n",
      "Epoch 130/500\n",
      "36/36 [==============================] - 0s 826us/step - loss: 158.3377 - mean_absolute_error: 9.8012\n",
      "Epoch 131/500\n",
      "36/36 [==============================] - 0s 826us/step - loss: 159.1897 - mean_absolute_error: 10.0104\n",
      "Epoch 132/500\n",
      "36/36 [==============================] - 0s 825us/step - loss: 171.4704 - mean_absolute_error: 10.3266\n",
      "Epoch 133/500\n",
      "36/36 [==============================] - 0s 940us/step - loss: 158.2783 - mean_absolute_error: 9.8910\n",
      "Epoch 134/500\n",
      "36/36 [==============================] - 0s 884us/step - loss: 154.3787 - mean_absolute_error: 9.9204\n",
      "Epoch 135/500\n",
      "36/36 [==============================] - 0s 941us/step - loss: 158.1762 - mean_absolute_error: 9.8519\n",
      "Epoch 136/500\n",
      "36/36 [==============================] - 0s 998us/step - loss: 160.8694 - mean_absolute_error: 9.9904\n",
      "Epoch 137/500\n",
      "36/36 [==============================] - 0s 997us/step - loss: 158.7961 - mean_absolute_error: 9.9962\n",
      "Epoch 138/500\n",
      "36/36 [==============================] - 0s 912us/step - loss: 163.0982 - mean_absolute_error: 10.0828\n",
      "Epoch 139/500\n",
      "36/36 [==============================] - 0s 912us/step - loss: 184.2569 - mean_absolute_error: 10.6127\n",
      "Epoch 140/500\n",
      "36/36 [==============================] - 0s 912us/step - loss: 163.2135 - mean_absolute_error: 9.9832\n",
      "Epoch 141/500\n",
      "36/36 [==============================] - 0s 770us/step - loss: 162.3862 - mean_absolute_error: 9.9862\n",
      "Epoch 142/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 853us/step - loss: 165.6886 - mean_absolute_error: 10.2424\n",
      "Epoch 143/500\n",
      "36/36 [==============================] - 0s 940us/step - loss: 153.9055 - mean_absolute_error: 9.8005\n",
      "Epoch 144/500\n",
      "36/36 [==============================] - 0s 970us/step - loss: 158.4314 - mean_absolute_error: 9.9325\n",
      "Epoch 145/500\n",
      "36/36 [==============================] - 0s 883us/step - loss: 174.5543 - mean_absolute_error: 10.3753\n",
      "Epoch 146/500\n",
      "36/36 [==============================] - 0s 912us/step - loss: 158.6280 - mean_absolute_error: 9.9157\n",
      "Epoch 147/500\n",
      "36/36 [==============================] - 0s 941us/step - loss: 167.4897 - mean_absolute_error: 10.1258\n",
      "Epoch 148/500\n",
      "36/36 [==============================] - 0s 971us/step - loss: 154.0006 - mean_absolute_error: 9.6608\n",
      "Epoch 149/500\n",
      "36/36 [==============================] - 0s 940us/step - loss: 154.7888 - mean_absolute_error: 9.8385\n",
      "Epoch 150/500\n",
      "36/36 [==============================] - 0s 912us/step - loss: 147.6522 - mean_absolute_error: 9.5381\n",
      "Epoch 151/500\n",
      "36/36 [==============================] - 0s 881us/step - loss: 147.7461 - mean_absolute_error: 9.5580\n",
      "Epoch 152/500\n",
      "36/36 [==============================] - 0s 826us/step - loss: 162.4120 - mean_absolute_error: 9.9500\n",
      "Epoch 153/500\n",
      "36/36 [==============================] - 0s 969us/step - loss: 150.8407 - mean_absolute_error: 9.8907\n",
      "Epoch 154/500\n",
      "36/36 [==============================] - 0s 969us/step - loss: 162.1815 - mean_absolute_error: 9.7257\n",
      "Epoch 155/500\n",
      "36/36 [==============================] - 0s 752us/step - loss: 163.4920 - mean_absolute_error: 10.1143\n",
      "Epoch 156/500\n",
      "36/36 [==============================] - 0s 997us/step - loss: 147.8967 - mean_absolute_error: 9.5751\n",
      "Epoch 157/500\n",
      "36/36 [==============================] - 0s 847us/step - loss: 162.4098 - mean_absolute_error: 9.9036\n",
      "Epoch 158/500\n",
      "36/36 [==============================] - 0s 951us/step - loss: 160.5694 - mean_absolute_error: 9.8535\n",
      "Epoch 159/500\n",
      "36/36 [==============================] - 0s 912us/step - loss: 155.9711 - mean_absolute_error: 9.8105\n",
      "Epoch 160/500\n",
      "36/36 [==============================] - 0s 883us/step - loss: 158.7511 - mean_absolute_error: 9.8433\n",
      "Epoch 161/500\n",
      "36/36 [==============================] - 0s 969us/step - loss: 136.4799 - mean_absolute_error: 9.3562\n",
      "Epoch 162/500\n",
      "36/36 [==============================] - 0s 997us/step - loss: 149.4800 - mean_absolute_error: 9.4247\n",
      "Epoch 163/500\n",
      "36/36 [==============================] - 0s 997us/step - loss: 153.8772 - mean_absolute_error: 9.5483\n",
      "Epoch 164/500\n",
      "36/36 [==============================] - 0s 940us/step - loss: 155.1350 - mean_absolute_error: 9.7727\n",
      "Epoch 165/500\n",
      "36/36 [==============================] - 0s 972us/step - loss: 149.4448 - mean_absolute_error: 9.7328\n",
      "Epoch 166/500\n",
      "36/36 [==============================] - 0s 974us/step - loss: 144.1907 - mean_absolute_error: 9.4911\n",
      "Epoch 167/500\n",
      "36/36 [==============================] - 0s 855us/step - loss: 151.2394 - mean_absolute_error: 9.8300\n",
      "Epoch 168/500\n",
      "36/36 [==============================] - 0s 791us/step - loss: 164.0369 - mean_absolute_error: 10.1411\n",
      "Epoch 169/500\n",
      "36/36 [==============================] - 0s 826us/step - loss: 159.8697 - mean_absolute_error: 9.9762\n",
      "Epoch 170/500\n",
      "36/36 [==============================] - 0s 780us/step - loss: 156.3915 - mean_absolute_error: 9.6865\n",
      "Epoch 171/500\n",
      "36/36 [==============================] - 0s 713us/step - loss: 142.4019 - mean_absolute_error: 9.3298\n",
      "Epoch 172/500\n",
      "36/36 [==============================] - 0s 884us/step - loss: 160.2753 - mean_absolute_error: 9.8039\n",
      "Epoch 173/500\n",
      "36/36 [==============================] - 0s 954us/step - loss: 173.5847 - mean_absolute_error: 10.2359\n",
      "Epoch 174/500\n",
      "36/36 [==============================] - 0s 856us/step - loss: 144.0751 - mean_absolute_error: 9.3099\n",
      "Epoch 175/500\n",
      "36/36 [==============================] - 0s 831us/step - loss: 142.6985 - mean_absolute_error: 9.3445\n",
      "Epoch 176/500\n",
      "36/36 [==============================] - 0s 940us/step - loss: 154.7454 - mean_absolute_error: 9.6658\n",
      "Epoch 177/500\n",
      "36/36 [==============================] - 0s 827us/step - loss: 153.2826 - mean_absolute_error: 9.8257\n",
      "Epoch 178/500\n",
      "36/36 [==============================] - 0s 797us/step - loss: 142.7316 - mean_absolute_error: 9.4804\n",
      "Epoch 179/500\n",
      "36/36 [==============================] - 0s 798us/step - loss: 148.8993 - mean_absolute_error: 9.5111\n",
      "Epoch 180/500\n",
      "36/36 [==============================] - 0s 741us/step - loss: 152.3398 - mean_absolute_error: 9.5106\n",
      "Epoch 181/500\n",
      "36/36 [==============================] - 0s 770us/step - loss: 154.8438 - mean_absolute_error: 9.7973\n",
      "Epoch 182/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 178.2159 - mean_absolute_error: 10.4475\n",
      "Epoch 183/500\n",
      "36/36 [==============================] - 0s 969us/step - loss: 150.2723 - mean_absolute_error: 9.6630\n",
      "Epoch 184/500\n",
      "36/36 [==============================] - 0s 919us/step - loss: 147.3364 - mean_absolute_error: 9.5921\n",
      "Epoch 185/500\n",
      "36/36 [==============================] - 0s 855us/step - loss: 167.5693 - mean_absolute_error: 10.0619\n",
      "Epoch 186/500\n",
      "36/36 [==============================] - 0s 941us/step - loss: 156.4383 - mean_absolute_error: 9.7881\n",
      "Epoch 187/500\n",
      "36/36 [==============================] - 0s 939us/step - loss: 151.7529 - mean_absolute_error: 9.6466\n",
      "Epoch 188/500\n",
      "36/36 [==============================] - 0s 912us/step - loss: 161.7856 - mean_absolute_error: 9.9049\n",
      "Epoch 189/500\n",
      "36/36 [==============================] - 0s 913us/step - loss: 148.6462 - mean_absolute_error: 9.5515\n",
      "Epoch 190/500\n",
      "36/36 [==============================] - 0s 970us/step - loss: 157.0737 - mean_absolute_error: 9.8335\n",
      "Epoch 191/500\n",
      "36/36 [==============================] - 0s 969us/step - loss: 157.0324 - mean_absolute_error: 9.7627\n",
      "Epoch 192/500\n",
      "36/36 [==============================] - 0s 968us/step - loss: 155.2156 - mean_absolute_error: 9.7051\n",
      "Epoch 193/500\n",
      "36/36 [==============================] - 0s 969us/step - loss: 136.0091 - mean_absolute_error: 9.1195\n",
      "Epoch 194/500\n",
      "36/36 [==============================] - 0s 913us/step - loss: 141.9445 - mean_absolute_error: 9.4771\n",
      "Epoch 195/500\n",
      "36/36 [==============================] - 0s 969us/step - loss: 159.5899 - mean_absolute_error: 9.8135\n",
      "Epoch 196/500\n",
      "36/36 [==============================] - 0s 912us/step - loss: 135.5558 - mean_absolute_error: 9.0600\n",
      "Epoch 197/500\n",
      "36/36 [==============================] - 0s 940us/step - loss: 158.8322 - mean_absolute_error: 9.9489\n",
      "Epoch 198/500\n",
      "36/36 [==============================] - 0s 969us/step - loss: 157.6095 - mean_absolute_error: 9.9625\n",
      "Epoch 199/500\n",
      "36/36 [==============================] - 0s 961us/step - loss: 148.4365 - mean_absolute_error: 9.5293\n",
      "Epoch 200/500\n",
      "36/36 [==============================] - 0s 949us/step - loss: 155.2461 - mean_absolute_error: 9.6907\n",
      "Epoch 201/500\n",
      "36/36 [==============================] - 0s 940us/step - loss: 145.3722 - mean_absolute_error: 9.3856\n",
      "Epoch 202/500\n",
      "36/36 [==============================] - 0s 848us/step - loss: 146.1655 - mean_absolute_error: 9.6556\n",
      "Epoch 203/500\n",
      "36/36 [==============================] - 0s 912us/step - loss: 153.5301 - mean_absolute_error: 9.7726\n",
      "Epoch 204/500\n",
      "36/36 [==============================] - 0s 912us/step - loss: 162.1560 - mean_absolute_error: 10.0765\n",
      "Epoch 205/500\n",
      "36/36 [==============================] - 0s 912us/step - loss: 167.4855 - mean_absolute_error: 10.2892\n",
      "Epoch 206/500\n",
      "36/36 [==============================] - 0s 940us/step - loss: 153.7859 - mean_absolute_error: 9.7312\n",
      "Epoch 207/500\n",
      "36/36 [==============================] - 0s 946us/step - loss: 153.9033 - mean_absolute_error: 9.6954\n",
      "Epoch 208/500\n",
      "36/36 [==============================] - 0s 940us/step - loss: 167.1416 - mean_absolute_error: 10.0369\n",
      "Epoch 209/500\n",
      "36/36 [==============================] - 0s 883us/step - loss: 144.3875 - mean_absolute_error: 9.3762\n",
      "Epoch 210/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 149.6754 - mean_absolute_error: 9.6949\n",
      "Epoch 211/500\n",
      "36/36 [==============================] - 0s 884us/step - loss: 134.1149 - mean_absolute_error: 9.1282\n",
      "Epoch 212/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 883us/step - loss: 149.2881 - mean_absolute_error: 9.6898\n",
      "Epoch 213/500\n",
      "36/36 [==============================] - 0s 855us/step - loss: 148.0709 - mean_absolute_error: 9.6672\n",
      "Epoch 214/500\n",
      "36/36 [==============================] - 0s 855us/step - loss: 142.6612 - mean_absolute_error: 9.5341\n",
      "Epoch 215/500\n",
      "36/36 [==============================] - 0s 794us/step - loss: 165.7128 - mean_absolute_error: 10.1852\n",
      "Epoch 216/500\n",
      "36/36 [==============================] - 0s 798us/step - loss: 141.4892 - mean_absolute_error: 9.3536\n",
      "Epoch 217/500\n",
      "36/36 [==============================] - 0s 763us/step - loss: 148.2774 - mean_absolute_error: 9.5206\n",
      "Epoch 218/500\n",
      "36/36 [==============================] - 0s 769us/step - loss: 167.3941 - mean_absolute_error: 10.0613\n",
      "Epoch 219/500\n",
      "36/36 [==============================] - 0s 883us/step - loss: 135.3159 - mean_absolute_error: 9.2171\n",
      "Epoch 220/500\n",
      "36/36 [==============================] - 0s 855us/step - loss: 152.7637 - mean_absolute_error: 9.7406\n",
      "Epoch 221/500\n",
      "36/36 [==============================] - 0s 851us/step - loss: 157.1332 - mean_absolute_error: 9.9454\n",
      "Epoch 222/500\n",
      "36/36 [==============================] - 0s 857us/step - loss: 155.0148 - mean_absolute_error: 9.9270\n",
      "Epoch 223/500\n",
      "36/36 [==============================] - 0s 826us/step - loss: 140.4023 - mean_absolute_error: 9.4569\n",
      "Epoch 224/500\n",
      "36/36 [==============================] - 0s 853us/step - loss: 154.7767 - mean_absolute_error: 9.6993\n",
      "Epoch 225/500\n",
      "36/36 [==============================] - 0s 826us/step - loss: 146.7175 - mean_absolute_error: 9.5246\n",
      "Epoch 226/500\n",
      "36/36 [==============================] - 0s 795us/step - loss: 145.9666 - mean_absolute_error: 9.4106\n",
      "Epoch 227/500\n",
      "36/36 [==============================] - 0s 809us/step - loss: 148.3576 - mean_absolute_error: 9.3723\n",
      "Epoch 228/500\n",
      "36/36 [==============================] - 0s 798us/step - loss: 155.4554 - mean_absolute_error: 9.5739\n",
      "Epoch 229/500\n",
      "36/36 [==============================] - 0s 795us/step - loss: 159.4797 - mean_absolute_error: 9.8902\n",
      "Epoch 230/500\n",
      "36/36 [==============================] - 0s 824us/step - loss: 141.0030 - mean_absolute_error: 9.3115\n",
      "Epoch 231/500\n",
      "36/36 [==============================] - 0s 862us/step - loss: 157.5750 - mean_absolute_error: 9.9034\n",
      "Epoch 232/500\n",
      "36/36 [==============================] - 0s 742us/step - loss: 149.5821 - mean_absolute_error: 9.6147\n",
      "Epoch 233/500\n",
      "36/36 [==============================] - 0s 820us/step - loss: 141.2655 - mean_absolute_error: 9.2827\n",
      "Epoch 234/500\n",
      "36/36 [==============================] - 0s 826us/step - loss: 145.6427 - mean_absolute_error: 9.3386\n",
      "Epoch 235/500\n",
      "36/36 [==============================] - 0s 850us/step - loss: 155.7022 - mean_absolute_error: 9.7772\n",
      "Epoch 236/500\n",
      "36/36 [==============================] - 0s 754us/step - loss: 155.3578 - mean_absolute_error: 9.7891\n",
      "Epoch 237/500\n",
      "36/36 [==============================] - 0s 787us/step - loss: 145.4651 - mean_absolute_error: 9.5222\n",
      "Epoch 238/500\n",
      "36/36 [==============================] - 0s 826us/step - loss: 147.4435 - mean_absolute_error: 9.3448\n",
      "Epoch 239/500\n",
      "36/36 [==============================] - 0s 832us/step - loss: 155.8956 - mean_absolute_error: 9.8622\n",
      "Epoch 240/500\n",
      "36/36 [==============================] - 0s 998us/step - loss: 148.2654 - mean_absolute_error: 9.6423\n",
      "Epoch 241/500\n",
      "36/36 [==============================] - 0s 940us/step - loss: 146.6967 - mean_absolute_error: 9.6458\n",
      "Epoch 242/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 142.1244 - mean_absolute_error: 9.3616\n",
      "Epoch 243/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 153.3526 - mean_absolute_error: 9.8087\n",
      "Epoch 244/500\n",
      "36/36 [==============================] - 0s 969us/step - loss: 143.1546 - mean_absolute_error: 9.4401\n",
      "Epoch 245/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 145.1311 - mean_absolute_error: 9.4715\n",
      "Epoch 246/500\n",
      "36/36 [==============================] - 0s 997us/step - loss: 162.2979 - mean_absolute_error: 10.0398\n",
      "Epoch 247/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 151.3878 - mean_absolute_error: 9.6923\n",
      "Epoch 248/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 150.8036 - mean_absolute_error: 9.7579\n",
      "Epoch 249/500\n",
      "36/36 [==============================] - 0s 969us/step - loss: 145.4798 - mean_absolute_error: 9.5405\n",
      "Epoch 250/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 143.5887 - mean_absolute_error: 9.3029\n",
      "Epoch 251/500\n",
      "36/36 [==============================] - 0s 856us/step - loss: 158.8098 - mean_absolute_error: 9.9456\n",
      "Epoch 252/500\n",
      "36/36 [==============================] - 0s 912us/step - loss: 146.1781 - mean_absolute_error: 9.5309\n",
      "Epoch 253/500\n",
      "36/36 [==============================] - 0s 855us/step - loss: 140.3986 - mean_absolute_error: 9.3827\n",
      "Epoch 254/500\n",
      "36/36 [==============================] - 0s 855us/step - loss: 148.1884 - mean_absolute_error: 9.6133\n",
      "Epoch 255/500\n",
      "36/36 [==============================] - 0s 826us/step - loss: 151.8647 - mean_absolute_error: 9.6866\n",
      "Epoch 256/500\n",
      "36/36 [==============================] - 0s 826us/step - loss: 149.6980 - mean_absolute_error: 9.6619\n",
      "Epoch 257/500\n",
      "36/36 [==============================] - 0s 834us/step - loss: 159.7666 - mean_absolute_error: 10.0364\n",
      "Epoch 258/500\n",
      "36/36 [==============================] - 0s 826us/step - loss: 151.1523 - mean_absolute_error: 9.7764\n",
      "Epoch 259/500\n",
      "36/36 [==============================] - 0s 798us/step - loss: 137.9480 - mean_absolute_error: 9.1918\n",
      "Epoch 260/500\n",
      "36/36 [==============================] - 0s 798us/step - loss: 152.5931 - mean_absolute_error: 9.7282\n",
      "Epoch 261/500\n",
      "36/36 [==============================] - 0s 798us/step - loss: 155.3574 - mean_absolute_error: 9.7987\n",
      "Epoch 262/500\n",
      "36/36 [==============================] - 0s 870us/step - loss: 164.0787 - mean_absolute_error: 9.8320\n",
      "Epoch 263/500\n",
      "36/36 [==============================] - 0s 911us/step - loss: 148.2406 - mean_absolute_error: 9.6313\n",
      "Epoch 264/500\n",
      "36/36 [==============================] - 0s 995us/step - loss: 141.9625 - mean_absolute_error: 9.3541\n",
      "Epoch 265/500\n",
      "36/36 [==============================] - 0s 864us/step - loss: 147.8091 - mean_absolute_error: 9.6066\n",
      "Epoch 266/500\n",
      "36/36 [==============================] - 0s 799us/step - loss: 154.1096 - mean_absolute_error: 9.6141\n",
      "Epoch 267/500\n",
      "36/36 [==============================] - 0s 826us/step - loss: 145.6803 - mean_absolute_error: 9.4472\n",
      "Epoch 268/500\n",
      "36/36 [==============================] - 0s 826us/step - loss: 161.2784 - mean_absolute_error: 9.8525\n",
      "Epoch 269/500\n",
      "36/36 [==============================] - 0s 826us/step - loss: 141.4088 - mean_absolute_error: 9.3569\n",
      "Epoch 270/500\n",
      "36/36 [==============================] - 0s 833us/step - loss: 154.0770 - mean_absolute_error: 9.6809\n",
      "Epoch 271/500\n",
      "36/36 [==============================] - 0s 829us/step - loss: 142.7540 - mean_absolute_error: 9.4631\n",
      "Epoch 272/500\n",
      "36/36 [==============================] - 0s 817us/step - loss: 135.6289 - mean_absolute_error: 9.0125\n",
      "Epoch 273/500\n",
      "36/36 [==============================] - 0s 742us/step - loss: 149.7082 - mean_absolute_error: 9.6076\n",
      "Epoch 274/500\n",
      "36/36 [==============================] - 0s 941us/step - loss: 144.4409 - mean_absolute_error: 9.4710\n",
      "Epoch 275/500\n",
      "36/36 [==============================] - 0s 969us/step - loss: 144.0662 - mean_absolute_error: 9.4277\n",
      "Epoch 276/500\n",
      "36/36 [==============================] - 0s 894us/step - loss: 142.2088 - mean_absolute_error: 9.3999\n",
      "Epoch 277/500\n",
      "36/36 [==============================] - 0s 969us/step - loss: 142.1280 - mean_absolute_error: 9.5132\n",
      "Epoch 278/500\n",
      "36/36 [==============================] - 0s 970us/step - loss: 150.9910 - mean_absolute_error: 9.6282\n",
      "Epoch 279/500\n",
      "36/36 [==============================] - 0s 941us/step - loss: 139.8837 - mean_absolute_error: 9.3711\n",
      "Epoch 280/500\n",
      "36/36 [==============================] - 0s 884us/step - loss: 138.7678 - mean_absolute_error: 9.2089\n",
      "Epoch 281/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 148.2775 - mean_absolute_error: 9.5814\n",
      "Epoch 282/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 845us/step - loss: 157.4908 - mean_absolute_error: 9.9337\n",
      "Epoch 283/500\n",
      "36/36 [==============================] - 0s 799us/step - loss: 150.9042 - mean_absolute_error: 9.8017\n",
      "Epoch 284/500\n",
      "36/36 [==============================] - 0s 997us/step - loss: 150.3667 - mean_absolute_error: 9.6270\n",
      "Epoch 285/500\n",
      "36/36 [==============================] - 0s 883us/step - loss: 134.5975 - mean_absolute_error: 9.2434\n",
      "Epoch 286/500\n",
      "36/36 [==============================] - 0s 832us/step - loss: 148.8427 - mean_absolute_error: 9.3551\n",
      "Epoch 287/500\n",
      "36/36 [==============================] - 0s 855us/step - loss: 153.6413 - mean_absolute_error: 9.7594\n",
      "Epoch 288/500\n",
      "36/36 [==============================] - 0s 884us/step - loss: 145.1453 - mean_absolute_error: 9.4475\n",
      "Epoch 289/500\n",
      "36/36 [==============================] - 0s 855us/step - loss: 151.1519 - mean_absolute_error: 9.5945\n",
      "Epoch 290/500\n",
      "36/36 [==============================] - 0s 855us/step - loss: 150.2152 - mean_absolute_error: 9.5569\n",
      "Epoch 291/500\n",
      "36/36 [==============================] - 0s 798us/step - loss: 150.1829 - mean_absolute_error: 9.7632\n",
      "Epoch 292/500\n",
      "36/36 [==============================] - 0s 912us/step - loss: 153.8152 - mean_absolute_error: 9.7331\n",
      "Epoch 293/500\n",
      "36/36 [==============================] - 0s 912us/step - loss: 149.7298 - mean_absolute_error: 9.6474\n",
      "Epoch 294/500\n",
      "36/36 [==============================] - 0s 855us/step - loss: 138.7475 - mean_absolute_error: 9.2784\n",
      "Epoch 295/500\n",
      "36/36 [==============================] - 0s 912us/step - loss: 147.4519 - mean_absolute_error: 9.4993\n",
      "Epoch 296/500\n",
      "36/36 [==============================] - 0s 941us/step - loss: 156.7409 - mean_absolute_error: 9.8464\n",
      "Epoch 297/500\n",
      "36/36 [==============================] - 0s 912us/step - loss: 149.7083 - mean_absolute_error: 9.5103\n",
      "Epoch 298/500\n",
      "36/36 [==============================] - 0s 912us/step - loss: 151.7067 - mean_absolute_error: 9.7757\n",
      "Epoch 299/500\n",
      "36/36 [==============================] - 0s 855us/step - loss: 140.2187 - mean_absolute_error: 9.1318\n",
      "Epoch 300/500\n",
      "36/36 [==============================] - 0s 881us/step - loss: 154.3698 - mean_absolute_error: 9.7223\n",
      "Epoch 301/500\n",
      "36/36 [==============================] - 0s 898us/step - loss: 134.5820 - mean_absolute_error: 9.2437\n",
      "Epoch 302/500\n",
      "36/36 [==============================] - 0s 970us/step - loss: 153.7835 - mean_absolute_error: 9.7952\n",
      "Epoch 303/500\n",
      "36/36 [==============================] - 0s 991us/step - loss: 138.6667 - mean_absolute_error: 9.3240\n",
      "Epoch 304/500\n",
      "36/36 [==============================] - 0s 969us/step - loss: 154.3793 - mean_absolute_error: 9.8772\n",
      "Epoch 305/500\n",
      "36/36 [==============================] - 0s 798us/step - loss: 161.8342 - mean_absolute_error: 9.9251\n",
      "Epoch 306/500\n",
      "36/36 [==============================] - 0s 940us/step - loss: 151.9011 - mean_absolute_error: 9.5757\n",
      "Epoch 307/500\n",
      "36/36 [==============================] - 0s 925us/step - loss: 144.1559 - mean_absolute_error: 9.3967\n",
      "Epoch 308/500\n",
      "36/36 [==============================] - 0s 826us/step - loss: 170.3993 - mean_absolute_error: 10.3437\n",
      "Epoch 309/500\n",
      "36/36 [==============================] - 0s 855us/step - loss: 141.6181 - mean_absolute_error: 9.3612\n",
      "Epoch 310/500\n",
      "36/36 [==============================] - 0s 883us/step - loss: 135.3432 - mean_absolute_error: 9.0999\n",
      "Epoch 311/500\n",
      "36/36 [==============================] - 0s 855us/step - loss: 140.8626 - mean_absolute_error: 9.3111\n",
      "Epoch 312/500\n",
      "36/36 [==============================] - 0s 836us/step - loss: 152.0071 - mean_absolute_error: 9.5986\n",
      "Epoch 313/500\n",
      "36/36 [==============================] - 0s 854us/step - loss: 155.2249 - mean_absolute_error: 9.8896\n",
      "Epoch 314/500\n",
      "36/36 [==============================] - 0s 827us/step - loss: 138.1309 - mean_absolute_error: 9.2914\n",
      "Epoch 315/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 151.5820 - mean_absolute_error: 9.6548\n",
      "Epoch 316/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 148.3887 - mean_absolute_error: 9.6264\n",
      "Epoch 317/500\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 150.0215 - mean_absolute_error: 9.4833\n",
      "Epoch 318/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 153.4817 - mean_absolute_error: 9.5754\n",
      "Epoch 319/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 150.0090 - mean_absolute_error: 9.7445\n",
      "Epoch 320/500\n",
      "36/36 [==============================] - 0s 912us/step - loss: 163.1551 - mean_absolute_error: 9.8760\n",
      "Epoch 321/500\n",
      "36/36 [==============================] - 0s 912us/step - loss: 144.8953 - mean_absolute_error: 9.5959\n",
      "Epoch 322/500\n",
      "36/36 [==============================] - 0s 883us/step - loss: 159.7177 - mean_absolute_error: 10.0442\n",
      "Epoch 323/500\n",
      "36/36 [==============================] - 0s 883us/step - loss: 151.5205 - mean_absolute_error: 9.5153\n",
      "Epoch 324/500\n",
      "36/36 [==============================] - 0s 855us/step - loss: 147.9162 - mean_absolute_error: 9.4351\n",
      "Epoch 325/500\n",
      "36/36 [==============================] - 0s 940us/step - loss: 140.3020 - mean_absolute_error: 9.2340\n",
      "Epoch 326/500\n",
      "36/36 [==============================] - 0s 970us/step - loss: 156.6559 - mean_absolute_error: 9.5726\n",
      "Epoch 327/500\n",
      "36/36 [==============================] - 0s 912us/step - loss: 157.4455 - mean_absolute_error: 9.9697\n",
      "Epoch 328/500\n",
      "36/36 [==============================] - 0s 798us/step - loss: 152.2958 - mean_absolute_error: 9.6445\n",
      "Epoch 329/500\n",
      "36/36 [==============================] - 0s 855us/step - loss: 152.7505 - mean_absolute_error: 9.6537\n",
      "Epoch 330/500\n",
      "36/36 [==============================] - 0s 969us/step - loss: 148.0523 - mean_absolute_error: 9.7252\n",
      "Epoch 331/500\n",
      "36/36 [==============================] - 0s 883us/step - loss: 136.0041 - mean_absolute_error: 9.2823\n",
      "Epoch 332/500\n",
      "36/36 [==============================] - 0s 912us/step - loss: 139.8192 - mean_absolute_error: 9.4064\n",
      "Epoch 333/500\n",
      "36/36 [==============================] - 0s 826us/step - loss: 149.7294 - mean_absolute_error: 9.3878\n",
      "Epoch 334/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 150.2986 - mean_absolute_error: 9.4441\n",
      "Epoch 335/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 143.8748 - mean_absolute_error: 9.3965\n",
      "Epoch 336/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 155.7207 - mean_absolute_error: 9.9207\n",
      "Epoch 337/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 152.5390 - mean_absolute_error: 9.5718\n",
      "Epoch 338/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 158.3380 - mean_absolute_error: 9.8422\n",
      "Epoch 339/500\n",
      "36/36 [==============================] - 0s 883us/step - loss: 140.5986 - mean_absolute_error: 9.3359\n",
      "Epoch 340/500\n",
      "36/36 [==============================] - 0s 855us/step - loss: 141.8006 - mean_absolute_error: 9.3854\n",
      "Epoch 341/500\n",
      "36/36 [==============================] - 0s 826us/step - loss: 150.4024 - mean_absolute_error: 9.5296\n",
      "Epoch 342/500\n",
      "36/36 [==============================] - 0s 827us/step - loss: 162.6757 - mean_absolute_error: 10.0355\n",
      "Epoch 343/500\n",
      "36/36 [==============================] - 0s 826us/step - loss: 166.9304 - mean_absolute_error: 9.9874\n",
      "Epoch 344/500\n",
      "36/36 [==============================] - 0s 912us/step - loss: 145.1818 - mean_absolute_error: 9.6249\n",
      "Epoch 345/500\n",
      "36/36 [==============================] - 0s 883us/step - loss: 138.0436 - mean_absolute_error: 9.2527\n",
      "Epoch 346/500\n",
      "36/36 [==============================] - 0s 912us/step - loss: 147.2893 - mean_absolute_error: 9.5351\n",
      "Epoch 347/500\n",
      "36/36 [==============================] - 0s 883us/step - loss: 146.1325 - mean_absolute_error: 9.4699\n",
      "Epoch 348/500\n",
      "36/36 [==============================] - 0s 913us/step - loss: 147.6632 - mean_absolute_error: 9.6666\n",
      "Epoch 349/500\n",
      "36/36 [==============================] - 0s 826us/step - loss: 135.8768 - mean_absolute_error: 9.1173\n",
      "Epoch 350/500\n",
      "36/36 [==============================] - 0s 912us/step - loss: 159.3022 - mean_absolute_error: 9.7691\n",
      "Epoch 351/500\n",
      "36/36 [==============================] - 0s 856us/step - loss: 157.5323 - mean_absolute_error: 9.6214\n",
      "Epoch 352/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 826us/step - loss: 145.5605 - mean_absolute_error: 9.4442\n",
      "Epoch 353/500\n",
      "36/36 [==============================] - 0s 939us/step - loss: 154.4130 - mean_absolute_error: 9.8969\n",
      "Epoch 354/500\n",
      "36/36 [==============================] - 0s 884us/step - loss: 138.5193 - mean_absolute_error: 9.2124\n",
      "Epoch 355/500\n",
      "36/36 [==============================] - 0s 826us/step - loss: 141.5349 - mean_absolute_error: 9.2923\n",
      "Epoch 356/500\n",
      "36/36 [==============================] - 0s 940us/step - loss: 141.8201 - mean_absolute_error: 9.2168\n",
      "Epoch 357/500\n",
      "36/36 [==============================] - 0s 912us/step - loss: 150.6088 - mean_absolute_error: 9.6245\n",
      "Epoch 358/500\n",
      "36/36 [==============================] - ETA: 0s - loss: 193.5280 - mean_absolute_error: 10.42 - 0s 1ms/step - loss: 151.4538 - mean_absolute_error: 9.7375\n",
      "Epoch 359/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 158.7831 - mean_absolute_error: 9.8371\n",
      "Epoch 360/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 153.8410 - mean_absolute_error: 9.6149\n",
      "Epoch 361/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 173.7155 - mean_absolute_error: 10.3849\n",
      "Epoch 362/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 147.7422 - mean_absolute_error: 9.5425\n",
      "Epoch 363/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 156.4349 - mean_absolute_error: 9.8118\n",
      "Epoch 364/500\n",
      "36/36 [==============================] - 0s 912us/step - loss: 164.2659 - mean_absolute_error: 9.9077\n",
      "Epoch 365/500\n",
      "36/36 [==============================] - 0s 889us/step - loss: 156.6757 - mean_absolute_error: 9.7626\n",
      "Epoch 366/500\n",
      "36/36 [==============================] - 0s 940us/step - loss: 144.2886 - mean_absolute_error: 9.4331\n",
      "Epoch 367/500\n",
      "36/36 [==============================] - 0s 940us/step - loss: 148.3986 - mean_absolute_error: 9.5449\n",
      "Epoch 368/500\n",
      "36/36 [==============================] - 0s 938us/step - loss: 153.6964 - mean_absolute_error: 9.6559\n",
      "Epoch 369/500\n",
      "36/36 [==============================] - 0s 940us/step - loss: 149.9308 - mean_absolute_error: 9.5054\n",
      "Epoch 370/500\n",
      "36/36 [==============================] - 0s 976us/step - loss: 149.1434 - mean_absolute_error: 9.7961\n",
      "Epoch 371/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 156.2529 - mean_absolute_error: 9.6287\n",
      "Epoch 372/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 134.7984 - mean_absolute_error: 9.1994\n",
      "Epoch 373/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 149.4507 - mean_absolute_error: 9.5225\n",
      "Epoch 374/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 159.5283 - mean_absolute_error: 9.7218\n",
      "Epoch 375/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 143.4092 - mean_absolute_error: 9.4397\n",
      "Epoch 376/500\n",
      "36/36 [==============================] - 0s 998us/step - loss: 148.9507 - mean_absolute_error: 9.6034\n",
      "Epoch 377/500\n",
      "36/36 [==============================] - 0s 911us/step - loss: 158.3377 - mean_absolute_error: 9.8517\n",
      "Epoch 378/500\n",
      "36/36 [==============================] - 0s 855us/step - loss: 138.2400 - mean_absolute_error: 9.1710\n",
      "Epoch 379/500\n",
      "36/36 [==============================] - 0s 911us/step - loss: 140.1023 - mean_absolute_error: 9.4982\n",
      "Epoch 380/500\n",
      "36/36 [==============================] - 0s 991us/step - loss: 147.6842 - mean_absolute_error: 9.4789\n",
      "Epoch 381/500\n",
      "36/36 [==============================] - 0s 912us/step - loss: 137.2128 - mean_absolute_error: 9.3293\n",
      "Epoch 382/500\n",
      "36/36 [==============================] - 0s 940us/step - loss: 137.7583 - mean_absolute_error: 9.2247\n",
      "Epoch 383/500\n",
      "36/36 [==============================] - 0s 942us/step - loss: 136.7226 - mean_absolute_error: 9.1992\n",
      "Epoch 384/500\n",
      "36/36 [==============================] - 0s 940us/step - loss: 147.3016 - mean_absolute_error: 9.6458\n",
      "Epoch 385/500\n",
      "36/36 [==============================] - 0s 953us/step - loss: 141.9318 - mean_absolute_error: 9.4024\n",
      "Epoch 386/500\n",
      "36/36 [==============================] - 0s 856us/step - loss: 155.8938 - mean_absolute_error: 10.0273\n",
      "Epoch 387/500\n",
      "36/36 [==============================] - 0s 912us/step - loss: 149.7976 - mean_absolute_error: 9.7612\n",
      "Epoch 388/500\n",
      "36/36 [==============================] - 0s 883us/step - loss: 149.6848 - mean_absolute_error: 9.5363\n",
      "Epoch 389/500\n",
      "36/36 [==============================] - 0s 883us/step - loss: 141.0313 - mean_absolute_error: 9.4657\n",
      "Epoch 390/500\n",
      "36/36 [==============================] - 0s 940us/step - loss: 157.0423 - mean_absolute_error: 9.7443\n",
      "Epoch 391/500\n",
      "36/36 [==============================] - 0s 941us/step - loss: 138.8041 - mean_absolute_error: 9.2534\n",
      "Epoch 392/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 147.4915 - mean_absolute_error: 9.4756\n",
      "Epoch 393/500\n",
      "36/36 [==============================] - 0s 855us/step - loss: 148.7750 - mean_absolute_error: 9.6353\n",
      "Epoch 394/500\n",
      "36/36 [==============================] - 0s 882us/step - loss: 141.7876 - mean_absolute_error: 9.2697\n",
      "Epoch 395/500\n",
      "36/36 [==============================] - 0s 884us/step - loss: 158.7685 - mean_absolute_error: 9.8746\n",
      "Epoch 396/500\n",
      "36/36 [==============================] - 0s 883us/step - loss: 143.2812 - mean_absolute_error: 9.5148\n",
      "Epoch 397/500\n",
      "36/36 [==============================] - 0s 855us/step - loss: 141.8310 - mean_absolute_error: 9.2613\n",
      "Epoch 398/500\n",
      "36/36 [==============================] - 0s 912us/step - loss: 158.5032 - mean_absolute_error: 9.8394\n",
      "Epoch 399/500\n",
      "36/36 [==============================] - 0s 969us/step - loss: 142.1555 - mean_absolute_error: 9.2308\n",
      "Epoch 400/500\n",
      "36/36 [==============================] - 0s 940us/step - loss: 144.1575 - mean_absolute_error: 9.4382\n",
      "Epoch 401/500\n",
      "36/36 [==============================] - 0s 968us/step - loss: 142.1093 - mean_absolute_error: 9.4650\n",
      "Epoch 402/500\n",
      "36/36 [==============================] - 0s 882us/step - loss: 146.3560 - mean_absolute_error: 9.5987\n",
      "Epoch 403/500\n",
      "36/36 [==============================] - 0s 983us/step - loss: 141.8456 - mean_absolute_error: 9.1868\n",
      "Epoch 404/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 148.4087 - mean_absolute_error: 9.7090\n",
      "Epoch 405/500\n",
      "36/36 [==============================] - 0s 997us/step - loss: 141.5916 - mean_absolute_error: 9.4565\n",
      "Epoch 406/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 145.1810 - mean_absolute_error: 9.1983\n",
      "Epoch 407/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 145.0509 - mean_absolute_error: 9.4339\n",
      "Epoch 408/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 139.5297 - mean_absolute_error: 9.3350\n",
      "Epoch 409/500\n",
      "36/36 [==============================] - 0s 968us/step - loss: 145.8704 - mean_absolute_error: 9.5998\n",
      "Epoch 410/500\n",
      "36/36 [==============================] - 0s 997us/step - loss: 143.1996 - mean_absolute_error: 9.3314\n",
      "Epoch 411/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 152.2291 - mean_absolute_error: 9.6997\n",
      "Epoch 412/500\n",
      "36/36 [==============================] - 0s 940us/step - loss: 157.0246 - mean_absolute_error: 9.8343\n",
      "Epoch 413/500\n",
      "36/36 [==============================] - 0s 940us/step - loss: 155.3473 - mean_absolute_error: 9.7410\n",
      "Epoch 414/500\n",
      "36/36 [==============================] - 0s 940us/step - loss: 147.5410 - mean_absolute_error: 9.6767\n",
      "Epoch 415/500\n",
      "36/36 [==============================] - 0s 883us/step - loss: 139.5281 - mean_absolute_error: 9.3760\n",
      "Epoch 416/500\n",
      "36/36 [==============================] - 0s 883us/step - loss: 149.3695 - mean_absolute_error: 9.6186\n",
      "Epoch 417/500\n",
      "36/36 [==============================] - 0s 941us/step - loss: 149.8238 - mean_absolute_error: 9.6654\n",
      "Epoch 418/500\n",
      "36/36 [==============================] - 0s 912us/step - loss: 154.0028 - mean_absolute_error: 9.7915\n",
      "Epoch 419/500\n",
      "36/36 [==============================] - 0s 940us/step - loss: 148.5231 - mean_absolute_error: 9.5682\n",
      "Epoch 420/500\n",
      "36/36 [==============================] - 0s 969us/step - loss: 136.6755 - mean_absolute_error: 9.1713\n",
      "Epoch 421/500\n",
      "36/36 [==============================] - 0s 912us/step - loss: 147.0201 - mean_absolute_error: 9.6024\n",
      "Epoch 422/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 882us/step - loss: 142.7413 - mean_absolute_error: 9.4316\n",
      "Epoch 423/500\n",
      "36/36 [==============================] - 0s 954us/step - loss: 156.1572 - mean_absolute_error: 9.8475\n",
      "Epoch 424/500\n",
      "36/36 [==============================] - 0s 940us/step - loss: 138.6575 - mean_absolute_error: 9.1613\n",
      "Epoch 425/500\n",
      "36/36 [==============================] - 0s 969us/step - loss: 143.0409 - mean_absolute_error: 9.3699\n",
      "Epoch 426/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 150.3546 - mean_absolute_error: 9.5431\n",
      "Epoch 427/500\n",
      "36/36 [==============================] - 0s 984us/step - loss: 150.3301 - mean_absolute_error: 9.6140\n",
      "Epoch 428/500\n",
      "36/36 [==============================] - 0s 941us/step - loss: 144.7913 - mean_absolute_error: 9.4128\n",
      "Epoch 429/500\n",
      "36/36 [==============================] - 0s 884us/step - loss: 148.7341 - mean_absolute_error: 9.5215\n",
      "Epoch 430/500\n",
      "36/36 [==============================] - 0s 999us/step - loss: 142.0697 - mean_absolute_error: 9.5443\n",
      "Epoch 431/500\n",
      "36/36 [==============================] - 0s 912us/step - loss: 132.2327 - mean_absolute_error: 8.9470\n",
      "Epoch 432/500\n",
      "36/36 [==============================] - 0s 883us/step - loss: 138.7469 - mean_absolute_error: 9.3311\n",
      "Epoch 433/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 141.1822 - mean_absolute_error: 9.3277\n",
      "Epoch 434/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 154.6039 - mean_absolute_error: 9.8168\n",
      "Epoch 435/500\n",
      "36/36 [==============================] - 0s 940us/step - loss: 150.0074 - mean_absolute_error: 9.5730\n",
      "Epoch 436/500\n",
      "36/36 [==============================] - 0s 912us/step - loss: 156.4339 - mean_absolute_error: 9.7645\n",
      "Epoch 437/500\n",
      "36/36 [==============================] - 0s 912us/step - loss: 135.1731 - mean_absolute_error: 9.1707\n",
      "Epoch 438/500\n",
      "36/36 [==============================] - 0s 926us/step - loss: 133.5112 - mean_absolute_error: 9.0520\n",
      "Epoch 439/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 143.2956 - mean_absolute_error: 9.6622\n",
      "Epoch 440/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 152.0167 - mean_absolute_error: 9.7371\n",
      "Epoch 441/500\n",
      "36/36 [==============================] - 0s 997us/step - loss: 155.2977 - mean_absolute_error: 9.7072\n",
      "Epoch 442/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 134.2380 - mean_absolute_error: 9.1894\n",
      "Epoch 443/500\n",
      "36/36 [==============================] - 0s 1000us/step - loss: 170.1068 - mean_absolute_error: 10.2890\n",
      "Epoch 444/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 138.0262 - mean_absolute_error: 9.2117\n",
      "Epoch 445/500\n",
      "36/36 [==============================] - 0s 998us/step - loss: 130.9714 - mean_absolute_error: 9.0452\n",
      "Epoch 446/500\n",
      "36/36 [==============================] - 0s 945us/step - loss: 150.2704 - mean_absolute_error: 9.5651\n",
      "Epoch 447/500\n",
      "36/36 [==============================] - 0s 935us/step - loss: 139.9340 - mean_absolute_error: 9.3709\n",
      "Epoch 448/500\n",
      "36/36 [==============================] - 0s 940us/step - loss: 149.3822 - mean_absolute_error: 9.5385\n",
      "Epoch 449/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 153.3425 - mean_absolute_error: 9.7194\n",
      "Epoch 450/500\n",
      "36/36 [==============================] - 0s 997us/step - loss: 160.4748 - mean_absolute_error: 9.8647\n",
      "Epoch 451/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 149.7223 - mean_absolute_error: 9.7563\n",
      "Epoch 452/500\n",
      "36/36 [==============================] - 0s 970us/step - loss: 140.2384 - mean_absolute_error: 9.3148\n",
      "Epoch 453/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 143.9611 - mean_absolute_error: 9.3907\n",
      "Epoch 454/500\n",
      "36/36 [==============================] - 0s 946us/step - loss: 136.9411 - mean_absolute_error: 9.2207\n",
      "Epoch 455/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 143.2604 - mean_absolute_error: 9.6171\n",
      "Epoch 456/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 146.6731 - mean_absolute_error: 9.7482\n",
      "Epoch 457/500\n",
      "36/36 [==============================] - 0s 997us/step - loss: 144.2864 - mean_absolute_error: 9.3874\n",
      "Epoch 458/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 156.4503 - mean_absolute_error: 9.8560\n",
      "Epoch 459/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 141.8741 - mean_absolute_error: 9.3913\n",
      "Epoch 460/500\n",
      "36/36 [==============================] - 0s 940us/step - loss: 142.2089 - mean_absolute_error: 9.2009\n",
      "Epoch 461/500\n",
      "36/36 [==============================] - 0s 997us/step - loss: 148.2191 - mean_absolute_error: 9.7264\n",
      "Epoch 462/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 149.7157 - mean_absolute_error: 9.7161\n",
      "Epoch 463/500\n",
      "36/36 [==============================] - 0s 913us/step - loss: 141.4417 - mean_absolute_error: 9.4736\n",
      "Epoch 464/500\n",
      "36/36 [==============================] - 0s 969us/step - loss: 155.7758 - mean_absolute_error: 9.7617\n",
      "Epoch 465/500\n",
      "36/36 [==============================] - 0s 969us/step - loss: 148.7428 - mean_absolute_error: 9.5155\n",
      "Epoch 466/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 165.0159 - mean_absolute_error: 10.2238\n",
      "Epoch 467/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 143.2727 - mean_absolute_error: 9.3417\n",
      "Epoch 468/500\n",
      "36/36 [==============================] - 0s 912us/step - loss: 145.6439 - mean_absolute_error: 9.5633\n",
      "Epoch 469/500\n",
      "36/36 [==============================] - 0s 912us/step - loss: 136.5769 - mean_absolute_error: 9.2023\n",
      "Epoch 470/500\n",
      "36/36 [==============================] - 0s 912us/step - loss: 146.1721 - mean_absolute_error: 9.5746\n",
      "Epoch 471/500\n",
      "36/36 [==============================] - 0s 966us/step - loss: 136.1660 - mean_absolute_error: 9.1813\n",
      "Epoch 472/500\n",
      "36/36 [==============================] - 0s 969us/step - loss: 136.7092 - mean_absolute_error: 9.0164\n",
      "Epoch 473/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 141.4983 - mean_absolute_error: 9.4924\n",
      "Epoch 474/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 142.3277 - mean_absolute_error: 9.3411\n",
      "Epoch 475/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 137.7064 - mean_absolute_error: 9.1979\n",
      "Epoch 476/500\n",
      "36/36 [==============================] - 0s 996us/step - loss: 142.4445 - mean_absolute_error: 9.4375\n",
      "Epoch 477/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 139.8746 - mean_absolute_error: 9.2229\n",
      "Epoch 478/500\n",
      "36/36 [==============================] - 0s 862us/step - loss: 156.5876 - mean_absolute_error: 9.8394\n",
      "Epoch 479/500\n",
      "36/36 [==============================] - 0s 883us/step - loss: 146.0226 - mean_absolute_error: 9.3640\n",
      "Epoch 480/500\n",
      "36/36 [==============================] - 0s 941us/step - loss: 137.6227 - mean_absolute_error: 9.1192\n",
      "Epoch 481/500\n",
      "36/36 [==============================] - 0s 912us/step - loss: 150.4625 - mean_absolute_error: 9.7517\n",
      "Epoch 482/500\n",
      "36/36 [==============================] - 0s 969us/step - loss: 145.8943 - mean_absolute_error: 9.4762\n",
      "Epoch 483/500\n",
      "36/36 [==============================] - 0s 997us/step - loss: 151.3442 - mean_absolute_error: 9.7533\n",
      "Epoch 484/500\n",
      "36/36 [==============================] - 0s 911us/step - loss: 146.0986 - mean_absolute_error: 9.4432\n",
      "Epoch 485/500\n",
      "36/36 [==============================] - 0s 970us/step - loss: 143.7664 - mean_absolute_error: 9.4812\n",
      "Epoch 486/500\n",
      "36/36 [==============================] - 0s 865us/step - loss: 147.4264 - mean_absolute_error: 9.5678\n",
      "Epoch 487/500\n",
      "36/36 [==============================] - 0s 911us/step - loss: 149.3286 - mean_absolute_error: 9.6243\n",
      "Epoch 488/500\n",
      "36/36 [==============================] - 0s 969us/step - loss: 153.5034 - mean_absolute_error: 9.6855\n",
      "Epoch 489/500\n",
      "36/36 [==============================] - 0s 913us/step - loss: 157.7090 - mean_absolute_error: 9.7302\n",
      "Epoch 490/500\n",
      "36/36 [==============================] - 0s 941us/step - loss: 148.0445 - mean_absolute_error: 9.4220\n",
      "Epoch 491/500\n",
      "36/36 [==============================] - 0s 940us/step - loss: 142.9003 - mean_absolute_error: 9.2614\n",
      "Epoch 492/500\n",
      "36/36 [==============================] - 0s 941us/step - loss: 136.1366 - mean_absolute_error: 9.1555\n",
      "Epoch 493/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 940us/step - loss: 143.3224 - mean_absolute_error: 9.5768\n",
      "Epoch 494/500\n",
      "36/36 [==============================] - 0s 997us/step - loss: 144.2096 - mean_absolute_error: 9.5791\n",
      "Epoch 495/500\n",
      "36/36 [==============================] - 0s 967us/step - loss: 136.7175 - mean_absolute_error: 9.1857\n",
      "Epoch 496/500\n",
      "36/36 [==============================] - 0s 887us/step - loss: 146.0440 - mean_absolute_error: 9.3945\n",
      "Epoch 497/500\n",
      "36/36 [==============================] - 0s 855us/step - loss: 146.2664 - mean_absolute_error: 9.3899\n",
      "Epoch 498/500\n",
      "36/36 [==============================] - 0s 941us/step - loss: 146.3865 - mean_absolute_error: 9.6343\n",
      "Epoch 499/500\n",
      "36/36 [==============================] - 0s 912us/step - loss: 138.3077 - mean_absolute_error: 9.2451\n",
      "Epoch 500/500\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 147.0879 - mean_absolute_error: 9.7467\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d37d7ae370>"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a model\n",
    "model_NN_age_control = Sequential()\n",
    "model_NN_age_control.add(Dense(7, input_dim=19, activation='relu'))\n",
    "model_NN_age_control.add(Dense(5, activation='relu'))\n",
    "model_NN_age_control.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Compiling model\n",
    "model_NN_age_control.compile(loss='mean_squared_error', optimizer='nadam', metrics=['mean_absolute_error'])\n",
    "\n",
    "# Training a model\n",
    "model_NN_age_control.fit(X_data_control_test_age_train, y_data_control_test_age_train, epochs=500, batch_size=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithms predict almost the same. Use a random forest to fill data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF, mae: 9.659689186746988\n",
      "GB, mae: 9.352810196686404\n",
      "NN, mae: 11.093522724616959\n"
     ]
    }
   ],
   "source": [
    "print('RF, mae:', mean_absolute_error(model_RF_age_control.predict(X_data_control_test_age_test), y_data_control_test_age_test))\n",
    "print('GB, mae:', mean_absolute_error(model_GB_age_control.predict(X_data_control_test_age_test), y_data_control_test_age_test))\n",
    "print('NN, mae:', mean_absolute_error(model_NN_age_control.predict(X_data_control_test_age_test), y_data_control_test_age_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
